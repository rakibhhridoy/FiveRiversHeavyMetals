{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f53b8ae-acd4-4071-88f0-443a3a913804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    LayerNormalization,\n",
    "    Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "import pickle # For saving and loading the scaler and feature importance results\n",
    "import json # For saving the feature importance results\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: The data loading logic remains the same as it provides the inputs\n",
    "# required for the new model architecture.\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "# Define the columns to drop and the numeric columns to use for MLP\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Ensure there are no NaNs in the numeric columns before proceeding\n",
    "orig[numeric_cols] = orig[numeric_cols].fillna(0)\n",
    "river_100[numeric_cols] = river_100[numeric_cols].fillna(0)\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"   -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \n",
    "    This version includes robust NaN handling to prevent model training errors.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    \n",
    "                    # Corrected logic: Convert any NaNs to a numerical value, e.g., 0,\n",
    "                    # to prevent them from propagating through the model.\n",
    "                    arr = np.nan_to_num(arr, nan=0.0)\n",
    "                    \n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # Get the maximum value, but check if it's a valid number and > 0.\n",
    "                    # This prevents division by zero if the patch is all zeros.\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if np.isfinite(max_val) and max_val > 0:\n",
    "                        arr /= max_val\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "\n",
    "# We now split the training data into a training and validation set\n",
    "train_split, val_split = train_test_split(train_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "coords_train_split = train_split[['Long','Lat']].values\n",
    "coords_val_split = val_split[['Long','Lat']].values\n",
    "\n",
    "dist_mat_train_split = distance_matrix(coords_train_split, coords_train_split)\n",
    "gnn_train_split = np.exp(-dist_mat_train_split/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train_split)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "dist_mat_val_train = distance_matrix(coords_val_split, coords_train_split)\n",
    "gnn_val_split = np.exp(-dist_mat_val_train/10)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train_split = scaler.fit_transform(train_split[numeric_cols])\n",
    "mlp_val_split = scaler.transform(val_split[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train_split = train_split['RI'].values\n",
    "y_val_split = val_split['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define the Mixture of Experts Model ==================== #\n",
    "def build_moe_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- Expert 1: CNN Branch ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch_flattened = Flatten()(cnn_branch)\n",
    "    cnn_branch_dense = Dense(128, activation=\"relu\")(cnn_branch_flattened)\n",
    "    # The CNN expert's final prediction\n",
    "    cnn_expert_out = Dense(1, activation=\"linear\", name=\"cnn_expert_out\")(cnn_branch_dense)\n",
    "\n",
    "    # --- Expert 2: MLP Branch ---\n",
    "    mlp_branch = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_branch = Dense(32, activation=\"relu\")(mlp_branch)\n",
    "    # The MLP expert's final prediction\n",
    "    mlp_expert_out = Dense(1, activation=\"linear\", name=\"mlp_expert_out\")(mlp_branch)\n",
    "\n",
    "    # --- Expert 3: GNN Branch ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_branch = Dense(32, activation=\"relu\")(gnn_branch)\n",
    "    # The GNN expert's final prediction\n",
    "    gnn_expert_out = Dense(1, activation=\"linear\", name=\"gnn_expert_out\")(gnn_branch)\n",
    "\n",
    "    # --- Gating Network ---\n",
    "    # The gating network needs features from all inputs to make its decision.\n",
    "    # We use the outputs of the dense layers before the final predictions as features.\n",
    "    gate_input = Concatenate()([cnn_branch_dense, mlp_branch, gnn_branch])\n",
    "    gate_network = Dense(64, activation=\"relu\")(gate_input)\n",
    "    gate_network = Dense(32, activation=\"relu\")(gate_network)\n",
    "    # The output is a set of weights for each expert (summing to 1 via softmax)\n",
    "    gate_weights = Dense(3, activation=\"softmax\", name=\"gate_weights\")(gate_network)\n",
    "\n",
    "    # --- Combine Experts and Gating Network ---\n",
    "    # Stack the predictions from each expert.\n",
    "    # The shape will be (batch_size, 3)\n",
    "    experts_stack = Concatenate(axis=1, name=\"experts_stack\")([cnn_expert_out, mlp_expert_out, gnn_expert_out])\n",
    "    \n",
    "    # Perform the weighted sum.\n",
    "    # This is done using a Lambda layer which takes the experts' outputs and\n",
    "    # the gating network's weights, and computes the dot product for each sample.\n",
    "    final_output = Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"final_output\")([experts_stack, gate_weights])\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing for BUFFER_METERS = {BUFFER_METERS}m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(train_split)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_moe_model(cnn_patch_shape, gnn_input_dim, mlp_train_split.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train_split,\n",
    "    mlp_data=mlp_train_split,\n",
    "    gnn_data=gnn_train_split,\n",
    "    y=y_train_split,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    coords=coords_val_split,\n",
    "    mlp_data=mlp_val_split,\n",
    "    gnn_data=gnn_val_split,\n",
    "    y=y_val_split,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False # No need to shuffle validation data\n",
    ")\n",
    "\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train_split[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_split[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n Mixture of Experts Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nBaseline Performance on Test Set: R\u00b2 = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test)).flatten()\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test)).flatten()\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated)).flatten()\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R\u00b2 drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R\u00b2 drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R\u00b2 drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(numeric_cols):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test)).flatten()\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator, validation_generator\n",
    "gc.collect()\n",
    "\n",
    "# ==================== 10. Save Model and Results ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Saving Model and Analysis Results...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Rebuild and re-train the model to ensure it's in a savable state.\n",
    "# This is a good practice to avoid issues with saving during a live session.\n",
    "# First, let's get the necessary dimensions again.\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(train_split)\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "final_model = build_moe_model(cnn_patch_shape, gnn_input_dim, mlp_train_split.shape[1])\n",
    "# Re-fit the model on the full training and validation data\n",
    "final_model.fit(\n",
    "    DataGenerator(coords=coords_train_split, mlp_data=mlp_train_split, gnn_data=gnn_train_split, y=y_train_split, raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size),\n",
    "    epochs=2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "    validation_data=DataGenerator(coords=coords_val_split, mlp_data=mlp_val_split, gnn_data=gnn_val_split, y=y_val_split, raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=False)\n",
    ")\n",
    "\n",
    "output_dir = \"mixture_of_experts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 10.1 Save the trained Keras model\n",
    "model_name = \"mixture_of_experts_model\"\n",
    "final_model.save(f'{output_dir}/{model_name}.keras')\n",
    "print(f\"Saved trained model to {output_dir}/{model_name}.keras\")\n",
    "\n",
    "# 10.2 Save the StandardScaler object\n",
    "# Using pickle.dump for serialization\n",
    "with open(f'{output_dir}/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"Saved StandardScaler object to {output_dir}/scaler.pkl\")\n",
    "\n",
    "# 10.3 Combine and save all feature importance results into a single file\n",
    "feature_importance_results = {\n",
    "    \"combined_branch_importance\": {\n",
    "        \"CNN_Importance_R2_drop\": importance_cnn,\n",
    "        \"MLP_Importance_R2_drop\": importance_mlp,\n",
    "        \"GNN_Importance_R2_drop\": importance_gnn\n",
    "    },\n",
    "    \"mlp_permutation_importance\": mlp_feature_importance\n",
    "}\n",
    "\n",
    "# Using pickle.dump for serialization\n",
    "with open(f'{output_dir}/feature_importance.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_importance_results, f)\n",
    "print(f\"Saved all feature importance results to {output_dir}/feature_importance.pkl\")\n",
    "\n",
    "# 10.4 Save the preprocessed data arrays for future use\n",
    "np.save(f'{output_dir}/coords_train.npy', coords_train)\n",
    "np.save(f'{output_dir}/mlp_train.npy', mlp_train_split)\n",
    "np.save(f'{output_dir}/gnn_train.npy', gnn_train_split)\n",
    "np.save(f'{output_dir}/y_train.npy', y_train_split)\n",
    "np.save(f'{output_dir}/coords_test.npy', coords_test)\n",
    "np.save(f'{output_dir}/mlp_test.npy', mlp_test)\n",
    "np.save(f'{output_dir}/gnn_test.npy', gnn_test)\n",
    "np.save(f'{output_dir}/y_test.npy', y_test)\n",
    "print(\"Saved preprocessed data arrays to .npy files\")\n",
    "\n",
    "print(\"\\nAll requested artifacts have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7c3ee-8994-4b26-908e-fab5f71e8e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaEarth Integration Enabled\n",
    "\n",
    "This notebook has been enhanced with AlphaEarth satellite embeddings.\n",
    "\n",
    "## Integration Options:\n",
    "- **Option A**: Replace indices with AlphaEarth (64 bands)\n",
    "- **Option B**: Add AlphaEarth to features (RECOMMENDED)\n",
    "- **Option C**: PCA-reduced AlphaEarth (20 components)\n",
    "- **Option D**: MLP enhancement only\n",
    "\n",
    "Expected improvement: +0.5% to +0.8% in R\u00b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== ALPHAEARTH CONFIGURATION ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Select which AlphaEarth option to use\n",
    "ALPHA_EARTH_OPTION = 'B'  # Options: A, B (recommended), C, D\n",
    "USE_ALPHA_EARTH = True\n",
    "\n",
    "# Paths to AlphaEarth data files (created by 00_AlphaEarth_Data_Preparation.ipynb)\n",
    "option_file = f'Option_{ALPHA_EARTH_OPTION}_RainyAE.csv'  # or WinterAE\n",
    "\n",
    "# Load AlphaEarth data\n",
    "if os.path.exists(option_file):\n",
    "    ae_data = pd.read_csv(option_file)\n",
    "    print(f'Loaded AlphaEarth Option {ALPHA_EARTH_OPTION}')\n",
    "    print(f'Shape: {ae_data.shape}')\n",
    "else:\n",
    "    print(f'WARNING: {option_file} not found')\n",
    "    print('Please run 00_AlphaEarth_Data_Preparation.ipynb first')\n",
    "    USE_ALPHA_EARTH = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dff4e-ab3f-4176-a490-0ef1701daed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9ab58-36bd-45e8-846f-8bc0f64dab1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3ffaa-ab99-4f08-83eb-e1689b3f5d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccde669e-feb9-4355-b82a-d5ecd4409d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "================================================================================\n",
      "Starting 5-Fold Cross-Validation...\n",
      "================================================================================\n",
      "Models will be saved in: 'models/mixture_of_experts'\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 168551.1094 - val_loss: 43592.1172\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 30601.4355 - val_loss: 9954.8633\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - loss: 7955.0679 - val_loss: 8405.6396\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - loss: 7188.4277 - val_loss: 7206.6782\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 5422.8413 - val_loss: 6562.2212\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 5381.4194 - val_loss: 7935.6968\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 4801.5469 - val_loss: 5844.4292\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 3973.6133 - val_loss: 5713.2842\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 3554.8162 - val_loss: 6006.5410\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - loss: 4241.2520 - val_loss: 5263.9468\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 198ms/step - loss: 2328.0583 - val_loss: 9025.3398\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 247ms/step - loss: 4971.9482 - val_loss: 4502.7417\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 261ms/step - loss: 3698.0166 - val_loss: 4214.6182\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 252ms/step - loss: 2109.3560 - val_loss: 3717.6140\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - loss: 2729.4966 - val_loss: 3453.7117\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 1851.5923 - val_loss: 3329.3872\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - loss: 1371.9370 - val_loss: 3290.9543\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - loss: 1865.2979 - val_loss: 3064.5010\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 1330.6146 - val_loss: 2894.0483\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 793.3242 - val_loss: 2606.8328\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 1249.2821 - val_loss: 2537.1587\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - loss: 1083.0071 - val_loss: 2411.1035\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - loss: 844.4875 - val_loss: 2227.5669\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 817.5580 - val_loss: 2056.4771\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 627.1797 - val_loss: 2152.1758\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - loss: 520.1290 - val_loss: 2015.5990\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 478.3618 - val_loss: 1811.0828\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 687.2567 - val_loss: 2020.3246\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 642.1403 - val_loss: 1656.5305\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step - loss: 469.0148 - val_loss: 1700.0020\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 503.2932 - val_loss: 1559.1846\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 434.2181 - val_loss: 1471.5553\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 371.9217 - val_loss: 1435.0919\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 198ms/step - loss: 318.4046 - val_loss: 1321.3064\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 202ms/step - loss: 249.0684 - val_loss: 1248.0770\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - loss: 228.0830 - val_loss: 1309.8303\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - loss: 226.5811 - val_loss: 1214.1860\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - loss: 209.3943 - val_loss: 1086.1028\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 278.9808 - val_loss: 1180.3383\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - loss: 183.2861 - val_loss: 1362.2240\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - loss: 409.5179 - val_loss: 1027.1716\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 207.5063 - val_loss: 955.9011\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - loss: 116.6661 - val_loss: 1167.8630\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - loss: 302.8499 - val_loss: 907.0584\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - loss: 240.3328 - val_loss: 1113.5762\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - loss: 271.4519 - val_loss: 984.3297\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 137.4708 - val_loss: 904.5404\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - loss: 163.2122 - val_loss: 899.7733\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - loss: 151.4830 - val_loss: 892.7277\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - loss: 149.5577 - val_loss: 958.9399\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 262ms/step - loss: 123.7961 - val_loss: 870.0558\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 100.6489 - val_loss: 852.3478\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 300ms/step - loss: 70.1776 - val_loss: 820.2714\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - loss: 100.1974 - val_loss: 1086.4813\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 325ms/step - loss: 187.0637 - val_loss: 764.2339\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 319ms/step - loss: 90.8036 - val_loss: 785.5148\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - loss: 108.3227 - val_loss: 729.8947\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 129.0822 - val_loss: 773.3651\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - loss: 65.0776 - val_loss: 800.8725\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 150.7952 - val_loss: 858.5091\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - loss: 170.7386 - val_loss: 779.8065\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 87.4429 - val_loss: 756.0178\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 92.2567 - val_loss: 743.5659\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 74.0730 - val_loss: 731.2203\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 77.1500 - val_loss: 732.8378\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 57.8554 - val_loss: 689.9385\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 85.9184 - val_loss: 692.6710\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 54.3277 - val_loss: 728.7250\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 91.7965 - val_loss: 732.0526\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 124.8116 - val_loss: 732.2144\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 62.1729 - val_loss: 616.2479\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 91.8659 - val_loss: 720.0981\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 108.5711 - val_loss: 591.8036\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 116.4101 - val_loss: 682.6935\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 82.0037 - val_loss: 865.4626\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 212.3897 - val_loss: 754.5359\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 165.6474 - val_loss: 627.7628\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 96.0442 - val_loss: 485.8390\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 137.0941 - val_loss: 637.3488\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 147.6378 - val_loss: 607.5875\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 307.1577 - val_loss: 942.7687\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 307.6737 - val_loss: 408.7343\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 168.5169 - val_loss: 575.2099\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 104.0305 - val_loss: 591.7393\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 84.8969 - val_loss: 484.9009\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 86.7823 - val_loss: 486.4568\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 115.1533 - val_loss: 433.5671\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 57.9257 - val_loss: 464.1304\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 47.9224 - val_loss: 535.7392\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 61.7107 - val_loss: 414.1655\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 31.5117 - val_loss: 494.5358\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 35.4863 - val_loss: 391.6352\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 41.3237 - val_loss: 403.9894\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 56.5006 - val_loss: 456.8347\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 55.9409 - val_loss: 360.1386\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 30.9794 - val_loss: 481.6875\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 65.1929 - val_loss: 442.2157\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 31.0588 - val_loss: 386.6520\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 56.8988 - val_loss: 360.4905\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 21.7911 - val_loss: 428.5547\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Validation Metrics:\n",
      "R\u00b2: 0.9257\n",
      "MAE: 13.3035\n",
      "RMSE: 18.6567\n",
      "SMAPE: 7.7818%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R\u00b2: 0.9331\n",
      "MAE: 16.4551\n",
      "RMSE: 20.4441\n",
      "SMAPE: 12.8520%\n",
      "Model for Fold 1 saved.\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 197598.2188 - val_loss: 31723.5586\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 30248.7168 - val_loss: 27372.3496\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 14759.2197 - val_loss: 15491.4551\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 49044.0508 - val_loss: 15631.5186\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 9700.0439 - val_loss: 11590.5352\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 10234.2383 - val_loss: 8879.1348\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 9330.3477 - val_loss: 9087.6680\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 6986.1309 - val_loss: 8651.9844\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 6427.5864 - val_loss: 8262.2920\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 7068.0537 - val_loss: 8251.5332\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 7703.4062 - val_loss: 8183.1899\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 5632.9917 - val_loss: 12121.5371\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 5903.4883 - val_loss: 7010.9248\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 5417.3057 - val_loss: 6696.9258\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 5037.4941 - val_loss: 6058.9189\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 4465.4990 - val_loss: 5731.9653\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 3927.6963 - val_loss: 5273.6807\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 4005.3311 - val_loss: 5573.9507\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3741.5269 - val_loss: 5099.3228\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 3044.9849 - val_loss: 5396.2422\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 3422.1621 - val_loss: 3432.0637\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 2496.7808 - val_loss: 3171.3843\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 3032.9939 - val_loss: 2830.1414\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1131.8815 - val_loss: 2543.8550\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 2285.2996 - val_loss: 2027.6722\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1272.4982 - val_loss: 1807.2028\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1274.3298 - val_loss: 1596.0555\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1798.2814 - val_loss: 1250.7006\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 1126.6176 - val_loss: 1053.2327\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 980.3923 - val_loss: 1049.7003\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 952.6404 - val_loss: 1156.1224\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 1014.5860 - val_loss: 779.9839\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 740.4284 - val_loss: 1154.7809\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 1385.1407 - val_loss: 821.4249\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 710.7786 - val_loss: 670.4493\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1081.6523 - val_loss: 699.3739\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 693.9974 - val_loss: 503.2077\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 979.2100 - val_loss: 630.2355\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 605.5117 - val_loss: 537.4675\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 624.1543 - val_loss: 573.5844\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 644.3289 - val_loss: 512.2254\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 1122.3124 - val_loss: 407.5423\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 378.7186 - val_loss: 520.5469\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 668.4836 - val_loss: 364.0913\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 342.7353 - val_loss: 322.8774\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 542.2949 - val_loss: 323.1964\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 459.1559 - val_loss: 415.7289\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 524.2381 - val_loss: 316.2062\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - loss: 347.9588 - val_loss: 419.1832\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 554.9625 - val_loss: 457.3340\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 324.7530 - val_loss: 276.4974\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 393.3343 - val_loss: 337.8380\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 281.5925 - val_loss: 276.7782\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 362.7354 - val_loss: 323.5320\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 524.9472 - val_loss: 261.6668\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 224.7333 - val_loss: 294.2843\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 358.8643 - val_loss: 309.0497\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 417.8557 - val_loss: 260.0991\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 285.3776 - val_loss: 309.0603\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 292.7693 - val_loss: 258.9649\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 329.2428 - val_loss: 350.4111\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 407.1974 - val_loss: 283.4362\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 348.1944 - val_loss: 277.9263\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - loss: 317.0385 - val_loss: 299.0559\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 247.8376 - val_loss: 254.2237\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 358.8851 - val_loss: 248.3902\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 226.5760 - val_loss: 270.8583\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 481.6812 - val_loss: 369.1644\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 413.2332 - val_loss: 354.5180\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 222.9184 - val_loss: 324.3142\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - loss: 335.0981 - val_loss: 326.1373\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 289.1891 - val_loss: 298.6695\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 226.4093 - val_loss: 238.4774\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 519.7305 - val_loss: 374.3802\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - loss: 437.9905 - val_loss: 357.5150\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 261.2592 - val_loss: 279.0586\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 469.7718 - val_loss: 469.8394\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 209.8560 - val_loss: 260.1358\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 229.0475 - val_loss: 285.0805\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 205ms/step - loss: 382.9658 - val_loss: 410.6593\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 302.5521 - val_loss: 341.2621\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 379.4114 - val_loss: 323.2434\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 242.0410 - val_loss: 263.7415\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Validation Metrics:\n",
      "R\u00b2: 0.9528\n",
      "MAE: 12.3677\n",
      "RMSE: 15.0206\n",
      "SMAPE: 7.2936%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R\u00b2: 0.7769\n",
      "MAE: 30.4060\n",
      "RMSE: 37.3455\n",
      "SMAPE: 22.0835%\n",
      "Model for Fold 2 saved.\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - loss: 207204.0000 - val_loss: 102355.9922\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 88927.5156 - val_loss: 70979.8750\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 229ms/step - loss: 13373.9492 - val_loss: 58134.3945\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 244ms/step - loss: 8524.8164 - val_loss: 54303.5312\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - loss: 6295.6729 - val_loss: 41184.8828\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 4341.7744 - val_loss: 51659.1133\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 5762.1826 - val_loss: 37495.3672\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 5094.3384 - val_loss: 36954.7266\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 4661.7183 - val_loss: 32992.6992\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4420.1519 - val_loss: 25424.5723\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 4353.0518 - val_loss: 31355.9902\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 4637.1870 - val_loss: 20031.9102\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 3847.7910 - val_loss: 14990.9629\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 4051.9246 - val_loss: 6927.5000\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 5397.0610 - val_loss: 6545.2412\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 3189.8792 - val_loss: 5138.4141\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 1994.9611 - val_loss: 8525.6582\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 1932.7791 - val_loss: 4650.4023\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 1832.5444 - val_loss: 4894.3296\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 1627.4253 - val_loss: 3179.9292\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - loss: 1884.6044 - val_loss: 3099.2131\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - loss: 1161.9441 - val_loss: 3208.2012\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 1122.4993 - val_loss: 3816.8567\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 934.9568 - val_loss: 5640.4336\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 949.7261 - val_loss: 4018.7781\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 680.0929 - val_loss: 4272.9678\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 607.5289 - val_loss: 5323.4126\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 546.5658 - val_loss: 9107.4512\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - loss: 633.8594 - val_loss: 6206.9521\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 471.4248 - val_loss: 6751.2041\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 447.3028 - val_loss: 7979.9272\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "Validation Metrics:\n",
      "R\u00b2: 0.2967\n",
      "MAE: 41.8401\n",
      "RMSE: 58.2206\n",
      "SMAPE: 23.5016%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R\u00b2: 0.4427\n",
      "MAE: 47.5664\n",
      "RMSE: 59.0281\n",
      "SMAPE: 34.6135%\n",
      "Model for Fold 3 saved.\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 247ms/step - loss: 79113.1016 - val_loss: 12965.1846\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - loss: 17051.6406 - val_loss: 7238.8389\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 12797.0020 - val_loss: 6995.4092\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 10642.5098 - val_loss: 7157.8047\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - loss: 8769.8271 - val_loss: 6498.4087\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - loss: 10841.0127 - val_loss: 5917.1377\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - loss: 8381.8691 - val_loss: 5119.9990\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - loss: 5993.1865 - val_loss: 4676.2876\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - loss: 5085.4385 - val_loss: 3521.8765\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 249ms/step - loss: 3112.8198 - val_loss: 3438.4907\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - loss: 2561.6882 - val_loss: 2353.6841\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - loss: 2240.5908 - val_loss: 1733.9779\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - loss: 1216.4978 - val_loss: 1511.9745\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 1412.6780 - val_loss: 1453.0432\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 859.7666 - val_loss: 1800.7498\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 830.8014 - val_loss: 1332.3905\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - loss: 802.7657 - val_loss: 1341.4266\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 625.5118 - val_loss: 1137.9250\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 233ms/step - loss: 760.8084 - val_loss: 1206.8407\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 601.2702 - val_loss: 1809.0215\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - loss: 870.5474 - val_loss: 1129.5876\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 583.8143 - val_loss: 1184.6074\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 562.3091 - val_loss: 1049.5518\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - loss: 733.2756 - val_loss: 1023.5347\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - loss: 382.8521 - val_loss: 1038.4670\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - loss: 494.5522 - val_loss: 1172.7582\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 779.6381 - val_loss: 1084.5659\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - loss: 442.7706 - val_loss: 1045.4456\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 488.4159 - val_loss: 1145.1061\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 470.4171 - val_loss: 1021.6561\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 366.6579 - val_loss: 962.9875\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 317.2423 - val_loss: 1058.0369\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - loss: 539.1573 - val_loss: 905.0832\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 553.8882 - val_loss: 1040.4020\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 372.7580 - val_loss: 1150.4724\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 434.1320 - val_loss: 947.1366\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 381.6964 - val_loss: 950.0345\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 306.9319 - val_loss: 1021.0139\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 375.4920 - val_loss: 900.0949\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 403.5190 - val_loss: 931.5753\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 589.0193 - val_loss: 865.9803\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 259ms/step - loss: 353.3411 - val_loss: 960.0892\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - loss: 265.8071 - val_loss: 898.8475\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 446.6572 - val_loss: 1002.9027\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 247.6969 - val_loss: 881.8472\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 244.1430 - val_loss: 852.2497\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 540.3265 - val_loss: 884.4515\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 438.7225 - val_loss: 876.4149\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 472.2773 - val_loss: 939.8046\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 368.3076 - val_loss: 853.5038\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 380.7210 - val_loss: 881.7832\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 221.8757 - val_loss: 933.2943\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 275.2752 - val_loss: 797.3197\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - loss: 365.5198 - val_loss: 816.6951\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - loss: 448.5050 - val_loss: 1044.7761\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 404.0130 - val_loss: 817.2828\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 473.1861 - val_loss: 802.1118\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 562.2990 - val_loss: 814.2020\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 456.7690 - val_loss: 801.9020\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 239.9463 - val_loss: 753.9796\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 177.9362 - val_loss: 773.0260\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 202.8980 - val_loss: 795.7689\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - loss: 474.1915 - val_loss: 727.7846\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 323.3051 - val_loss: 743.8610\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 369.8028 - val_loss: 871.1393\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 376.3257 - val_loss: 778.4739\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 590.4070 - val_loss: 845.0584\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 422.8452 - val_loss: 890.5460\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 283.6234 - val_loss: 782.4456\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 231.0260 - val_loss: 824.1019\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 186.0070 - val_loss: 791.4579\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 418.4774 - val_loss: 791.7413\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 366.5075 - val_loss: 757.7540\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Validation Metrics:\n",
      "R\u00b2: 0.8220\n",
      "MAE: 20.8524\n",
      "RMSE: 26.7814\n",
      "SMAPE: 12.9073%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R\u00b2: 0.7626\n",
      "MAE: 30.9662\n",
      "RMSE: 38.5283\n",
      "SMAPE: 20.3546%\n",
      "Model for Fold 4 saved.\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 323199.5000 - val_loss: 37455.0508\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 29901.6367 - val_loss: 14583.5186\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 10666.0469 - val_loss: 16349.7949\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - loss: 12319.7148 - val_loss: 10448.7832\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - loss: 9956.7646 - val_loss: 8382.9590\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 8735.4395 - val_loss: 7790.8101\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 4899.3398 - val_loss: 9299.4199\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 5753.5850 - val_loss: 8085.6392\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 5336.9492 - val_loss: 7843.9819\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 7044.6987 - val_loss: 8043.8218\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 6231.4678 - val_loss: 7365.2134\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 5840.4844 - val_loss: 7655.4248\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 5586.7178 - val_loss: 6992.6201\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 5769.4565 - val_loss: 7278.7788\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - loss: 4080.5693 - val_loss: 6362.5659\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 3811.1057 - val_loss: 6815.8491\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 4786.5181 - val_loss: 6018.3721\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 4330.4604 - val_loss: 5671.0518\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 3853.2800 - val_loss: 6914.0889\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 198ms/step - loss: 3592.4929 - val_loss: 6081.6011\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 2865.4961 - val_loss: 4379.0220\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 3715.4531 - val_loss: 3470.3008\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 2478.2874 - val_loss: 3015.6230\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 1919.9175 - val_loss: 3036.7473\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - loss: 1497.2520 - val_loss: 3203.0220\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 1160.5769 - val_loss: 3299.1196\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 1270.7262 - val_loss: 2687.7625\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 1610.6776 - val_loss: 3030.9866\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 1469.8716 - val_loss: 2664.5457\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 1189.9661 - val_loss: 2422.7988\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 916.8902 - val_loss: 2669.9382\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - loss: 960.5358 - val_loss: 2495.4614\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - loss: 910.6307 - val_loss: 2322.2373\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 937.7753 - val_loss: 2407.7690\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 811.4907 - val_loss: 2570.2188\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - loss: 726.5640 - val_loss: 2444.6250\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 791.1614 - val_loss: 2337.6675\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 649.3843 - val_loss: 2394.4214\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 386.4344 - val_loss: 2411.6973\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 880.2274 - val_loss: 2165.2488\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 712.1331 - val_loss: 2796.0735\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 886.6893 - val_loss: 2932.3110\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 1238.0565 - val_loss: 2176.5007\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 562.2212 - val_loss: 2162.0649\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 524.8977 - val_loss: 2122.5310\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 680.8143 - val_loss: 1985.0320\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - loss: 558.4435 - val_loss: 2259.8599\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 781.1934 - val_loss: 1922.4636\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 390.6912 - val_loss: 2408.2578\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 424.0555 - val_loss: 2034.6947\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 445.7570 - val_loss: 1990.4871\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 376.3476 - val_loss: 2040.5020\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 240.4497 - val_loss: 1792.5065\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 167.4628 - val_loss: 2047.8955\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 173.7923 - val_loss: 2059.1704\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 224.3048 - val_loss: 1867.7164\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 233.3040 - val_loss: 1867.8414\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 183.1339 - val_loss: 1844.4889\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 207.8668 - val_loss: 1672.2158\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 225.0246 - val_loss: 1707.1013\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 402.3533 - val_loss: 1703.3275\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 199.1490 - val_loss: 1718.0502\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 180.5921 - val_loss: 1639.1891\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 202.9267 - val_loss: 1546.8185\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 111.2246 - val_loss: 1758.8646\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 185.6041 - val_loss: 1475.6124\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 140.8734 - val_loss: 1521.9812\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 99.2126 - val_loss: 1616.1271\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 90.0542 - val_loss: 1767.4944\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 117.2922 - val_loss: 1526.7230\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 101.5183 - val_loss: 1610.6458\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 129.9842 - val_loss: 1539.4445\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 97.7074 - val_loss: 1538.9524\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 143.4677 - val_loss: 1515.4594\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 111.8223 - val_loss: 1511.7507\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 75.5142 - val_loss: 1382.1997\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 105.0983 - val_loss: 1645.5300\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 116.4162 - val_loss: 1357.9755\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 91.0820 - val_loss: 1529.8450\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 110.1285 - val_loss: 1305.3610\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 97.8184 - val_loss: 1665.9773\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 157.8788 - val_loss: 1282.3612\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 148.6776 - val_loss: 1652.9912\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 157.3329 - val_loss: 1361.9746\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 167.7110 - val_loss: 1717.9489\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 190.3654 - val_loss: 1293.1677\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 154.7692 - val_loss: 1481.1700\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 127.8391 - val_loss: 1518.1829\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 149.1441 - val_loss: 1246.6233\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 154.6922 - val_loss: 1516.0077\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 177.2737 - val_loss: 1390.3949\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 134.6171 - val_loss: 1186.6316\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 186.7685 - val_loss: 1249.4973\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 131.9183 - val_loss: 1218.4240\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 146.7942 - val_loss: 1306.8822\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 129.9509 - val_loss: 1191.3782\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 141.3596 - val_loss: 3588.8503\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 307.1623 - val_loss: 16133.0391\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5557.8975 - val_loss: 1422.4219\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 596.3342 - val_loss: 758.7017\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Validation Metrics:\n",
      "R\u00b2: 0.8548\n",
      "MAE: 17.5415\n",
      "RMSE: 26.4678\n",
      "SMAPE: 13.6133%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R\u00b2: 0.9207\n",
      "MAE: 18.1734\n",
      "RMSE: 22.2681\n",
      "SMAPE: 11.1326%\n",
      "Model for Fold 5 saved.\n",
      "\n",
      "================================================================================\n",
      "Final Average Metrics Across All Folds:\n",
      "================================================================================\n",
      "\n",
      "Average Validation Metrics:\n",
      "Average R\u00b2: 0.7704\n",
      "Average MAE: 21.1810\n",
      "Average RMSE: 29.0294\n",
      "Average SMAPE: 13.0195%\n",
      "\n",
      "Average Independent Test Set Metrics:\n",
      "Average R\u00b2: 0.7672\n",
      "Average MAE: 28.7134\n",
      "Average RMSE: 35.5228\n",
      "Average SMAPE: 20.2072%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "import sys\n",
    "from io import StringIO # To capture print output\n",
    "import pickle # For saving dictionaries and other objects\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "N_SPLITS = 5 # Number of folds for cross-validation\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/WinterSeason1.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100W.csv\")\n",
    "# Define the columns to drop and the numeric columns to use for MLP\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "# Ensure there are no NaNs in the numeric columns before proceeding\n",
    "orig[numeric_cols] = orig[numeric_cols].fillna(0)\n",
    "river_100[numeric_cols] = river_100[numeric_cols].fillna(0)\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "# ==================== 3. Define Metric Functions ==================== #\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    # Avoid division by zero by setting the result to 0 where denominator is 0\n",
    "    return np.mean(np.where(denominator == 0, 0, numerator / denominator)) * 100\n",
    "# ==================== 4. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    \n",
    "                    # Corrected logic: Convert any NaNs to a numerical value, e.g., 0,\n",
    "                    # to prevent them from propagating through the model.\n",
    "                    arr = np.nan_to_num(arr, nan=0.0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "                    # Get the maximum value, but check if it's a valid number and > 0.\n",
    "                    # This prevents division by zero if the patch is all zeros.\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if np.isfinite(max_val) and max_val > 0:\n",
    "                        arr /= max_val\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.buffer_meters = buffer_meters\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "# ==================== 5. Define the Mixture of Experts Model ==================== #\n",
    "def build_moe_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- Expert 1: CNN Branch ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch_flattened = Flatten()(cnn_branch)\n",
    "    cnn_branch_dense = Dense(128, activation=\"relu\")(cnn_branch_flattened)\n",
    "    cnn_expert_out = Dense(1, activation=\"linear\", name=\"cnn_expert_out\")(cnn_branch_dense)\n",
    "    # --- Expert 2: MLP Branch ---\n",
    "    mlp_branch = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_branch = Dense(32, activation=\"relu\")(mlp_branch)\n",
    "    mlp_expert_out = Dense(1, activation=\"linear\", name=\"mlp_expert_out\")(mlp_branch)\n",
    "    # --- Expert 3: GNN Branch ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_branch = Dense(32, activation=\"relu\")(gnn_branch)\n",
    "    gnn_expert_out = Dense(1, activation=\"linear\", name=\"gnn_expert_out\")(gnn_branch)\n",
    "    # --- Gating Network ---\n",
    "    gate_input = Concatenate()([cnn_branch_dense, mlp_branch, gnn_branch])\n",
    "    gate_network = Dense(64, activation=\"relu\")(gate_input)\n",
    "    gate_network = Dense(32, activation=\"relu\")(gate_network)\n",
    "    gate_weights = Dense(3, activation=\"softmax\", name=\"gate_weights\")(gate_network)\n",
    "    # --- Combine Experts and Gating Network ---\n",
    "    experts_stack = Concatenate(axis=1, name=\"experts_stack\")([cnn_expert_out, mlp_expert_out, gnn_expert_out])\n",
    "    final_output = Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"final_output\")([experts_stack, gate_weights])\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "def evaluate_model(model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4):\n",
    "    \"\"\"\n",
    "    Evaluates a model on the given data and returns a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    num_samples = len(y)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    # Get patch dimensions\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords[i:i+batch_size]\n",
    "        batch_mlp = mlp_data[i:i+batch_size]\n",
    "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    smape_val = smape(y, y_pred)\n",
    "    return {\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'SMAPE': smape_val\n",
    "    }\n",
    "# ==================== 6. Run Train/Test Single Split ==================== #\n",
    "print(\"=\"*80)\n",
    "print(f\"Starting {N_SPLITS}-Fold Single Split...\")\n",
    "print(\"=\"*80)\n",
    "# Create a folder to save models\n",
    "model_save_dir = \"models/mixture_of_experts\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "print(f\"Models will be saved in: '{model_save_dir}'\")\n",
    "# Prepare data for Train/Test\n",
    "combined_indices = np.arange(len(train_combined))\n",
    "coords_all = train_combined[['Long','Lat']].values\n",
    "data_all = train_combined[numeric_cols].values\n",
    "gnn_input_all = np.exp(-distance_matrix(coords_all, coords_all)/10)\n",
    "y_all = train_combined['RI'].values\n",
    "batch_size = 4\n",
    "# Store metrics for each fold\n",
    "fold_metrics = []\n",
    "test_metrics = []\n",
    "# Initialize Train/Test\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(combined_indices)):\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} ---\")\n",
    "    # Split data for the current fold\n",
    "    coords_train_fold = coords_all[train_indices]\n",
    "    coords_val_fold = coords_all[val_indices]\n",
    "    mlp_train_fold = data_all[train_indices]\n",
    "    mlp_val_fold = data_all[val_indices]\n",
    "    y_train_fold = y_all[train_indices]\n",
    "    y_val_fold = y_all[val_indices]\n",
    "    # Scale MLP data and prepare GNN matrices for the current fold\n",
    "    scaler_fold = StandardScaler()\n",
    "    mlp_train_scaled = scaler_fold.fit_transform(mlp_train_fold)\n",
    "    mlp_val_scaled = scaler_fold.transform(mlp_val_fold)\n",
    "    \n",
    "    dist_mat_train_fold = distance_matrix(coords_train_fold, coords_train_fold)\n",
    "    gnn_train_fold = np.exp(-dist_mat_train_fold/10)\n",
    "    \n",
    "    dist_mat_val_fold = distance_matrix(coords_val_fold, coords_train_fold)\n",
    "    gnn_val_fold = np.exp(-dist_mat_val_fold/10)\n",
    "    # Re-initialize and compile the model for each fold\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "    \n",
    "    model = build_moe_model(cnn_patch_shape, len(coords_train_fold), mlp_train_fold.shape[1])\n",
    "    \n",
    "    # Create Data Generators for the current fold\n",
    "    train_generator = DataGenerator(\n",
    "        coords=coords_train_fold,\n",
    "        mlp_data=mlp_train_scaled,\n",
    "        gnn_data=gnn_train_fold,\n",
    "        y=y_train_fold,\n",
    "        raster_paths=raster_paths,\n",
    "        buffer_meters=BUFFER_METERS,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = DataGenerator(\n",
    "        coords=coords_val_fold,\n",
    "        mlp_data=mlp_val_scaled,\n",
    "        gnn_data=gnn_val_fold,\n",
    "        y=y_val_fold,\n",
    "        raster_paths=raster_paths,\n",
    "        buffer_meters=BUFFER_METERS,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    print(\"Starting model training...\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=val_generator\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "    # Evaluate on the validation set\n",
    "    fold_result = evaluate_model(model, coords_val_fold, mlp_val_scaled, gnn_val_fold, y_val_fold, raster_paths, BUFFER_METERS, batch_size)\n",
    "    fold_metrics.append(fold_result)\n",
    "    print(\"Validation Metrics:\")\n",
    "    print(f\"R\u00b2: {fold_result['R2']:.4f}\")\n",
    "    print(f\"MAE: {fold_result['MAE']:.4f}\")\n",
    "    print(f\"RMSE: {fold_result['RMSE']:.4f}\")\n",
    "    print(f\"SMAPE: {fold_result['SMAPE']:.4f}%\")\n",
    "    # Prepare and evaluate on the independent test set\n",
    "    dist_mat_test_train = distance_matrix(test_orig[['Long','Lat']].values, coords_train_fold)\n",
    "    gnn_test_fold = np.exp(-dist_mat_test_train/10)\n",
    "    \n",
    "    mlp_test_scaled = scaler_fold.transform(test_orig[numeric_cols].values)\n",
    "    test_result = evaluate_model(model, test_orig[['Long','Lat']].values, mlp_test_scaled, gnn_test_fold, test_orig['RI'].values, raster_paths, BUFFER_METERS, batch_size)\n",
    "    test_metrics.append(test_result)\n",
    "    print(\"\\nIndependent Test Set Metrics:\")\n",
    "    print(f\"R\u00b2: {test_result['R2']:.4f}\")\n",
    "    print(f\"MAE: {test_result['MAE']:.4f}\")\n",
    "    print(f\"RMSE: {test_result['RMSE']:.4f}\")\n",
    "    print(f\"SMAPE: {test_result['SMAPE']:.4f}%\")\n",
    "    \n",
    "    # Save the trained model for the current fold\n",
    "    model.save(os.path.join(model_save_dir, f\"fold_{fold+1}.keras\"))\n",
    "    print(f\"Model for Fold {fold+1} saved.\")\n",
    "    # Clean up to free memory\n",
    "    del model, train_generator, val_generator, early_stopping, history\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "# ==================== 7. Print Final Averages ==================== #\n",
    "# Calculate average metrics\n",
    "avg_fold_metrics = pd.DataFrame(fold_metrics).mean().to_dict()\n",
    "avg_test_metrics = pd.DataFrame(test_metrics).mean().to_dict()\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Final Average Metrics Across All Folds:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAverage Validation Metrics:\")\n",
    "print(f\"Average R\u00b2: {avg_fold_metrics['R2']:.4f}\")\n",
    "print(f\"Average MAE: {avg_fold_metrics['MAE']:.4f}\")\n",
    "print(f\"Average RMSE: {avg_fold_metrics['RMSE']:.4f}\")\n",
    "print(f\"Average SMAPE: {avg_fold_metrics['SMAPE']:.4f}%\")\n",
    "print(\"\\nAverage Independent Test Set Metrics:\")\n",
    "print(f\"Average R\u00b2: {avg_test_metrics['R2']:.4f}\")\n",
    "print(f\"Average MAE: {avg_test_metrics['MAE']:.4f}\")\n",
    "print(f\"Average RMSE: {avg_test_metrics['RMSE']:.4f}\")\n",
    "print(f\"Average SMAPE: {avg_test_metrics['SMAPE']:.4f}%\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ec7f52-4760-4c44-b169-d9ba240e3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - ClayW.tif\n",
      "  - CdW.tif\n",
      "  - SandW.tif\n",
      "  - SiltW.tif\n",
      "  - AsW.tif\n",
      "  - CrW.tif\n",
      "  - NiW.tif\n",
      "  - PbW.tif\n",
      "  - CuW.tif\n",
      "================================================================================\n",
      "Starting Single-Run Training and Evaluation...\n",
      "================================================================================\n",
      "Starting model training...\n",
      "Training complete.\n",
      "\n",
      "================================================================================\n",
      "Evaluating on Independent Test Set...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "import sys\n",
    "import warnings # For LIME\n",
    "from io import StringIO\n",
    "import pickle # For saving dictionaries and other objects\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# Load original data\n",
    "orig = pd.read_csv(\"../../data/WinterSeason1.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100W.csv\")\n",
    "\n",
    "# Define the columns to drop and the numeric columns to use for MLP\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Ensure there are no NaNs in the numeric columns before proceeding\n",
    "orig[numeric_cols] = orig[numeric_cols].fillna(0)\n",
    "river_100[numeric_cols] = river_100[numeric_cols].fillna(0)\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDWW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Define Metric Functions ==================== #\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    # Avoid division by zero by setting the result to 0 where denominator is 0\n",
    "    return np.mean(np.where(denominator == 0, 0, numerator / denominator)) * 100\n",
    "\n",
    "# ==================== 4. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    \n",
    "                    # Corrected logic: Convert any NaNs to a numerical value, e.g., 0,\n",
    "                    # to prevent them from propagating through the model.\n",
    "                    arr = np.nan_to_num(arr, nan=0.0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # Get the maximum value, but check if it's a valid number and > 0.\n",
    "                    # This prevents division by zero if the patch is all zeros.\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if np.isfinite(max_val) and max_val > 0:\n",
    "                        arr /= max_val\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.buffer_meters = buffer_meters\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 5. Define the Mixture of Experts Model ==================== #\n",
    "def build_moe_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- Expert 1: CNN Branch ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch_flattened = Flatten()(cnn_branch)\n",
    "    cnn_branch_dense = Dense(128, activation=\"relu\")(cnn_branch_flattened)\n",
    "    cnn_expert_out = Dense(1, activation=\"linear\", name=\"cnn_expert_out\")(cnn_branch_dense)\n",
    "\n",
    "    # --- Expert 2: MLP Branch ---\n",
    "    mlp_branch = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_branch = Dense(32, activation=\"relu\")(mlp_branch)\n",
    "    mlp_expert_out = Dense(1, activation=\"linear\", name=\"mlp_expert_out\")(mlp_branch)\n",
    "\n",
    "    # --- Expert 3: GNN Branch ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_branch = Dense(32, activation=\"relu\")(gnn_branch)\n",
    "    gnn_expert_out = Dense(1, activation=\"linear\", name=\"gnn_expert_out\")(gnn_branch)\n",
    "\n",
    "    # --- Gating Network ---\n",
    "    gate_input = Concatenate()([cnn_branch_dense, mlp_branch, gnn_branch])\n",
    "    gate_network = Dense(64, activation=\"relu\")(gate_input)\n",
    "    gate_network = Dense(32, activation=\"relu\")(gate_network)\n",
    "    gate_weights = Dense(3, activation=\"softmax\", name=\"gate_weights\")(gate_network)\n",
    "\n",
    "    # --- Combine Experts and Gating Network ---\n",
    "    experts_stack = Concatenate(axis=1, name=\"experts_stack\")([cnn_expert_out, mlp_expert_out, gnn_expert_out])\n",
    "    final_output = Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"final_output\")([experts_stack, gate_weights])\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4):\n",
    "    \"\"\"\n",
    "    Evaluates a model on the given data and returns a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    num_samples = len(y)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    # Get patch dimensions\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords[i:i+batch_size]\n",
    "        batch_mlp = mlp_data[i:i+batch_size]\n",
    "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn), verbose=0).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    smape_val = smape(y, y_pred)\n",
    "\n",
    "    return {\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'SMAPE': smape_val\n",
    "    }\n",
    "\n",
    "# ==================== 6. Main Script: Train, Evaluate, and Explain ==================== #\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Starting Single-Run Training and Evaluation...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data for training and validation\n",
    "coords_train_all = train_combined[['Long', 'Lat']].values\n",
    "mlp_train_all = train_combined[numeric_cols].values\n",
    "y_train_all = train_combined['RI'].values\n",
    "batch_size = 4\n",
    "\n",
    "# Create a train/validation split from the training data\n",
    "coords_train, coords_val, mlp_train, mlp_val, y_train, y_val = train_test_split(\n",
    "    coords_train_all, mlp_train_all, y_train_all, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale MLP data and prepare GNN matrices for training\n",
    "scaler = StandardScaler()\n",
    "mlp_train_scaled = scaler.fit_transform(mlp_train)\n",
    "mlp_val_scaled = scaler.transform(mlp_val)\n",
    "\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train / 10)\n",
    "\n",
    "dist_mat_val = distance_matrix(coords_val, coords_train)\n",
    "gnn_val = np.exp(-dist_mat_val / 10)\n",
    "\n",
    "# Build and compile the model\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_moe_model(cnn_patch_shape, gnn_train.shape[1], mlp_train_scaled.shape[1])\n",
    "\n",
    "# Create Data Generators\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train_scaled,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    coords=coords_val,\n",
    "    mlp_data=mlp_val_scaled,\n",
    "    gnn_data=gnn_val,\n",
    "    y=y_val,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=val_generator\n",
    ")\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# --- Evaluation on Independent Test Set ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Evaluating on Independent Test Set...\")\n",
    "print(\"=\"*80)\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols].values)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "test_result = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68ed568-3a8b-4b1b-a07d-c4217f4a952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Independent Test Set Metrics:\n",
      "R\u00b2: 0.7706\n",
      "MAE: 29.3151\n",
      "RMSE: 37.8735\n",
      "SMAPE: 17.5464%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIndependent Test Set Metrics:\")\n",
    "print(f\"R\u00b2: {test_result['R2']:.4f}\")\n",
    "print(f\"MAE: {test_result['MAE']:.4f}\")\n",
    "print(f\"RMSE: {test_result['RMSE']:.4f}\")\n",
    "print(f\"SMAPE: {test_result['SMAPE']:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d9b21f-8b02-48fe-b7af-b9bd489e01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MixtureOfExperts.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dead155-5fe2-4f88-8f14-1f2fd9fbc14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Calculating Permutation Feature Importance...\n",
      "================================================================================\n",
      "Permuting feature: hydro_dist_brick\n",
      "Permuting feature: num_brick_field\n",
      "Permuting feature: hydro_dist_ind\n",
      "Permuting feature: num_industry\n",
      "Permuting feature: CrW\n",
      "Permuting feature: NiW\n",
      "Permuting feature: CuW\n",
      "Permuting feature: AsW\n",
      "Permuting feature: CdW\n",
      "Permuting feature: PbW\n",
      "Permuting feature: MW\n",
      "Permuting feature: SandW\n",
      "Permuting feature: SiltW\n",
      "Permuting feature: ClayW\n",
      "Permuting feature: FeW\n",
      "\n",
      "Permutation Feature Importance (MLP Features):\n",
      "                  Permutation Importance (R\u00b2 drop)\n",
      "hydro_dist_brick                               0.0\n",
      "num_brick_field                                0.0\n",
      "hydro_dist_ind                                 0.0\n",
      "num_industry                                   0.0\n",
      "CrW                                            0.0\n",
      "NiW                                            0.0\n",
      "CuW                                            0.0\n",
      "AsW                                            0.0\n",
      "CdW                                            0.0\n",
      "PbW                                            0.0\n",
      "MW                                             0.0\n",
      "SandW                                          0.0\n",
      "SiltW                                          0.0\n",
      "ClayW                                          0.0\n",
      "FeW                                            0.0\n",
      "\n",
      "================================================================================\n",
      "Calculating LIME Feature Importance for a few samples...\n",
      "================================================================================\n",
      "Pre-loading CNN patches and GNN matrix for LIME...\n",
      "\n",
      "Explaining sample at index 0...\n",
      "\n",
      "Explaining sample at index 1...\n",
      "\n",
      "Explaining sample at index 5...\n",
      "\n",
      "Explaining sample at index 2...\n",
      "\n",
      "Explaining sample at index 4...\n",
      "\n",
      "LIME Local Feature Importance for 5 Test Samples:\n",
      "    Sample Index                          Feature  LIME Weight\n",
      "0              0         hydro_dist_brick > -1.10          0.0\n",
      "1              0          num_brick_field <= 1.44          0.0\n",
      "2              0  -0.87 < hydro_dist_ind <= -0.87          0.0\n",
      "3              0      1.72 < num_industry <= 3.64          0.0\n",
      "4              0              -0.78 < CrW <= 0.23          0.0\n",
      "..           ...                              ...          ...\n",
      "70             4                      MW <= -1.19          0.0\n",
      "71             4             1.67 < SandW <= 1.78          0.0\n",
      "72             4           -1.47 < SiltW <= -1.32          0.0\n",
      "73             4           -1.31 < ClayW <= -0.89          0.0\n",
      "74             4                       FeW > 0.90          0.0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# ==================== 7. Feature Importance Analysis ==================== #\n",
    "\n",
    "# --- Permutation Feature Importance (MLP Features only) ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Calculating Permutation Feature Importance...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get baseline performance on the test set\n",
    "baseline_r2 = test_result['R2']\n",
    "importance = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"Permuting feature: {col}\")\n",
    "    \n",
    "    # Create a copy of the scaled test data\n",
    "    mlp_test_shuffled = mlp_test.copy()\n",
    "    \n",
    "    # Find the index of the column to shuffle\n",
    "    col_idx = list(numeric_cols).index(col)\n",
    "    \n",
    "    # Shuffle the values of the specific column\n",
    "    np.random.shuffle(mlp_test_shuffled[:, col_idx])\n",
    "    \n",
    "    # Evaluate the model with the shuffled data\n",
    "    shuffled_result = evaluate_model(model, coords_test, mlp_test_shuffled, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
    "    shuffled_r2 = shuffled_result['R2']\n",
    "    \n",
    "    # Calculate the importance as the drop in R\u00b2\n",
    "    importance[col] = baseline_r2 - shuffled_r2\n",
    "\n",
    "# Create a DataFrame for permutation importance\n",
    "permutation_df = pd.DataFrame.from_dict(\n",
    "    importance,\n",
    "    orient='index',\n",
    "    columns=['Permutation Importance (R\u00b2 drop)']\n",
    ").sort_values(by='Permutation Importance (R\u00b2 drop)', ascending=False)\n",
    "print(\"\\nPermutation Feature Importance (MLP Features):\")\n",
    "print(permutation_df)\n",
    "\n",
    "# --- LIME (Local Interpretable Model-Agnostic Explanations) ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Calculating LIME Feature Importance for a few samples...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Get CNN and GNN data for the entire test set once\n",
    "print(\"Pre-loading CNN patches and GNN matrix for LIME...\")\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "    \n",
    "cnn_data_test = extract_patch_for_generator(\n",
    "    coords_test,\n",
    "    raster_paths,\n",
    "    buffer_pixels_x,\n",
    "    buffer_pixels_y,\n",
    "    patch_width,\n",
    "    patch_height\n",
    ")\n",
    "gnn_data_test = np.exp(-distance_matrix(coords_test, coords_train) / 10)\n",
    "\n",
    "\n",
    "# LIME explainer setup\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=mlp_test,\n",
    "    feature_names=list(numeric_cols),\n",
    "    class_names=['RI'],\n",
    "    mode='regression'\n",
    ")\n",
    "\n",
    "# Select a few random samples from the test set for explanation\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(test_orig), 5, replace=False)\n",
    "\n",
    "lime_results = []\n",
    "for i in sample_indices:\n",
    "    print(f\"\\nExplaining sample at index {i}...\")\n",
    "    \n",
    "    # Define a local prediction function for LIME\n",
    "    def predict_wrapper(instances):\n",
    "        # LIME provides a batch of perturbed tabular data (instances).\n",
    "        # We need to replicate the CNN and GNN data for this batch.\n",
    "        num_instances = instances.shape[0]\n",
    "        \n",
    "        # Replicate the CNN patch for the current sample\n",
    "        cnn_batch = np.tile(cnn_data_test[i:i+1], (num_instances, 1, 1, 1))\n",
    "        \n",
    "        # Replicate the GNN row for the current sample\n",
    "        gnn_batch = np.tile(gnn_data_test[i:i+1], (num_instances, 1))\n",
    "        \n",
    "        # Predict on the new batch\n",
    "        predictions = model.predict((cnn_batch, instances, gnn_batch), verbose=0)\n",
    "        return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "    # Explain the prediction for a single instance using the wrapper\n",
    "    explanation = explainer.explain_instance(\n",
    "        data_row=mlp_test[i],\n",
    "        predict_fn=predict_wrapper,\n",
    "        num_features=len(numeric_cols)\n",
    "    )\n",
    "    \n",
    "    # Get the feature importances from the explanation\n",
    "    feat_imps = explanation.as_list()\n",
    "    \n",
    "    # Append to our list of results\n",
    "    for feature, importance in feat_imps:\n",
    "        lime_results.append({\n",
    "            'Sample Index': i,\n",
    "            'Feature': feature,\n",
    "            'LIME Weight': importance\n",
    "        })\n",
    "\n",
    "# Create a DataFrame for LIME results\n",
    "lime_df = pd.DataFrame(lime_results)\n",
    "print(\"\\nLIME Local Feature Importance for 5 Test Samples:\")\n",
    "print(lime_df)\n",
    "\n",
    "warnings.filterwarnings(\"default\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb99126-573f-4240-92e7-8dd38772d1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>LIME Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hydro_dist_brick &gt; -1.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>CdW &lt;= -0.81</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.71 &lt; AsW &lt;= 0.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.13 &lt; CuW &lt;= 0.93</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>NiW &lt;= -0.34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>CrW &gt; 1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>3.64 &lt; num_industry &lt;= 7.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.87 &lt; hydro_dist_ind &lt;= -0.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>num_brick_field &gt; 7.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>hydro_dist_brick &lt;= -1.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sample Index                          Feature  LIME Weight\n",
       "0              0         hydro_dist_brick > -1.10          0.0\n",
       "53             2                     CdW <= -0.81          0.0\n",
       "52             2              -0.71 < AsW <= 0.80          0.0\n",
       "51             2              -0.13 < CuW <= 0.93          0.0\n",
       "50             2                     NiW <= -0.34          0.0\n",
       "49             2                       CrW > 1.00          0.0\n",
       "48             2      3.64 < num_industry <= 7.10          0.0\n",
       "47             2  -0.87 < hydro_dist_ind <= -0.87          0.0\n",
       "46             2           num_brick_field > 7.23          0.0\n",
       "45             2        hydro_dist_brick <= -1.10          0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lime_df.sort_values(\"LIME Weight\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d56e95-7abd-4d61-a0e2-9a51a37f2d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permutation Importance (R\u00b2 drop)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hydro_dist_brick</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_brick_field</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydro_dist_ind</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_industry</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NiW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CuW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AsW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CdW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PbW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SandW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SiltW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClayW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FeW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Permutation Importance (R\u00b2 drop)\n",
       "hydro_dist_brick                               0.0\n",
       "num_brick_field                                0.0\n",
       "hydro_dist_ind                                 0.0\n",
       "num_industry                                   0.0\n",
       "CrW                                            0.0\n",
       "NiW                                            0.0\n",
       "CuW                                            0.0\n",
       "AsW                                            0.0\n",
       "CdW                                            0.0\n",
       "PbW                                            0.0\n",
       "MW                                             0.0\n",
       "SandW                                          0.0\n",
       "SiltW                                          0.0\n",
       "ClayW                                          0.0\n",
       "FeW                                            0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5929d6-f207-4a77-a8b3-ac7a0d7e504e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "alphaearth_integrated": true,
  "season": "winter"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}