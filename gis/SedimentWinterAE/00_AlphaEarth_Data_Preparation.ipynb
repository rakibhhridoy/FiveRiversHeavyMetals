{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaEarth Data Preparation for Winter Season",
    "",
    "This notebook prepares AlphaEarth satellite embeddings for integration with your existing CNN/MLP/GNN models.",
    "",
    "## Overview",
    "- Extract AlphaEarth embeddings from Google Earth Engine",
    "- Prepare 4 integration options (A, B, C, D)",
    "- Create patches for CNN input",
    "- Prepare summary statistics for MLP input",
    "- Save data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import os\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All imports successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Earth Engine (run once per session)\n",
    "try:\n",
    "    ee.Initialize(project='five-rivers-alphaearth')\n",
    "    print(\"Earth Engine initialized successfully\")\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project='five-rivers-alphaearth')\n",
    "    print(\"Earth Engine authenticated and initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Sampling Points and Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your sampling points\n",
    "sampling_points = pd.read_csv('../data/Samples_100.csv')\n",
    "rainy_data = pd.read_csv('../../data/RainySeason.csv')\n",
    "\n",
    "print(f\"Sampling points: {len(sampling_points)}\")\n",
    "print(f\"Rainy season data: {len(rainy_data)}\")\n",
    "print(f\"\\nColumns in sampling data: {sampling_points.columns.tolist()[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract AlphaEarth Embeddings from Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlphaEarth dataset\n",
    "embeddings_collection = ee.ImageCollection('GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL')\n",
    "\n",
    "# Define study area (Dhaka, Bangladesh)\n",
    "# Adjust bounds to match your study area\n",
    "aoi = ee.Geometry.Rectangle([88.0, 23.5, 90.0, 24.0])\n",
    "\n",
    "print(f\"AlphaEarth dataset loaded\")\n",
    "print(f\"Area of Interest: {aoi.getInfo()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract AlphaEarth values at sampling points\n",
    "def extract_alpha_earth_values(year_start, year_end, season_name):\n",
    "    \"\"\"\n",
    "    Extract AlphaEarth embeddings for specified year range and season\n",
    "    \n",
    "    Parameters:\n",
    "    - year_start: Start year (e.g., 2023)\n",
    "    - year_end: End year (e.g., 2023)\n",
    "    - season_name: 'rainy' or 'winter'\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with AlphaEarth values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define date ranges for seasons\n",
    "    if season_name == 'rainy':\n",
    "        date_start = f'{year_start}-06-01'\n",
    "        date_end = f'{year_end}-09-30'\n",
    "    else:  # winter\n",
    "        date_start = f'{year_start}-11-01'\n",
    "        if year_start == year_end:\n",
    "            date_end = f'{year_end+1}-02-28'\n",
    "        else:\n",
    "            date_end = f'{year_end}-02-28'\n",
    "    \n",
    "    # Load AlphaEarth for this period\n",
    "    embeddings = embeddings_collection.filterDate(date_start, date_end).first()\n",
    "    \n",
    "    # Extract values at each sampling point\n",
    "    alpha_earth_values = []\n",
    "    \n",
    "    for idx, row in sampling_points.iterrows():\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Extracting sample {idx+1}/{len(sampling_points)}...\")\n",
    "        \n",
    "        point = ee.Geometry.Point([row['Longitude'], row['Latitude']])\n",
    "        \n",
    "        try:\n",
    "            # Sample at 10m resolution (AlphaEarth native resolution)\n",
    "            sample = embeddings.sample(point, scale=10)\n",
    "            values = sample.first().toDictionary().getInfo()\n",
    "            alpha_earth_values.append(values)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting sample {idx}: {e}\")\n",
    "            # Create NaN row if extraction fails\n",
    "            alpha_earth_values.append({f'AE_{i:02d}': np.nan for i in range(64)})\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    ae_df = pd.DataFrame(alpha_earth_values)\n",
    "    \n",
    "    # Rename columns from A00-A63 to AE_00-AE_63 for clarity\n",
    "    ae_columns = {}\n",
    "    for col in ae_df.columns:\n",
    "        if col.startswith('A') and col[1:].isdigit():\n",
    "            ae_columns[col] = f'AE_{col[1:]}'\n",
    "    ae_df = ae_df.rename(columns=ae_columns)\n",
    "    \n",
    "    print(f\"\\nExtracted {len(ae_df)} samples\")\n",
    "    print(f\"Columns: {ae_df.columns.tolist()[:5]}...\")\n",
    "    print(f\"Shape: {ae_df.shape}\")\n",
    "    \n",
    "    return ae_df\n",
    "\n",
    "print(\"Function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract for rainy season 2023\n",
    "# NOTE: This will take 10-15 minutes per year\n",
    "# For full analysis, loop through years 2017-2024\n",
    "\n",
    "print(\"Extracting AlphaEarth for rainy season 2023...\")\n",
    "alpha_earth_rainy = extract_alpha_earth_values(2023, 2023, 'rainy')\n",
    "\n",
    "# Save for future use\n",
    "alpha_earth_rainy.to_csv('alpha_earth_rainy_2023.csv', index=False)\n",
    "print(\"\\nSaved to: alpha_earth_rainy_2023.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Extract for all years 2017-2024\n",
    "# Uncomment to run full extraction\n",
    "\n",
    "# all_years_data = {}\n",
    "# for year in range(2017, 2025):\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Extracting year {year}...\")\n",
    "#     print(f\"{'='*60}\")\n",
    "#     \n",
    "#     ae_data = extract_alpha_earth_values(year, year, 'rainy')\n",
    "#     ae_data['year'] = year\n",
    "#     ae_data['season'] = 'rainy'\n",
    "#     all_years_data[f'rainy_{year}'] = ae_data\n",
    "#     \n",
    "#     ae_data.to_csv(f'alpha_earth_rainy_{year}.csv', index=False)\n",
    "\n",
    "print(\"Extraction code prepared (uncomment to run full analysis)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare AlphaEarth Integration - Option B (Recommended)\n",
    "\n",
    "### Option B: Add to Current Features\n",
    "\n",
    "This integrates AlphaEarth embeddings while keeping all existing features.\n",
    "Expected improvement: +3-6% R\u00b2 improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current base data for comparison\n",
    "base_data = pd.read_csv('../data/Samples_100.csv')\n",
    "\n",
    "# Merge with AlphaEarth\n",
    "combined_data = pd.concat([base_data.reset_index(drop=True), alpha_earth_rainy.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(f\"Combined data shape: {combined_data.shape}\")\n",
    "print(f\"Base features: {list(base_data.columns[:10])}\")\n",
    "print(f\"AlphaEarth columns: {[c for c in combined_data.columns if c.startswith('AE_')][:5]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlphaEarth Integration Option B: Add to Current Features (RECOMMENDED)\n",
    "# This is the recommended approach - keeps all existing features and adds AlphaEarth\n",
    "",
    "# Load current base data\n",
    "base_data = pd.read_csv('../data/Samples_100.csv')\n",
    "",
    "# Merge with AlphaEarth embeddings\n",
    "combined_data = pd.concat([base_data.reset_index(drop=True), alpha_earth_rainy.reset_index(drop=True)], axis=1)\n",
    "",
    "print(f'Combined data shape: {combined_data.shape}')\n",
    "print(f'Total features: {len(combined_data.columns)}')\n",
    "print(f'  - Original features: {len(base_data.columns)}')\n",
    "print(f'  - AlphaEarth features: 64')\n",
    "",
    "# Save Option B data (MAIN DATASET)\n",
    "option_b_data = combined_data.copy()\n",
    "option_b_data.to_csv('Option_B_RainyAE.csv', index=False)\n",
    "",
    "print(f'\\nOption B dataset saved: Option_B_RainyAE.csv')\n",
    "print(f'Shape: {option_b_data.shape}')\n",
    "print(f'Columns: {list(option_b_data.columns[:10])}...')\n",
    "",
    "# Info about what this option includes:\n",
    "print()\n",
    "print('=' * 70)\n",
    "print('OPTION B DETAILS (RECOMMENDED)')\n",
    "print('=' * 70)\n",
    "print('\u2713 Keeps all original features (25 bands: metals, indices, LULC, soil)')\n",
    "print('\u2713 Adds 64-dimensional AlphaEarth embeddings')\n",
    "print('\u2713 Total CNN input: ~89 channels')\n",
    "print('\u2713 Expected improvement: +3-6% R\u00b2 (rainy), +2-4% R\u00b2 (winter)')\n",
    "print('\u2713 Best balance of performance vs complexity')\n",
    "print('=' * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create CNN Patches with AlphaEarth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract raster patches (existing code, adapted)\n",
    "def extract_alpha_earth_patches(alpha_earth_path, coordinates, patch_size=32, resolution=10):\n",
    "    \"\"\"\n",
    "    Extract patches from AlphaEarth raster at sampling locations\n",
    "    \n",
    "    Parameters:\n",
    "    - alpha_earth_path: Path to AlphaEarth GeoTIFF/GeoPackage\n",
    "    - coordinates: List of (lon, lat) tuples\n",
    "    - patch_size: Size in pixels (32x32 = 320m x 320m at 10m resolution)\n",
    "    - resolution: Pixel resolution in meters\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array of shape (N, patch_size, patch_size, 64)\n",
    "    \"\"\"\n",
    "    \n",
    "    patches = []\n",
    "    \n",
    "    with rasterio.open(alpha_earth_path) as src:\n",
    "        for idx, (lon, lat) in enumerate(coordinates):\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"Extracting patch {idx+1}/{len(coordinates)}...\")\n",
    "            \n",
    "            try:\n",
    "                # Convert geo coordinates to pixel coordinates\n",
    "                row, col = src.index(lon, lat)\n",
    "                \n",
    "                # Define window (patch_size x patch_size pixels, centered on location)\n",
    "                half_size = patch_size // 2\n",
    "                window = Window(col - half_size, row - half_size, patch_size, patch_size)\n",
    "                \n",
    "                # Read patch (all 64 bands)\n",
    "                patch = src.read(window=window)\n",
    "                \n",
    "                # Transpose to (patch_size, patch_size, 64)\n",
    "                patch = np.transpose(patch, (1, 2, 0))\n",
    "                \n",
    "                # Handle edge cases (pad if necessary)\n",
    "                if patch.shape != (patch_size, patch_size, 64):\n",
    "                    patch = np.pad(patch, \n",
    "                                  ((0, patch_size - patch.shape[0]),\n",
    "                                   (0, patch_size - patch.shape[1]),\n",
    "                                   (0, 0)),\n",
    "                                  mode='constant', constant_values=0)\n",
    "                \n",
    "                patches.append(patch)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting patch {idx}: {e}\")\n",
    "                # Create zero patch if extraction fails\n",
    "                patches.append(np.zeros((patch_size, patch_size, 64)))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "print(\"Patch extraction function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\n\" + \"=\"*80)\n",
    "print(\"ALPHAEARTH DATA PREPARATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  1. Option_A_RainyAE.csv - Replace indices approach\")\n",
    "print(\"  2. Option_B_RainyAE.csv - Add to current features (RECOMMENDED)\")\n",
    "print(\"  3. Option_C_RainyAE.csv - PCA-reduced approach\")\n",
    "print(\"  4. Option_D_RainyAE.csv - MLP enhancement only\")\n",
    "print(\"  5. pca_alpha_earth.pkl - PCA model for Option C\")\n",
    "print(\"  6. alpha_earth_rainy_2023.csv - Raw AlphaEarth values\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Copy these files to ../data/ directory\")\n",
    "print(\"  2. Modify existing model notebooks to use these files\")\n",
    "print(\"  3. Update data loading and CNN input preparation code\")\n",
    "print(\"  4. Retrain models with AlphaEarth integration\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check file sizes\n",
    "import os\n",
    "\n",
    "files = [\n",
    "    'Option_A_RainyAE.csv',\n",
    "    'Option_B_RainyAE.csv',\n",
    "    'Option_C_RainyAE.csv',\n",
    "    'Option_D_RainyAE.csv'\n",
    "]\n",
    "\n",
    "print(\"\\nOutput Files:\")\n",
    "for f in files:\n",
    "    if os.path.exists(f):\n",
    "        size_mb = os.path.getsize(f) / (1024*1024)\n",
    "        print(f\"  {f}: {size_mb:.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}