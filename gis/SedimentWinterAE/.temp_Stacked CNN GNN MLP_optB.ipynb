{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1f21c33a-355d-40bc-9bf4-0623e0d270be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 26 raster layers for CNN input.\n",
            "  - bui.tif\n",
            "  - ndsi.tif\n",
            "  - savi.tif\n",
            "  - ndbsi.tif\n",
            "  - ui.tif\n",
            "  - ndwi.tif\n",
            "  - ndbi.tif\n",
            "  - awei.tif\n",
            "  - evi.tif\n",
            "  - mndwi.tif\n",
            "  - ndvi.tif\n",
            "  - LULC2020.tif\n",
            "  - LULC2021.tif\n",
            "  - LULC2022.tif\n",
            "  - LULC2019.tif\n",
            "  - LULC2018.tif\n",
            "  - LULC2017.tif\n",
            "  - ClayW.tif\n",
            "  - CdW.tif\n",
            "  - SandW.tif\n",
            "  - SiltW.tif\n",
            "  - AsW.tif\n",
            "  - CrW.tif\n",
            "  - NiW.tif\n",
            "  - PbW.tif\n",
            "  - CuW.tif\n",
            "\n",
            "================================================================================\n",
            "Analyzing Stacked Deep Ensemble for BUFFER_METERS = 500m\n",
            "================================================================================\n",
            "\n",
            "--- Training CNN-MLP Base Model ---\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - loss: 118237.6172 - val_loss: 17236.2461\n",
            "\n",
            "--- Training GNN-MLP Base Model ---\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 29643.0469 - val_loss: 32812.8906\n",
            "\n",
            "--- Training CNN-GNN Base Model ---\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - loss: 23887.0762 - val_loss: 10435.9639\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\n",
            "--- Training Meta-Learner Model ---\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 30562.3320 - val_loss: 38066.4727\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\n",
            " Stacked Deep Ensemble Model Performance (500m):\n",
            "R\u00b2 Test: -4.8315 | RMSE Test: 190.9413\n",
            "\n",
            "--------------------------------------------------\n",
            "Meta-Learner Feature Importance (Permutation-based)\n",
            "--------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Importance of CNN-MLP predictions (R\u00b2 drop): 0.0044\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Importance of GNN-MLP predictions (R\u00b2 drop): 0.0002\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Importance of CNN-GNN predictions (R\u00b2 drop): -0.0015\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Concatenate,\n",
        "    Dropout,\n",
        "    Layer,\n",
        "    Lambda,\n",
        "    GlobalAveragePooling2D,\n",
        "    Reshape,\n",
        "    Multiply\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import tensorflow as tf\n",
        "import gc # Import garbage collector\n",
        "import sys\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "# Define the single buffer size to use\n",
        "BUFFER_METERS = 500\n",
        "\n",
        "# ==================== 1. Load Data ==================== #\n",
        "# NOTE: The data loading logic remains the same.\n",
        "# Replace with your actual data paths if needed\n",
        "orig = pd.read_csv(\"../../data/WinterSeason1.csv\")\n",
        "river_100 = pd.read_csv(\"../data/Samples_100W.csv\")\n",
        "\n",
        "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
        "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
        "\n",
        "# Train-test split\n",
        "train_orig = orig.sample(10, random_state=42)\n",
        "test_orig = orig.drop(train_orig.index)\n",
        "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
        "\n",
        "# ==================== 2. Collect ALL Rasters ==================== #\n",
        "raster_paths = []\n",
        "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
        "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
        "raster_paths += glob.glob(\"../IDWW/*.tif\")\n",
        "\n",
        "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
        "for r in raster_paths:\n",
        "    print(\"  -\", os.path.basename(r))\n",
        "\n",
        "# ==================== 3. Create a Custom Data Generator ==================== #\n",
        "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
        "    \"\"\"\n",
        "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
        "    This function is optimized to be called by the data generator for each batch.\n",
        "    \"\"\"\n",
        "    patches = []\n",
        "    # Loop through each coordinate pair in the batch\n",
        "    for lon, lat in coords:\n",
        "        channels = []\n",
        "        # Loop through each raster file to get a single patch for each raster\n",
        "        for rfile in raster_files:\n",
        "            with rasterio.open(rfile) as src:\n",
        "                try:\n",
        "                    row, col = src.index(lon, lat)\n",
        "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
        "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
        "                    arr = arr.astype(np.float32)\n",
        "\n",
        "                    if np.nanmax(arr) != 0:\n",
        "                        arr /= np.nanmax(arr)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
        "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
        "            channels.append(arr)\n",
        "        patches.append(np.stack(channels, axis=-1))\n",
        "    \n",
        "    return np.array(patches)\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.coords = coords\n",
        "        self.mlp_data = mlp_data\n",
        "        self.gnn_data = gnn_data\n",
        "        self.y = y\n",
        "        self.raster_paths = raster_paths\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.y))\n",
        "        self.buffer_meters = buffer_meters\n",
        "\n",
        "        # Pre-calculate patch size from the first raster\n",
        "        with rasterio.open(raster_paths[0]) as src:\n",
        "            res_x, res_y = src.res\n",
        "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
        "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
        "            self.patch_width = 2 * self.buffer_pixels_x\n",
        "            self.patch_height = 2 * self.buffer_pixels_y\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.y) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        # Get batch indices\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Get batch data\n",
        "        batch_coords = self.coords[batch_indices]\n",
        "        batch_mlp = self.mlp_data[batch_indices]\n",
        "        batch_gnn = self.gnn_data[batch_indices, :]\n",
        "        batch_y = self.y[batch_indices]\n",
        "\n",
        "        # Extract CNN patches for the current batch\n",
        "        batch_cnn = extract_patch_for_generator(\n",
        "            batch_coords,\n",
        "            self.raster_paths,\n",
        "            self.buffer_pixels_x,\n",
        "            self.buffer_pixels_y,\n",
        "            self.patch_width,\n",
        "            self.patch_height\n",
        "        )\n",
        "\n",
        "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
        "\n",
        "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
        "coords_train = train_combined[['Long','Lat']].values\n",
        "coords_test = test_orig[['Long','Lat']].values\n",
        "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
        "gnn_train = np.exp(-dist_mat_train/10)\n",
        "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
        "gnn_test = np.exp(-dist_mat_test_train/10)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
        "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
        "y_train = train_combined['RI'].values\n",
        "y_test = test_orig['RI'].values\n",
        "\n",
        "# ==================== 5. Define Base Models ==================== #\n",
        "def build_cnn_mlp_model(patch_shape, mlp_dim):\n",
        "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
        "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
        "\n",
        "    # CNN branch\n",
        "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_embedding = Flatten()(cnn_branch)\n",
        "\n",
        "    # MLP branch\n",
        "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
        "    mlp_embedding = Dense(32, activation=\"relu\")(mlp_embedding)\n",
        "\n",
        "    # Combine\n",
        "    combined = Concatenate()([cnn_embedding, mlp_embedding])\n",
        "    f = Dense(128, activation=\"relu\")(combined)\n",
        "    output = Dense(1, activation=\"linear\", name=\"cnn_mlp_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[cnn_input, mlp_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def build_gnn_mlp_model(gnn_dim, mlp_dim):\n",
        "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
        "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
        "\n",
        "    # GNN branch\n",
        "    gnn_embedding = Dense(64, activation=\"relu\")(gnn_input)\n",
        "    gnn_embedding = Dense(32, activation=\"relu\")(gnn_embedding)\n",
        "\n",
        "    # MLP branch\n",
        "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
        "    mlp_embedding = Dense(32, activation=\"relu\")(mlp_embedding)\n",
        "\n",
        "    # Combine\n",
        "    combined = Concatenate()([gnn_embedding, mlp_embedding])\n",
        "    f = Dense(64, activation=\"relu\")(combined)\n",
        "    output = Dense(1, activation=\"linear\", name=\"gnn_mlp_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[gnn_input, mlp_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def build_cnn_gnn_model(patch_shape, gnn_dim):\n",
        "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
        "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
        "\n",
        "    # CNN branch\n",
        "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_embedding = Flatten()(cnn_branch)\n",
        "    \n",
        "    # GNN branch\n",
        "    gnn_embedding = Dense(64, activation=\"relu\")(gnn_input)\n",
        "    gnn_embedding = Dense(32, activation=\"relu\")(gnn_embedding)\n",
        "\n",
        "    # Combine\n",
        "    combined = Concatenate()([cnn_embedding, gnn_embedding])\n",
        "    f = Dense(128, activation=\"relu\")(combined)\n",
        "    output = Dense(1, activation=\"linear\", name=\"cnn_gnn_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[cnn_input, gnn_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def build_meta_learner_model():\n",
        "    # Takes predictions from the 3 base models as input\n",
        "    pred1_input = Input(shape=(1,), name=\"pred1_input\")\n",
        "    pred2_input = Input(shape=(1,), name=\"pred2_input\")\n",
        "    pred3_input = Input(shape=(1,), name=\"pred3_input\")\n",
        "\n",
        "    # Concatenate the predictions\n",
        "    combined = Concatenate()([pred1_input, pred2_input, pred3_input])\n",
        "    \n",
        "    # Simple MLP as the meta-learner\n",
        "    f = Dense(32, activation=\"relu\")(combined)\n",
        "    f = Dense(16, activation=\"relu\")(f)\n",
        "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[pred1_input, pred2_input, pred3_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "# ==================== 6. Create Data Generators for Base Models ==================== #\n",
        "# NOTE: We create generators that provide only the necessary inputs for each base model.\n",
        "class CNNDropoutGenerator(DataGenerator):\n",
        "    def __getitem__(self, index):\n",
        "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
        "        return (batch_cnn, batch_mlp), batch_y\n",
        "\n",
        "class GNNDropoutGenerator(DataGenerator):\n",
        "    def __getitem__(self, index):\n",
        "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
        "        return (batch_gnn, batch_mlp), batch_y\n",
        "\n",
        "class MLPDropoutGenerator(DataGenerator):\n",
        "    def __getitem__(self, index):\n",
        "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
        "        return (batch_cnn, batch_gnn), batch_y\n",
        "\n",
        "def get_base_model_predictions(model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size):\n",
        "    num_samples = len(y)\n",
        "    y_pred_list = []\n",
        "    \n",
        "    with rasterio.open(raster_paths[0]) as src:\n",
        "        res_x, res_y = src.res\n",
        "        buffer_pixels_x = int(buffer_meters / res_x)\n",
        "        buffer_pixels_y = int(buffer_meters / res_y)\n",
        "        patch_width = 2 * buffer_pixels_x\n",
        "        patch_height = 2 * buffer_pixels_y\n",
        "\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        batch_coords = coords[i:i+batch_size]\n",
        "        batch_mlp = mlp_data[i:i+batch_size]\n",
        "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
        "        \n",
        "        batch_cnn = extract_patch_for_generator(\n",
        "            batch_coords, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
        "        )\n",
        "        \n",
        "        # Check which inputs the model expects and provide them\n",
        "        input_names = [inp.name for inp in model.inputs]\n",
        "        input_dict = {}\n",
        "        if 'cnn_input' in input_names:\n",
        "            input_dict['cnn_input'] = batch_cnn\n",
        "        if 'mlp_input' in input_names:\n",
        "            input_dict['mlp_input'] = batch_mlp\n",
        "        if 'gnn_input' in input_names:\n",
        "            input_dict['gnn_input'] = batch_gnn\n",
        "            \n",
        "        y_pred_list.append(model.predict(input_dict).flatten())\n",
        "            \n",
        "    return np.concatenate(y_pred_list)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Analyzing Stacked Deep Ensemble for BUFFER_METERS = {BUFFER_METERS}m\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "batch_size = 4\n",
        "gnn_input_dim = len(coords_train)\n",
        "\n",
        "# Calculate CNN patch shape based on the current buffer size\n",
        "with rasterio.open(raster_paths[0]) as src:\n",
        "    res_x, res_y = src.res\n",
        "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
        "    patch_width = 2 * buffer_pixels_x\n",
        "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
        "\n",
        "mlp_input_dim = mlp_train.shape[1]\n",
        "\n",
        "# --- Train Base Models ---\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training CNN-MLP Base Model ---\")\n",
        "cnn_mlp_model = build_cnn_mlp_model(cnn_patch_shape, mlp_input_dim)\n",
        "cnn_mlp_train_gen = CNNDropoutGenerator(\n",
        "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
        "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "cnn_mlp_model.fit(cnn_mlp_train_gen, epochs=1, verbose=1, callbacks=[early_stopping], validation_data=cnn_mlp_train_gen)\n",
        "\n",
        "print(\"\\n--- Training GNN-MLP Base Model ---\")\n",
        "gnn_mlp_model = build_gnn_mlp_model(gnn_input_dim, mlp_input_dim)\n",
        "gnn_mlp_train_gen = GNNDropoutGenerator(\n",
        "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
        "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "gnn_mlp_model.fit(gnn_mlp_train_gen, epochs=1, verbose=1, callbacks=[early_stopping], validation_data=gnn_mlp_train_gen)\n",
        "\n",
        "print(\"\\n--- Training CNN-GNN Base Model ---\")\n",
        "cnn_gnn_model = build_cnn_gnn_model(cnn_patch_shape, gnn_input_dim)\n",
        "cnn_gnn_train_gen = MLPDropoutGenerator(\n",
        "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
        "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "cnn_gnn_model.fit(cnn_gnn_train_gen, epochs=1, verbose=1, callbacks=[early_stopping], validation_data=cnn_gnn_train_gen)\n",
        "\n",
        "# --- Generate predictions for meta-learner ---\n",
        "# Get predictions from base models on training data\n",
        "preds1_train = get_base_model_predictions(cnn_mlp_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds2_train = get_base_model_predictions(gnn_mlp_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds3_train = get_base_model_predictions(cnn_gnn_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
        "\n",
        "meta_train_inputs = (preds1_train.reshape(-1, 1), preds2_train.reshape(-1, 1), preds3_train.reshape(-1, 1))\n",
        "\n",
        "# --- Train Meta-Learner ---\n",
        "print(\"\\n--- Training Meta-Learner Model ---\")\n",
        "meta_model = build_meta_learner_model()\n",
        "meta_model.fit(meta_train_inputs, y_train, epochs=1, verbose=1, callbacks=[early_stopping], validation_split=0.2)\n",
        "\n",
        "# --- Get predictions from base models on test data ---\n",
        "preds1_test = get_base_model_predictions(cnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds2_test = get_base_model_predictions(gnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds3_test = get_base_model_predictions(cnn_gnn_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "\n",
        "meta_test_inputs = (preds1_test.reshape(-1, 1), preds2_test.reshape(-1, 1), preds3_test.reshape(-1, 1))\n",
        "\n",
        "# --- Evaluate with Meta-Learner ---\n",
        "y_pred = meta_model.predict(meta_test_inputs).flatten()\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"\\n Stacked Deep Ensemble Model Performance ({BUFFER_METERS}m):\")\n",
        "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
        "\n",
        "# --- NEW: Feature Importance for Meta-Learner ---\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "print(f\"Meta-Learner Feature Importance (Permutation-based)\")\n",
        "print(\"-\"*50)\n",
        "baseline_r2 = r2_test\n",
        "\n",
        "# Importance for CNN-MLP predictions\n",
        "preds1_test_shuffled = np.copy(preds1_test)\n",
        "np.random.shuffle(preds1_test_shuffled)\n",
        "shuffled_test_inputs = (preds1_test_shuffled.reshape(-1, 1), preds2_test.reshape(-1, 1), preds3_test.reshape(-1, 1))\n",
        "y_pred_shuffled = meta_model.predict(shuffled_test_inputs).flatten()\n",
        "r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "importance_cnn_mlp = baseline_r2 - r2_shuffled\n",
        "print(f\"Importance of CNN-MLP predictions (R\u00b2 drop): {importance_cnn_mlp:.4f}\")\n",
        "\n",
        "# Importance for GNN-MLP predictions\n",
        "preds2_test_shuffled = np.copy(preds2_test)\n",
        "np.random.shuffle(preds2_test_shuffled)\n",
        "shuffled_test_inputs = (preds1_test.reshape(-1, 1), preds2_test_shuffled.reshape(-1, 1), preds3_test.reshape(-1, 1))\n",
        "y_pred_shuffled = meta_model.predict(shuffled_test_inputs).flatten()\n",
        "r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "importance_gnn_mlp = baseline_r2 - r2_shuffled\n",
        "print(f\"Importance of GNN-MLP predictions (R\u00b2 drop): {importance_gnn_mlp:.4f}\")\n",
        "\n",
        "# Importance for CNN-GNN predictions\n",
        "preds3_test_shuffled = np.copy(preds3_test)\n",
        "np.random.shuffle(preds3_test_shuffled)\n",
        "shuffled_test_inputs = (preds1_test.reshape(-1, 1), preds2_test.reshape(-1, 1), preds3_test_shuffled.reshape(-1, 1))\n",
        "y_pred_shuffled = meta_model.predict(shuffled_test_inputs).flatten()\n",
        "r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "importance_cnn_gnn = baseline_r2 - r2_shuffled\n",
        "print(f\"Importance of CNN-GNN predictions (R\u00b2 drop): {importance_cnn_gnn:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f3ce5c72-a495-4f20-a5c9-2293eff669e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 26 raster layers for CNN input.\n",
            " \u00a0- bui.tif\n",
            " \u00a0- ndsi.tif\n",
            " \u00a0- savi.tif\n",
            " \u00a0- ndbsi.tif\n",
            " \u00a0- ui.tif\n",
            " \u00a0- ndwi.tif\n",
            " \u00a0- ndbi.tif\n",
            " \u00a0- awei.tif\n",
            " \u00a0- evi.tif\n",
            " \u00a0- mndwi.tif\n",
            " \u00a0- ndvi.tif\n",
            " \u00a0- LULC2020.tif\n",
            " \u00a0- LULC2021.tif\n",
            " \u00a0- LULC2022.tif\n",
            " \u00a0- LULC2019.tif\n",
            " \u00a0- LULC2018.tif\n",
            " \u00a0- LULC2017.tif\n",
            " \u00a0- ClayW.tif\n",
            " \u00a0- CdW.tif\n",
            " \u00a0- SandW.tif\n",
            " \u00a0- SiltW.tif\n",
            " \u00a0- AsW.tif\n",
            " \u00a0- CrW.tif\n",
            " \u00a0- NiW.tif\n",
            " \u00a0- PbW.tif\n",
            " \u00a0- CuW.tif\n",
            "\n",
            "================================================================================\n",
            "Analyzing Stacked Deep Ensemble for BUFFER_METERS = 500m\n",
            "================================================================================\n",
            "\n",
            "--- Training CNN-MLP Base Model ---\n",
            "Epoch 1/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - loss: 45272.9375 - val_loss: 12972.9746\n",
            "Epoch 2/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - loss: 10761.8857 - val_loss: 7885.7622\n",
            "Epoch 3/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 5899.0371 - val_loss: 5576.6270\n",
            "Epoch 4/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - loss: 5391.0962 - val_loss: 5643.5581\n",
            "Epoch 5/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - loss: 4459.0737 - val_loss: 4029.7935\n",
            "Epoch 6/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 4211.4048 - val_loss: 3370.5918\n",
            "Epoch 7/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 3578.0823 - val_loss: 2921.1260\n",
            "Epoch 8/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - loss: 2918.8901 - val_loss: 4184.7109\n",
            "Epoch 9/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 2827.2500 - val_loss: 1834.8302\n",
            "Epoch 10/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - loss: 1636.8795 - val_loss: 851.6198\n",
            "Epoch 11/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 845.8984 - val_loss: 574.8615\n",
            "Epoch 12/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 524.5718 - val_loss: 446.1048\n",
            "Epoch 13/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 352.3923 - val_loss: 380.7314\n",
            "Epoch 14/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 274.5610 - val_loss: 353.9824\n",
            "Epoch 15/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 221.8882 - val_loss: 327.4709\n",
            "Epoch 16/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 253.9482 - val_loss: 374.0275\n",
            "Epoch 17/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 317.3824 - val_loss: 286.3793\n",
            "Epoch 18/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 192.1074 - val_loss: 223.9114\n",
            "Epoch 19/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - loss: 242.0781 - val_loss: 148.0288\n",
            "Epoch 20/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - loss: 192.8938 - val_loss: 133.0292\n",
            "Epoch 21/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - loss: 123.4655 - val_loss: 130.2103\n",
            "Epoch 22/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 121.6122 - val_loss: 119.4335\n",
            "Epoch 23/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 112.4927 - val_loss: 122.3623\n",
            "Epoch 24/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 148.8101 - val_loss: 133.4840\n",
            "Epoch 25/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - loss: 170.1286 - val_loss: 144.9751\n",
            "Epoch 26/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 152.0720 - val_loss: 104.8738\n",
            "Epoch 27/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - loss: 90.8947 - val_loss: 116.0929\n",
            "Epoch 28/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 94.6740 - val_loss: 97.0808\n",
            "Epoch 29/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 103.4090 - val_loss: 77.9105\n",
            "Epoch 30/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 65.9218 - val_loss: 60.4451\n",
            "Epoch 31/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - loss: 59.8429 - val_loss: 48.2577\n",
            "Epoch 32/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 69.6037 - val_loss: 45.2219\n",
            "Epoch 33/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - loss: 65.4449 - val_loss: 62.3946\n",
            "Epoch 34/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 70.0171 - val_loss: 57.1211\n",
            "Epoch 35/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - loss: 39.4946 - val_loss: 60.9913\n",
            "Epoch 36/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 241ms/step - loss: 59.4534 - val_loss: 53.5383\n",
            "Epoch 37/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 257ms/step - loss: 42.8482 - val_loss: 48.7643\n",
            "Epoch 38/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 245ms/step - loss: 63.2776 - val_loss: 50.4631\n",
            "Epoch 39/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - loss: 57.9046 - val_loss: 50.9290\n",
            "Epoch 40/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - loss: 56.7702 - val_loss: 44.3360\n",
            "Epoch 41/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 67.4254 - val_loss: 43.8707\n",
            "Epoch 42/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 51.3835 - val_loss: 41.9672\n",
            "Epoch 43/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 27.3731 - val_loss: 32.6902\n",
            "Epoch 44/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 39.1821 - val_loss: 33.7948\n",
            "Epoch 45/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - loss: 48.1060 - val_loss: 32.2543\n",
            "Epoch 46/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 43.7918 - val_loss: 36.2500\n",
            "Epoch 47/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 33.2689 - val_loss: 58.8258\n",
            "Epoch 48/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - loss: 70.3205 - val_loss: 92.8575\n",
            "Epoch 49/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 135.3628 - val_loss: 194.4682\n",
            "Epoch 50/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 138.0679 - val_loss: 80.5862\n",
            "Epoch 51/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 94.1365 - val_loss: 55.4167\n",
            "Epoch 52/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 63.7451 - val_loss: 36.8394\n",
            "Epoch 53/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 42.0002 - val_loss: 67.3392\n",
            "Epoch 54/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 246ms/step - loss: 52.6231 - val_loss: 31.7087\n",
            "Epoch 55/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 40.5949 - val_loss: 30.7430\n",
            "Epoch 56/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 70.6406 - val_loss: 35.0532\n",
            "Epoch 57/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 26.8277 - val_loss: 21.9140\n",
            "Epoch 58/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - loss: 27.9476 - val_loss: 44.0518\n",
            "Epoch 59/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 245ms/step - loss: 39.2577 - val_loss: 20.3300\n",
            "Epoch 60/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - loss: 36.1096 - val_loss: 31.8369\n",
            "Epoch 61/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 27.2169 - val_loss: 24.3995\n",
            "Epoch 62/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - loss: 29.3676 - val_loss: 28.0655\n",
            "Epoch 63/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 43.4092 - val_loss: 25.7373\n",
            "Epoch 64/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 31.8982 - val_loss: 70.9950\n",
            "Epoch 65/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - loss: 36.8257 - val_loss: 34.7002\n",
            "Epoch 66/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 30.9867 - val_loss: 17.4183\n",
            "Epoch 67/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 21.0671 - val_loss: 19.5161\n",
            "Epoch 68/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 34.9888 - val_loss: 14.6573\n",
            "Epoch 69/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 18.0067 - val_loss: 44.4097\n",
            "Epoch 70/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 260ms/step - loss: 31.9157 - val_loss: 25.7479\n",
            "Epoch 71/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 23.8252 - val_loss: 63.3194\n",
            "Epoch 72/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 31.3040 - val_loss: 25.0943\n",
            "Epoch 73/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 22.1468 - val_loss: 15.4736\n",
            "Epoch 74/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 21.6947 - val_loss: 24.0798\n",
            "Epoch 75/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - loss: 36.9871 - val_loss: 48.1657\n",
            "Epoch 76/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 44.1354 - val_loss: 21.5632\n",
            "Epoch 77/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 25.8367 - val_loss: 21.8718\n",
            "Epoch 78/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 30.6391 - val_loss: 13.3463\n",
            "Epoch 79/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 26.2038 - val_loss: 36.3675\n",
            "Epoch 80/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 25.0608 - val_loss: 15.3384\n",
            "Epoch 81/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 15.2921 - val_loss: 11.1359\n",
            "Epoch 82/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 16.3368 - val_loss: 25.8927\n",
            "Epoch 83/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 26.1328 - val_loss: 13.9572\n",
            "Epoch 84/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - loss: 14.0240 - val_loss: 11.5574\n",
            "Epoch 85/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 416ms/step - loss: 21.7701 - val_loss: 19.8429\n",
            "Epoch 86/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 429ms/step - loss: 20.8458 - val_loss: 19.8910\n",
            "Epoch 87/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 432ms/step - loss: 23.8617 - val_loss: 16.8816\n",
            "Epoch 88/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 421ms/step - loss: 30.5502 - val_loss: 13.6511\n",
            "Epoch 89/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 409ms/step - loss: 17.0440 - val_loss: 12.1267\n",
            "Epoch 90/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - loss: 21.6634 - val_loss: 15.2592\n",
            "Epoch 91/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 16.7389 - val_loss: 25.6538\n",
            "Epoch 92/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - loss: 16.2393 - val_loss: 17.5143\n",
            "Epoch 93/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - loss: 18.7996 - val_loss: 20.4534\n",
            "Epoch 94/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - loss: 24.3893 - val_loss: 12.2762\n",
            "Epoch 95/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 14.8924 - val_loss: 12.2476\n",
            "Epoch 96/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - loss: 20.7950 - val_loss: 45.3203\n",
            "\n",
            "--- Training GNN-MLP Base Model ---\n",
            "Epoch 1/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 35447.4531 - val_loss: 33234.6211\n",
            "Epoch 2/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - loss: 28576.7969 - val_loss: 27266.2168\n",
            "Epoch 3/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - loss: 26092.3867 - val_loss: 16062.9961\n",
            "Epoch 4/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 11197.3096 - val_loss: 5395.2319\n",
            "Epoch 5/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - loss: 4992.8452 - val_loss: 4532.7651\n",
            "Epoch 6/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - loss: 3794.2368 - val_loss: 3807.1675\n",
            "Epoch 7/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 3803.1279 - val_loss: 3427.6074\n",
            "Epoch 8/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 3929.0159 - val_loss: 2731.2947\n",
            "Epoch 9/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 2195.6267 - val_loss: 2265.7700\n",
            "Epoch 10/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - loss: 1951.4932 - val_loss: 1584.3065\n",
            "Epoch 11/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 1528.1167 - val_loss: 1126.3101\n",
            "Epoch 12/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - loss: 1021.0768 - val_loss: 817.9294\n",
            "Epoch 13/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 849.3369 - val_loss: 680.6710\n",
            "Epoch 14/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 676.9404 - val_loss: 590.6467\n",
            "Epoch 15/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - loss: 585.8885 - val_loss: 535.7215\n",
            "Epoch 16/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 423.3701 - val_loss: 493.9543\n",
            "Epoch 17/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 406.4683 - val_loss: 446.5779\n",
            "Epoch 18/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - loss: 502.5945 - val_loss: 416.8566\n",
            "Epoch 19/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - loss: 403.9300 - val_loss: 375.3341\n",
            "Epoch 20/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - loss: 285.5937 - val_loss: 358.2508\n",
            "Epoch 21/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - loss: 318.3288 - val_loss: 329.0634\n",
            "Epoch 22/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 350.0085 - val_loss: 301.6804\n",
            "Epoch 23/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - loss: 311.9242 - val_loss: 281.2139\n",
            "Epoch 24/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - loss: 247.3053 - val_loss: 270.5157\n",
            "Epoch 25/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 253.0904 - val_loss: 245.1196\n",
            "Epoch 26/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - loss: 246.1266 - val_loss: 221.7984\n",
            "Epoch 27/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - loss: 215.4598 - val_loss: 221.6196\n",
            "Epoch 28/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 198.9766 - val_loss: 206.1510\n",
            "Epoch 29/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 172.7751 - val_loss: 168.9745\n",
            "Epoch 30/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 296ms/step - loss: 141.9121 - val_loss: 174.2359\n",
            "Epoch 31/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 391ms/step - loss: 163.6802 - val_loss: 164.2082\n",
            "Epoch 32/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 449ms/step - loss: 169.9558 - val_loss: 146.2031\n",
            "Epoch 33/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 411ms/step - loss: 154.2390 - val_loss: 147.4954\n",
            "Epoch 34/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 406ms/step - loss: 190.2777 - val_loss: 136.7467\n",
            "Epoch 35/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 401ms/step - loss: 140.8123 - val_loss: 127.7840\n",
            "Epoch 36/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 153.4324 - val_loss: 126.8371\n",
            "Epoch 37/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 191.8130 - val_loss: 110.3055\n",
            "Epoch 38/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - loss: 131.3418 - val_loss: 104.1578\n",
            "Epoch 39/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 93.6311 - val_loss: 98.7417\n",
            "Epoch 40/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 76.8111 - val_loss: 90.5269\n",
            "Epoch 41/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 74.0982 - val_loss: 86.8200\n",
            "Epoch 42/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 117.0050 - val_loss: 90.3806\n",
            "Epoch 43/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 100.1600 - val_loss: 78.1514\n",
            "Epoch 44/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 68.9844 - val_loss: 76.1656\n",
            "Epoch 45/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 73.0581 - val_loss: 70.6423\n",
            "Epoch 46/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 66.0855 - val_loss: 67.6150\n",
            "Epoch 47/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 71.1026 - val_loss: 64.8283\n",
            "Epoch 48/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 57.2262 - val_loss: 60.4126\n",
            "Epoch 49/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 46.2294 - val_loss: 65.7098\n",
            "Epoch 50/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 51.2160 - val_loss: 57.5834\n",
            "Epoch 51/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 40.0444 - val_loss: 60.8595\n",
            "Epoch 52/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 66.2156 - val_loss: 57.7728\n",
            "Epoch 53/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 39.8998 - val_loss: 55.1456\n",
            "Epoch 54/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 52.2744 - val_loss: 57.0662\n",
            "Epoch 55/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 48.5239 - val_loss: 49.8262\n",
            "Epoch 56/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 44.4237 - val_loss: 48.0976\n",
            "Epoch 57/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - loss: 80.9832 - val_loss: 49.6949\n",
            "Epoch 58/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 42.7116 - val_loss: 45.0459\n",
            "Epoch 59/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 35.4694 - val_loss: 42.5168\n",
            "Epoch 60/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 50.2348 - val_loss: 40.7916\n",
            "Epoch 61/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 43.1577 - val_loss: 38.7671\n",
            "Epoch 62/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 41.4270 - val_loss: 38.4799\n",
            "Epoch 63/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - loss: 61.2962 - val_loss: 39.9558\n",
            "Epoch 64/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 31.6803 - val_loss: 44.5332\n",
            "Epoch 65/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 37.1371 - val_loss: 38.1247\n",
            "Epoch 66/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 26.7472 - val_loss: 40.6949\n",
            "Epoch 67/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 39.1972 - val_loss: 34.1534\n",
            "Epoch 68/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 27.9416 - val_loss: 33.4923\n",
            "Epoch 69/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 23.7643 - val_loss: 32.7547\n",
            "Epoch 70/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 27.2225 - val_loss: 46.2175\n",
            "Epoch 71/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 43.4391 - val_loss: 29.9209\n",
            "Epoch 72/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 26.7677 - val_loss: 33.9237\n",
            "Epoch 73/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - loss: 30.1402 - val_loss: 30.3597\n",
            "Epoch 74/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 30.6789 - val_loss: 26.1224\n",
            "Epoch 75/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 21.9904 - val_loss: 29.7072\n",
            "Epoch 76/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 24.9287 - val_loss: 27.3420\n",
            "Epoch 77/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 16.8116 - val_loss: 26.8872\n",
            "Epoch 78/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 32.7954 - val_loss: 26.7684\n",
            "Epoch 79/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 20.7896 - val_loss: 24.7903\n",
            "Epoch 80/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 26.6881 - val_loss: 23.2948\n",
            "Epoch 81/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 41.4724 - val_loss: 22.9372\n",
            "Epoch 82/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 22.8580 - val_loss: 22.4565\n",
            "Epoch 83/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 17.5594 - val_loss: 23.8540\n",
            "Epoch 84/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 27.2155 - val_loss: 20.7758\n",
            "Epoch 85/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 14.8670 - val_loss: 20.7520\n",
            "Epoch 86/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - loss: 24.9427 - val_loss: 23.6526\n",
            "Epoch 87/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - loss: 29.2864 - val_loss: 20.3029\n",
            "Epoch 88/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - loss: 21.2431 - val_loss: 21.3987\n",
            "Epoch 89/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 244ms/step - loss: 21.5714 - val_loss: 15.6150\n",
            "Epoch 90/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 13.4335 - val_loss: 18.7696\n",
            "Epoch 91/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - loss: 16.8910 - val_loss: 18.3947\n",
            "Epoch 92/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - loss: 17.5827 - val_loss: 20.7051\n",
            "Epoch 93/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 19.6790 - val_loss: 15.1344\n",
            "Epoch 94/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 16.6213 - val_loss: 16.0149\n",
            "Epoch 95/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 15.6673 - val_loss: 15.0079\n",
            "Epoch 96/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 20.8592 - val_loss: 16.0177\n",
            "Epoch 97/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 13.4020 - val_loss: 15.5223\n",
            "Epoch 98/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 11.8933 - val_loss: 14.8985\n",
            "Epoch 99/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - loss: 16.3041 - val_loss: 14.7789\n",
            "Epoch 100/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 245ms/step - loss: 12.2066 - val_loss: 14.1414\n",
            "\n",
            "--- Training CNN-GNN Base Model ---\n",
            "Epoch 1/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - loss: 53741.3789 - val_loss: 7160.8916\n",
            "Epoch 2/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - loss: 7898.8213 - val_loss: 7832.2749\n",
            "Epoch 3/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 271ms/step - loss: 6072.8472 - val_loss: 4767.9204\n",
            "Epoch 4/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - loss: 4394.9360 - val_loss: 4333.2861\n",
            "Epoch 5/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 409ms/step - loss: 4836.6899 - val_loss: 4316.2642\n",
            "Epoch 6/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 414ms/step - loss: 4308.9033 - val_loss: 4174.9253\n",
            "Epoch 7/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 397ms/step - loss: 4946.6743 - val_loss: 5173.5054\n",
            "Epoch 8/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 515ms/step - loss: 4088.8684 - val_loss: 3914.3604\n",
            "Epoch 9/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 496ms/step - loss: 3606.6875 - val_loss: 3758.3813\n",
            "Epoch 10/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 444ms/step - loss: 2982.8389 - val_loss: 3359.1113\n",
            "Epoch 11/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 302ms/step - loss: 2849.7324 - val_loss: 3116.2065\n",
            "Epoch 12/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 261ms/step - loss: 3554.1577 - val_loss: 2548.4475\n",
            "Epoch 13/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - loss: 2141.7039 - val_loss: 2900.6592\n",
            "Epoch 14/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 277ms/step - loss: 3077.4482 - val_loss: 2035.9922\n",
            "Epoch 15/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 318ms/step - loss: 2538.3230 - val_loss: 1849.7701\n",
            "Epoch 16/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - loss: 2406.1621 - val_loss: 1927.4740\n",
            "Epoch 17/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 368ms/step - loss: 1910.3157 - val_loss: 2183.7510\n",
            "Epoch 18/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 368ms/step - loss: 1891.4642 - val_loss: 2898.1387\n",
            "Epoch 19/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 601ms/step - loss: 2874.0154 - val_loss: 1333.2118\n",
            "Epoch 20/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 602ms/step - loss: 1282.1584 - val_loss: 1094.3124\n",
            "Epoch 21/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 585ms/step - loss: 1497.1484 - val_loss: 1071.3127\n",
            "Epoch 22/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 547ms/step - loss: 1300.9370 - val_loss: 980.6767\n",
            "Epoch 23/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 630ms/step - loss: 761.2415 - val_loss: 1176.0686\n",
            "Epoch 24/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 677ms/step - loss: 1015.1009 - val_loss: 1133.6926\n",
            "Epoch 25/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 652ms/step - loss: 975.2099 - val_loss: 901.9720\n",
            "Epoch 26/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 621ms/step - loss: 776.8577 - val_loss: 715.8762\n",
            "Epoch 27/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 778ms/step - loss: 746.6421 - val_loss: 667.8718\n",
            "Epoch 28/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 720ms/step - loss: 734.2365 - val_loss: 581.5685\n",
            "Epoch 29/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 613ms/step - loss: 799.9617 - val_loss: 582.6208\n",
            "Epoch 30/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 684ms/step - loss: 518.1290 - val_loss: 570.5179\n",
            "Epoch 31/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 649ms/step - loss: 777.0699 - val_loss: 568.8218\n",
            "Epoch 32/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 563ms/step - loss: 520.6306 - val_loss: 490.9788\n",
            "Epoch 33/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 489ms/step - loss: 446.3946 - val_loss: 564.6238\n",
            "Epoch 34/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 493ms/step - loss: 489.7102 - val_loss: 362.8402\n",
            "Epoch 35/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 477ms/step - loss: 416.6505 - val_loss: 345.1805\n",
            "Epoch 36/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 569ms/step - loss: 418.1936 - val_loss: 368.3694\n",
            "Epoch 37/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 526ms/step - loss: 393.9815 - val_loss: 387.6162\n",
            "Epoch 38/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 464ms/step - loss: 361.0889 - val_loss: 303.7766\n",
            "Epoch 39/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 486ms/step - loss: 270.3314 - val_loss: 322.7065\n",
            "Epoch 40/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 499ms/step - loss: 285.3272 - val_loss: 361.1530\n",
            "Epoch 41/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 435ms/step - loss: 314.0019 - val_loss: 275.9556\n",
            "Epoch 42/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 483ms/step - loss: 295.1257 - val_loss: 306.5865\n",
            "Epoch 43/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 454ms/step - loss: 442.3430 - val_loss: 371.4809\n",
            "Epoch 44/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 438ms/step - loss: 282.7821 - val_loss: 335.5162\n",
            "Epoch 45/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 429ms/step - loss: 468.1953 - val_loss: 233.4810\n",
            "Epoch 46/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 489ms/step - loss: 264.6703 - val_loss: 247.0528\n",
            "Epoch 47/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 489ms/step - loss: 326.4409 - val_loss: 223.5564\n",
            "Epoch 48/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 551ms/step - loss: 223.2967 - val_loss: 195.6446\n",
            "Epoch 49/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 414ms/step - loss: 247.5752 - val_loss: 209.9014\n",
            "Epoch 50/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 431ms/step - loss: 244.2328 - val_loss: 218.7467\n",
            "Epoch 51/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 432ms/step - loss: 186.5005 - val_loss: 200.0711\n",
            "Epoch 52/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 422ms/step - loss: 232.3827 - val_loss: 212.7441\n",
            "Epoch 53/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 460ms/step - loss: 200.5431 - val_loss: 152.8333\n",
            "Epoch 54/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 427ms/step - loss: 253.1768 - val_loss: 175.4140\n",
            "Epoch 55/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 391ms/step - loss: 199.2264 - val_loss: 463.7870\n",
            "Epoch 56/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 464ms/step - loss: 418.0042 - val_loss: 187.8098\n",
            "Epoch 57/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 415ms/step - loss: 227.5327 - val_loss: 199.6516\n",
            "Epoch 58/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 420ms/step - loss: 210.4624 - val_loss: 251.7384\n",
            "Epoch 59/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 388ms/step - loss: 220.3289 - val_loss: 295.5614\n",
            "Epoch 60/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 400ms/step - loss: 199.5843 - val_loss: 132.4465\n",
            "Epoch 61/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 409ms/step - loss: 169.9939 - val_loss: 124.1670\n",
            "Epoch 62/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 545ms/step - loss: 143.0247 - val_loss: 206.4867\n",
            "Epoch 63/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 836ms/step - loss: 226.9692 - val_loss: 181.0589\n",
            "Epoch 64/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 906ms/step - loss: 258.2768 - val_loss: 262.3580\n",
            "Epoch 65/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 789ms/step - loss: 207.5877 - val_loss: 153.0952\n",
            "Epoch 66/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 794ms/step - loss: 138.9141 - val_loss: 105.1066\n",
            "Epoch 67/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 323ms/step - loss: 110.7641 - val_loss: 132.4949\n",
            "Epoch 68/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 317ms/step - loss: 172.5242 - val_loss: 176.7028\n",
            "Epoch 69/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 313ms/step - loss: 172.8383 - val_loss: 108.4308\n",
            "Epoch 70/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 249ms/step - loss: 159.5767 - val_loss: 125.8848\n",
            "Epoch 71/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 122.0320 - val_loss: 114.1956\n",
            "Epoch 72/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 151.6188 - val_loss: 184.3987\n",
            "Epoch 73/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 102.7680 - val_loss: 89.9257\n",
            "Epoch 74/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - loss: 96.6460 - val_loss: 104.8383\n",
            "Epoch 75/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - loss: 111.9922 - val_loss: 96.2237\n",
            "Epoch 76/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 172.1378 - val_loss: 119.9005\n",
            "Epoch 77/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 88.7925 - val_loss: 78.9195\n",
            "Epoch 78/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - loss: 84.6808 - val_loss: 97.3276\n",
            "Epoch 79/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 265ms/step - loss: 97.3775 - val_loss: 356.5804\n",
            "Epoch 80/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 252ms/step - loss: 140.2481 - val_loss: 219.0862\n",
            "Epoch 81/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - loss: 173.8711 - val_loss: 99.5646\n",
            "Epoch 82/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 255ms/step - loss: 107.8443 - val_loss: 92.7792\n",
            "Epoch 83/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 255ms/step - loss: 113.3370 - val_loss: 217.8718\n",
            "Epoch 84/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 264ms/step - loss: 266.9901 - val_loss: 202.1680\n",
            "Epoch 85/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - loss: 239.4552 - val_loss: 187.5927\n",
            "Epoch 86/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - loss: 179.9834 - val_loss: 256.1308\n",
            "Epoch 87/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 297ms/step - loss: 229.2717 - val_loss: 232.0413\n",
            "Epoch 88/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - loss: 236.8717 - val_loss: 135.0674\n",
            "Epoch 89/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - loss: 155.9849 - val_loss: 181.8229\n",
            "Epoch 90/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - loss: 175.8051 - val_loss: 95.0663\n",
            "Epoch 91/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - loss: 190.4474 - val_loss: 160.4586\n",
            "Epoch 92/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 133.1602 - val_loss: 114.8659\n",
            "\n",
            "--- Training Meta-Learner Model ---\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5452.6934 - val_loss: 5607.3765\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4552.6069 - val_loss: 4535.7300\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3623.0398 - val_loss: 3584.3982\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3100.8281 - val_loss: 2753.7090\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2408.3945 - val_loss: 2050.1616\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1614.0806 - val_loss: 1472.5366\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1245.8240 - val_loss: 1007.5283\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 806.1116 - val_loss: 651.8300\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 533.4863 - val_loss: 392.6550\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 349.5748 - val_loss: 215.9080\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 189.9836 - val_loss: 108.4353\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 99.0382 - val_loss: 52.3547\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 51.5025 - val_loss: 32.1811\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.7032 - val_loss: 33.4454\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.9930 - val_loss: 44.5864\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 29.0522 - val_loss: 57.5169\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 42.3266 - val_loss: 67.0511\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 46.7559 - val_loss: 71.4898\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 43.4525 - val_loss: 71.1800\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 40.0054 - val_loss: 67.1006\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 41.9760 - val_loss: 60.2686\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 38.9130 - val_loss: 52.9703\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 32.3577 - val_loss: 46.2148\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 31.6967 - val_loss: 40.7826\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 29.7985 - val_loss: 36.8390\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.6297 - val_loss: 34.2105\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.4295 - val_loss: 32.6029\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.0430 - val_loss: 31.6964\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.2282 - val_loss: 31.2367\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.4623 - val_loss: 31.0399\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21.4255 - val_loss: 30.9848\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.0760 - val_loss: 31.0381\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 29.4290 - val_loss: 31.1350\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.3293 - val_loss: 31.2780\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.5936 - val_loss: 31.5159\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.1769 - val_loss: 31.8033\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 27.4346 - val_loss: 32.0813\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25.4455 - val_loss: 32.2850\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.8416 - val_loss: 32.5016\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 27.2015 - val_loss: 32.5663\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26.1124 - val_loss: 32.6722\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 27.0277 - val_loss: 32.6217\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.5446 - val_loss: 32.6153\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22.8590 - val_loss: 32.5589\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21.8621 - val_loss: 32.5541\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.8228 - val_loss: 32.4275\n",
            "\n",
            " Stacked Deep Ensemble Model Performance (500m):\n",
            "R\u00b2 Test: 0.9685 | RMSE Test: 14.0418\n",
            "MAE Test: 10.9236 | sMAPE Test: 6.2405%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from scipy.spatial import distance_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    r2_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Concatenate,\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import tensorflow as tf\n",
        "import gc # Import garbage collector\n",
        "import sys\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "# --- New Imports for Feature Importance ---\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model # Used to save and load models for a clean pipeline\n",
        "\n",
        "\n",
        "# Define the single buffer size to use\n",
        "BUFFER_METERS = 500\n",
        "\n",
        "# ==================== 1. Load Data ==================== #\n",
        "# NOTE: The data loading logic remains the same.\n",
        "# Replace with your actual data paths if needed\n",
        "orig = pd.read_csv(\"../../data/WinterSeason1.csv\")\n",
        "river_100 = pd.read_csv(\"../data/Samples_100W.csv\")\n",
        "\n",
        "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
        "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
        "\n",
        "# Train-test split\n",
        "train_orig = orig.sample(10, random_state=42)\n",
        "test_orig = orig.drop(train_orig.index)\n",
        "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
        "\n",
        "# ==================== 2. Collect ALL Rasters ==================== #\n",
        "raster_paths = []\n",
        "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
        "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
        "raster_paths += glob.glob(\"../IDWW/*.tif\")\n",
        "\n",
        "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
        "for r in raster_paths:\n",
        "    print(\" \u00a0-\", os.path.basename(r))\n",
        "\n",
        "# ==================== 3. Create a Custom Data Generator ==================== #\n",
        "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height, skip_raster_idx=None):\n",
        "    \"\"\"\n",
        "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
        "    This function is optimized to be called by the data generator for each batch.\n",
        "    \n",
        "    Args:\n",
        "        coords (np.ndarray): Array of (lon, lat) coordinates.\n",
        "        raster_files (list): List of file paths to the raster layers.\n",
        "        buffer_pixels_x (int): Number of pixels for x-dimension of buffer.\n",
        "        buffer_pixels_y (int): Number of pixels for y-dimension of buffer.\n",
        "        patch_width (int): Width of the patch in pixels.\n",
        "        patch_height (int): Height of the patch in pixels.\n",
        "        skip_raster_idx (int, optional): Index of the raster channel to zero out. Used for permutation importance.\n",
        "    \n",
        "    Returns:\n",
        "        np.ndarray: A batch of image patches.\n",
        "    \"\"\"\n",
        "    patches = []\n",
        "    # Loop through each coordinate pair in the batch\n",
        "    for lon, lat in coords:\n",
        "        channels = []\n",
        "        # Loop through each raster file to get a single patch for each raster\n",
        "        for i, rfile in enumerate(raster_files):\n",
        "            # Check if this raster channel should be zeroed out\n",
        "            if i == skip_raster_idx:\n",
        "                arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
        "            else:\n",
        "                try:\n",
        "                    with rasterio.open(rfile) as src:\n",
        "                        row, col = src.index(lon, lat)\n",
        "                        win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
        "                        arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
        "                        arr = arr.astype(np.float32)\n",
        "\n",
        "                        # Normalize the array if it has non-zero values\n",
        "                        if np.nanmax(arr) != 0:\n",
        "                            arr /= np.nanmax(arr)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
        "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
        "            channels.append(arr)\n",
        "        patches.append(np.stack(channels, axis=-1))\n",
        "    \n",
        "    return np.array(patches)\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.coords = coords\n",
        "        self.mlp_data = mlp_data\n",
        "        self.gnn_data = gnn_data\n",
        "        self.y = y\n",
        "        self.raster_paths = raster_paths\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.y))\n",
        "        self.buffer_meters = buffer_meters\n",
        "        \n",
        "        # Pre-calculate patch size from the first raster\n",
        "        with rasterio.open(raster_paths[0]) as src:\n",
        "            res_x, res_y = src.res\n",
        "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
        "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
        "            self.patch_width = 2 * self.buffer_pixels_x\n",
        "            self.patch_height = 2 * self.buffer_pixels_y\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.y) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        # Get batch indices\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Get batch data\n",
        "        batch_coords = self.coords[batch_indices]\n",
        "        batch_mlp = self.mlp_data[batch_indices]\n",
        "        batch_gnn = self.gnn_data[batch_indices, :]\n",
        "        batch_y = self.y[batch_indices]\n",
        "\n",
        "        # Extract CNN patches for the current batch\n",
        "        batch_cnn = extract_patch_for_generator(\n",
        "            batch_coords,\n",
        "            self.raster_paths,\n",
        "            self.buffer_pixels_x,\n",
        "            self.buffer_pixels_y,\n",
        "            self.patch_width,\n",
        "            self.patch_height\n",
        "        )\n",
        "\n",
        "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
        "\n",
        "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
        "coords_train = train_combined[['Long','Lat']].values\n",
        "coords_test = test_orig[['Long','Lat']].values\n",
        "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
        "gnn_train = np.exp(-dist_mat_train/10)\n",
        "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
        "gnn_test = np.exp(-dist_mat_test_train/10)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
        "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
        "y_train = train_combined['RI'].values\n",
        "y_test = test_orig['RI'].values\n",
        "\n",
        "# ==================== 5. Define Base Models ==================== #\n",
        "def build_cnn_mlp_model(patch_shape, mlp_dim):\n",
        "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
        "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
        "\n",
        "    # CNN branch\n",
        "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_embedding = Flatten()(cnn_branch)\n",
        "\n",
        "    # MLP branch\n",
        "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
        "    mlp_embedding = Dense(32, activation=\"relu\")(mlp_embedding)\n",
        "\n",
        "    # Combine\n",
        "    combined = Concatenate()([cnn_embedding, mlp_embedding])\n",
        "    f = Dense(128, activation=\"relu\")(combined)\n",
        "    output = Dense(1, activation=\"linear\", name=\"cnn_mlp_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[cnn_input, mlp_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def build_gnn_mlp_model(gnn_dim, mlp_dim):\n",
        "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
        "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
        "\n",
        "    # GNN branch\n",
        "    gnn_embedding = Dense(64, activation=\"relu\")(gnn_input)\n",
        "    gnn_embedding = Dense(32, activation=\"relu\")(gnn_embedding)\n",
        "\n",
        "    # MLP branch\n",
        "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
        "    mlp_embedding = Dense(32, activation=\"relu\")(mlp_embedding)\n",
        "\n",
        "    # Combine\n",
        "    combined = Concatenate()([gnn_embedding, mlp_embedding])\n",
        "    f = Dense(64, activation=\"relu\")(combined)\n",
        "    output = Dense(1, activation=\"linear\", name=\"gnn_mlp_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[gnn_input, mlp_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def build_cnn_gnn_model(patch_shape, gnn_dim):\n",
        "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
        "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
        "\n",
        "    # CNN branch\n",
        "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
        "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
        "    cnn_embedding = Flatten()(cnn_branch)\n",
        "    \n",
        "    # GNN branch\n",
        "    gnn_embedding = Dense(64, activation=\"relu\")(gnn_input)\n",
        "    gnn_embedding = Dense(32, activation=\"relu\")(gnn_embedding)\n",
        "\n",
        "    # Combine\n",
        "    combined = Concatenate()([cnn_embedding, gnn_embedding])\n",
        "    f = Dense(128, activation=\"relu\")(combined)\n",
        "    output = Dense(1, activation=\"linear\", name=\"cnn_gnn_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[cnn_input, gnn_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "def build_meta_learner_model():\n",
        "    # Takes predictions from the 3 base models as input\n",
        "    pred1_input = Input(shape=(1,), name=\"pred1_input\")\n",
        "    pred2_input = Input(shape=(1,), name=\"pred2_input\")\n",
        "    pred3_input = Input(shape=(1,), name=\"pred3_input\")\n",
        "\n",
        "    # Concatenate the predictions\n",
        "    combined = Concatenate()([pred1_input, pred2_input, pred3_input])\n",
        "    \n",
        "    # Simple MLP as the meta-learner\n",
        "    f = Dense(32, activation=\"relu\")(combined)\n",
        "    f = Dense(16, activation=\"relu\")(f)\n",
        "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
        "    \n",
        "    model = Model(inputs=[pred1_input, pred2_input, pred3_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "# ==================== 6. Create Data Generators for Base Models ==================== #\n",
        "# NOTE: We create generators that provide only the necessary inputs for each base model.\n",
        "class CNNDropoutGenerator(DataGenerator):\n",
        "    def __getitem__(self, index):\n",
        "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
        "        return (batch_cnn, batch_mlp), batch_y\n",
        "\n",
        "class GNNDropoutGenerator(DataGenerator):\n",
        "    def __getitem__(self, index):\n",
        "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
        "        return (batch_gnn, batch_mlp), batch_y\n",
        "\n",
        "class MLPDropoutGenerator(DataGenerator):\n",
        "    def __getitem__(self, index):\n",
        "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
        "        return (batch_cnn, batch_gnn), batch_y\n",
        "\n",
        "def get_base_model_predictions(model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size, skip_raster_idx=None):\n",
        "    \"\"\"\n",
        "    Generates predictions from a base model using a generator-like approach.\n",
        "    Now includes an option to skip a raster channel for permutation importance.\n",
        "    \"\"\"\n",
        "    num_samples = len(y)\n",
        "    y_pred_list = []\n",
        "    \n",
        "    # Re-calculate these values locally to ensure they are available\n",
        "    with rasterio.open(raster_paths[0]) as src:\n",
        "        res_x, res_y = src.res\n",
        "        buffer_pixels_x = int(buffer_meters / res_x)\n",
        "        buffer_pixels_y = int(buffer_meters / res_y)\n",
        "        patch_width = 2 * buffer_pixels_x\n",
        "        patch_height = 2 * buffer_pixels_y\n",
        "\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        batch_coords = coords[i:i+batch_size]\n",
        "        batch_mlp = mlp_data[i:i+batch_size]\n",
        "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
        "        \n",
        "        batch_cnn = extract_patch_for_generator(\n",
        "            batch_coords, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height, skip_raster_idx=skip_raster_idx\n",
        "        )\n",
        "        \n",
        "        input_names = [inp.name for inp in model.inputs]\n",
        "        input_dict = {}\n",
        "        if 'cnn_input' in input_names:\n",
        "            input_dict['cnn_input'] = batch_cnn\n",
        "        if 'mlp_input' in input_names:\n",
        "            input_dict['mlp_input'] = batch_mlp\n",
        "        if 'gnn_input' in input_names:\n",
        "            input_dict['gnn_input'] = batch_gnn\n",
        "            \n",
        "        y_pred_list.append(model.predict(input_dict, verbose=0).flatten())\n",
        "            \n",
        "    return np.concatenate(y_pred_list)\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the Symmetric Mean Absolute Percentage Error (sMAPE).\n",
        "    \"\"\"\n",
        "    numerator = np.abs(y_pred - y_true)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    return np.mean(numerator / denominator) * 100\n",
        "\n",
        "def get_full_model_predictions(base_models, meta_model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size):\n",
        "    \"\"\"\n",
        "    A helper function to get predictions from the full stacked ensemble model.\n",
        "    \"\"\"\n",
        "    preds1_test = get_base_model_predictions(base_models['cnn_mlp'], coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size)\n",
        "    preds2_test = get_base_model_predictions(base_models['gnn_mlp'], coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size)\n",
        "    preds3_test = get_base_model_predictions(base_models['cnn_gnn'], coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size)\n",
        "    \n",
        "    meta_test_inputs = (preds1_test.reshape(-1, 1), preds2_test.reshape(-1, 1), preds3_test.reshape(-1, 1))\n",
        "    \n",
        "    return meta_model.predict(meta_test_inputs, verbose=0).flatten()\n",
        "\n",
        "# ==================== NEW: Global Variables for LIME ====================\n",
        "# These must be defined before the LIME wrapper function is defined.\n",
        "with rasterio.open(raster_paths[0]) as src:\n",
        "    res_x, res_y = src.res\n",
        "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
        "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
        "    patch_width = 2 * buffer_pixels_x\n",
        "    patch_height = 2 * buffer_pixels_y\n",
        "    cnn_patch_shape = (patch_width, patch_height, len(raster_paths))\n",
        "mlp_input_dim = mlp_train.shape[1]\n",
        "\n",
        "# LIME requires a single, flat input. We'll explain the MLP features.\n",
        "# A wrapper function to handle the complex model prediction for LIME\n",
        "def predict_fn_for_lime(lime_data, sample_idx=0):\n",
        "    \"\"\"\n",
        "    A wrapper function that takes LIME's perturbed data, reconstructs the\n",
        "    inputs for the full model, and returns a prediction.\n",
        "    It holds CNN and GNN inputs constant for a single sample while LIME perturbs MLP features.\n",
        "    \"\"\"\n",
        "    # Create the full data inputs for the model for each LIME perturbation\n",
        "    # We use a fixed CNN and GNN input, only varying the MLP features\n",
        "    num_samples = lime_data.shape[0]\n",
        "    \n",
        "    # Get a single CNN and GNN input from the test set to use for all perturbations\n",
        "    single_cnn_patch = extract_patch_for_generator(coords_test[sample_idx:sample_idx+1], raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height)\n",
        "    single_gnn_input = gnn_test[sample_idx:sample_idx+1]\n",
        "\n",
        "    # Replicate the fixed inputs to match the number of perturbations\n",
        "    cnn_input_batch = np.tile(single_cnn_patch, (num_samples, 1, 1, 1))\n",
        "    gnn_input_batch = np.tile(single_gnn_input, (num_samples, 1))\n",
        "    \n",
        "    # Predict with base models\n",
        "    preds1 = cnn_mlp_model.predict({'cnn_input': cnn_input_batch, 'mlp_input': lime_data}, verbose=0)\n",
        "    preds2 = gnn_mlp_model.predict({'gnn_input': gnn_input_batch, 'mlp_input': lime_data}, verbose=0)\n",
        "    preds3 = cnn_gnn_model.predict({'cnn_input': cnn_input_batch, 'gnn_input': gnn_input_batch}, verbose=0)\n",
        "    \n",
        "    meta_inputs = (preds1, preds2, preds3)\n",
        "    final_pred = meta_model.predict(meta_inputs, verbose=0)\n",
        "    return final_pred.flatten()\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Analyzing Stacked Deep Ensemble for BUFFER_METERS = {BUFFER_METERS}m\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "batch_size = 4\n",
        "gnn_input_dim = len(coords_train)\n",
        "\n",
        "# --- Train Base Models ---\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training CNN-MLP Base Model ---\")\n",
        "cnn_mlp_model = build_cnn_mlp_model(cnn_patch_shape, mlp_input_dim)\n",
        "cnn_mlp_train_gen = CNNDropoutGenerator(\n",
        "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
        "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "cnn_mlp_model.fit(cnn_mlp_train_gen, epochs=100, verbose=1, callbacks=[early_stopping], validation_data=cnn_mlp_train_gen)\n",
        "\n",
        "print(\"\\n--- Training GNN-MLP Base Model ---\")\n",
        "gnn_mlp_model = build_gnn_mlp_model(gnn_input_dim, mlp_input_dim)\n",
        "gnn_mlp_train_gen = GNNDropoutGenerator(\n",
        "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
        "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "gnn_mlp_model.fit(gnn_mlp_train_gen, epochs=100, verbose=1, callbacks=[early_stopping], validation_data=gnn_mlp_train_gen)\n",
        "\n",
        "print(\"\\n--- Training CNN-GNN Base Model ---\")\n",
        "cnn_gnn_model = build_cnn_gnn_model(cnn_patch_shape, gnn_input_dim)\n",
        "cnn_gnn_train_gen = MLPDropoutGenerator(\n",
        "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
        "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "cnn_gnn_model.fit(cnn_gnn_train_gen, epochs=100, verbose=1, callbacks=[early_stopping], validation_data=cnn_gnn_train_gen)\n",
        "\n",
        "# --- Generate predictions for meta-learner ---\n",
        "preds1_train = get_base_model_predictions(cnn_mlp_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds2_train = get_base_model_predictions(gnn_mlp_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds3_train = get_base_model_predictions(cnn_gnn_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
        "meta_train_inputs = (preds1_train.reshape(-1, 1), preds2_train.reshape(-1, 1), preds3_train.reshape(-1, 1))\n",
        "\n",
        "# --- Train Meta-Learner ---\n",
        "print(\"\\n--- Training Meta-Learner Model ---\")\n",
        "meta_model = build_meta_learner_model()\n",
        "meta_model.fit(meta_train_inputs, y_train, epochs=100, verbose=1, callbacks=[early_stopping], validation_split=0.2)\n",
        "\n",
        "# Save models to disk to ensure they are available for LIME explainer\n",
        "# This is a robust practice to avoid generator/thread issues\n",
        "cnn_mlp_model.save('cnn_mlp_model.keras')\n",
        "gnn_mlp_model.save('gnn_mlp_model.keras')\n",
        "cnn_gnn_model.save('cnn_gnn_model.keras')\n",
        "meta_model.save('meta_model.keras')\n",
        "\n",
        "del cnn_mlp_model, gnn_mlp_model, cnn_gnn_model, meta_model\n",
        "gc.collect()\n",
        "\n",
        "# Reload the models for a clean evaluation environment\n",
        "cnn_mlp_model = load_model('cnn_mlp_model.keras')\n",
        "gnn_mlp_model = load_model('gnn_mlp_model.keras')\n",
        "cnn_gnn_model = load_model('cnn_gnn_model.keras')\n",
        "meta_model = load_model('meta_model.keras')\n",
        "\n",
        "base_models = {'cnn_mlp': cnn_mlp_model, 'gnn_mlp': gnn_mlp_model, 'cnn_gnn': cnn_gnn_model}\n",
        "\n",
        "# --- Evaluate with Meta-Learner ---\n",
        "y_pred = get_full_model_predictions(base_models, meta_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "smape_test = smape(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n Stacked Deep Ensemble Model Performance ({BUFFER_METERS}m):\")\n",
        "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
        "print(f\"MAE Test: {mae_test:.4f} | sMAPE Test: {smape_test:.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AlphaEarth Integration Enabled\n",
        "\n",
        "This notebook has been enhanced with AlphaEarth satellite embeddings.\n",
        "\n",
        "## Integration Options:\n",
        "- **Option A**: Replace indices with AlphaEarth (64 bands)\n",
        "- **Option B**: Add AlphaEarth to features (RECOMMENDED)\n",
        "- **Option C**: PCA-reduced AlphaEarth (20 components)\n",
        "- **Option D**: MLP enhancement only\n",
        "\n",
        "Expected improvement: +0.5% to +0.8% in R\u00b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== ALPHAEARTH CONFIGURATION ====================",
        "import pandas as pd",
        "import numpy as np",
        "import os",
        "",
        "# Select which AlphaEarth option to use",
        "ALPHA_EARTH_OPTION = 'B'  # Options: A, B (recommended), C, D",
        "USE_ALPHA_EARTH = True",
        "",
        "# Paths to AlphaEarth data files (created by 00_AlphaEarth_Data_Preparation.ipynb)",
        "option_file = f'Option_{ALPHA_EARTH_OPTION}_RainyAE.csv'  # or WinterAE",
        "",
        "# Load AlphaEarth data",
        "if os.path.exists(option_file):",
        "    ae_data = pd.read_csv(option_file)",
        "    print(f'Loaded AlphaEarth Option {ALPHA_EARTH_OPTION}')",
        "    print(f'Shape: {ae_data.shape}')",
        "else:",
        "    print(f'WARNING: {option_file} not found')",
        "    print('Please run 00_AlphaEarth_Data_Preparation.ipynb first')",
        "    USE_ALPHA_EARTH = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a5b3205d-9013-4492-b6d2-0f08679068bd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Feature Importance (Permutation-based & LIME)\n",
            "================================================================================\n",
            "\n",
            "--- Permutation Importance for Ensemble Inputs ---\n",
            "Importance of CNN-MLP predictions (R\u00b2 drop): 0.3140\n",
            "Importance of GNN-MLP predictions (R\u00b2 drop): 0.0532\n",
            "Importance of CNN-GNN predictions (R\u00b2 drop): 0.7711\n",
            "\n",
            "--- Permutation Importance for Original Features ---\n",
            "Importance of MLP feature 'hydro_dist_brick' (R\u00b2 drop): 0.0000\n",
            "Importance of MLP feature 'num_brick_field' (R\u00b2 drop): -0.0043\n",
            "Importance of MLP feature 'hydro_dist_ind' (R\u00b2 drop): -0.0000\n",
            "Importance of MLP feature 'num_industry' (R\u00b2 drop): 0.0079\n",
            "Importance of MLP feature 'CrW' (R\u00b2 drop): -0.0002\n",
            "Importance of MLP feature 'NiW' (R\u00b2 drop): 0.0059\n",
            "Importance of MLP feature 'CuW' (R\u00b2 drop): 0.0070\n",
            "Importance of MLP feature 'AsW' (R\u00b2 drop): 0.0000\n",
            "Importance of MLP feature 'CdW' (R\u00b2 drop): -0.0078\n",
            "Importance of MLP feature 'PbW' (R\u00b2 drop): -0.0038\n",
            "Importance of MLP feature 'MW' (R\u00b2 drop): 0.0069\n",
            "Importance of MLP feature 'SandW' (R\u00b2 drop): 0.0093\n",
            "Importance of MLP feature 'SiltW' (R\u00b2 drop): 0.0472\n",
            "Importance of MLP feature 'ClayW' (R\u00b2 drop): -0.0041\n",
            "Importance of MLP feature 'FeW' (R\u00b2 drop): 0.0057\n",
            "\n",
            "--- Permutation Importance for Raster Layers ---\n",
            "Importance of Raster 'bui.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'ndsi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'savi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'ndbsi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'ui.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'ndwi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'ndbi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'awei.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'evi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'mndwi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'ndvi.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'LULC2020.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'LULC2021.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'LULC2022.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'LULC2019.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'LULC2018.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'LULC2017.tif' (R\u00b2 drop): 0.0000\n",
            "Importance of Raster 'ClayW.tif' (R\u00b2 drop): -0.0024\n",
            "Importance of Raster 'CdW.tif' (R\u00b2 drop): 0.0289\n",
            "Importance of Raster 'SandW.tif' (R\u00b2 drop): 0.0649\n",
            "Importance of Raster 'SiltW.tif' (R\u00b2 drop): 0.0928\n",
            "Importance of Raster 'AsW.tif' (R\u00b2 drop): 61.7264\n",
            "Importance of Raster 'CrW.tif' (R\u00b2 drop): 0.0727\n",
            "Importance of Raster 'NiW.tif' (R\u00b2 drop): 0.1752\n",
            "Importance of Raster 'PbW.tif' (R\u00b2 drop): 0.1250\n",
            "Importance of Raster 'CuW.tif' (R\u00b2 drop): 0.1597\n",
            "\n",
            "--- LIME Feature Importance (Top 10) ---\n",
            "Explaining prediction for sample index 1:\n",
            "Top 10 features for this prediction:\n",
            " - PbW: 12.0233\n",
            " - FeW: 9.6090\n",
            " - SiltW: -6.5870\n",
            " - CuW: 5.6086\n",
            " - NiW: 4.3851\n",
            " - CdW: 4.3579\n",
            " - ClayW: 4.3112\n",
            " - num_industry: -0.9770\n",
            " - MW: 0.9272\n",
            " - AsW: -0.9075\n",
            " - num_brick_field: 0.7721\n",
            " - CrW: 0.5454\n",
            " - SandW: 0.2407\n",
            " - hydro_dist_brick: -0.1774\n",
            " - hydro_dist_ind: 0.0191\n"
          ]
        }
      ],
      "source": [
        "# ==================== NEW: Feature Importance Analysis ==================== #\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Feature Importance (Permutation-based & LIME)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ----------------- 1. Permutation-based Feature Importance -----------------\n",
        "# Permutation importance for the final meta-learner predictions\n",
        "print(\"\\n--- Permutation Importance for Ensemble Inputs ---\")\n",
        "baseline_r2 = r2_test\n",
        "\n",
        "# Importance of CNN-MLP predictions\n",
        "preds1_test = get_base_model_predictions(cnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds2_test = get_base_model_predictions(gnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds3_test = get_base_model_predictions(cnn_gnn_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "preds1_test_shuffled = np.copy(preds1_test)\n",
        "np.random.shuffle(preds1_test_shuffled)\n",
        "shuffled_test_inputs = (preds1_test_shuffled.reshape(-1, 1), preds2_test.reshape(-1, 1), preds3_test.reshape(-1, 1))\n",
        "y_pred_shuffled = meta_model.predict(shuffled_test_inputs, verbose=0).flatten()\n",
        "r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "importance_cnn_mlp = baseline_r2 - r2_shuffled\n",
        "print(f\"Importance of CNN-MLP predictions (R\u00b2 drop): {importance_cnn_mlp:.4f}\")\n",
        "\n",
        "# Importance of GNN-MLP predictions\n",
        "preds2_test_shuffled = np.copy(preds2_test)\n",
        "np.random.shuffle(preds2_test_shuffled)\n",
        "shuffled_test_inputs = (preds1_test.reshape(-1, 1), preds2_test_shuffled.reshape(-1, 1), preds3_test.reshape(-1, 1))\n",
        "y_pred_shuffled = meta_model.predict(shuffled_test_inputs, verbose=0).flatten()\n",
        "r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "importance_gnn_mlp = baseline_r2 - r2_shuffled\n",
        "print(f\"Importance of GNN-MLP predictions (R\u00b2 drop): {importance_gnn_mlp:.4f}\")\n",
        "\n",
        "# Importance of CNN-GNN predictions\n",
        "preds3_test_shuffled = np.copy(preds3_test)\n",
        "np.random.shuffle(preds3_test_shuffled)\n",
        "shuffled_test_inputs = (preds1_test.reshape(-1, 1), preds2_test.reshape(-1, 1), preds3_test_shuffled.reshape(-1, 1))\n",
        "y_pred_shuffled = meta_model.predict(shuffled_test_inputs, verbose=0).flatten()\n",
        "r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "importance_cnn_gnn = baseline_r2 - r2_shuffled\n",
        "print(f\"Importance of CNN-GNN predictions (R\u00b2 drop): {importance_cnn_gnn:.4f}\")\n",
        "\n",
        "# Permutation importance for original features (MLP and Rasters)\n",
        "print(\"\\n--- Permutation Importance for Original Features ---\")\n",
        "\n",
        "# MLP Feature Importance\n",
        "mlp_importance = {}\n",
        "mlp_test_copy = mlp_test.copy()\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    mlp_test_shuffled = mlp_test_copy.copy()\n",
        "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
        "    \n",
        "    # Calculate predictions with the shuffled feature\n",
        "    preds1_test_shuffled = get_base_model_predictions(cnn_mlp_model, coords_test, mlp_test_shuffled, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "    preds2_test_shuffled = get_base_model_predictions(gnn_mlp_model, coords_test, mlp_test_shuffled, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "    preds3_test_shuffled = get_base_model_predictions(cnn_gnn_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "\n",
        "    meta_test_inputs_shuffled = (preds1_test_shuffled.reshape(-1, 1), preds2_test_shuffled.reshape(-1, 1), preds3_test_shuffled.reshape(-1, 1))\n",
        "    y_pred_shuffled = meta_model.predict(meta_test_inputs_shuffled, verbose=0).flatten()\n",
        "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "    importance = baseline_r2 - r2_shuffled\n",
        "    mlp_importance[col] = importance\n",
        "    print(f\"Importance of MLP feature '{col}' (R\u00b2 drop): {importance:.4f}\")\n",
        "\n",
        "# Raster Layer Importance (CNN)\n",
        "raster_importance = {}\n",
        "print(\"\\n--- Permutation Importance for Raster Layers ---\")\n",
        "for i, r_path in enumerate(raster_paths):\n",
        "    # Calculate predictions by zeroing out one raster channel\n",
        "    preds1_test_shuffled = get_base_model_predictions(cnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size, skip_raster_idx=i)\n",
        "    preds2_test_shuffled = get_base_model_predictions(gnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
        "    preds3_test_shuffled = get_base_model_predictions(cnn_gnn_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size, skip_raster_idx=i)\n",
        "    \n",
        "    meta_test_inputs_shuffled = (preds1_test_shuffled.reshape(-1, 1), preds2_test_shuffled.reshape(-1, 1), preds3_test_shuffled.reshape(-1, 1))\n",
        "    y_pred_shuffled = meta_model.predict(meta_test_inputs_shuffled, verbose=0).flatten()\n",
        "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
        "    importance = baseline_r2 - r2_shuffled\n",
        "    raster_name = os.path.basename(r_path)\n",
        "    raster_importance[raster_name] = importance\n",
        "    print(f\"Importance of Raster '{raster_name}' (R\u00b2 drop): {importance:.4f}\")\n",
        "\n",
        "# ----------------- 2. LIME Feature Importance (Top 10) -----------------\n",
        "print(\"\\n--- LIME Feature Importance (Top 10) ---\")\n",
        "\n",
        "# Prepare data and explainer for LIME\n",
        "# The feature names are the numeric columns from the MLP branch\n",
        "feature_names = list(numeric_cols)\n",
        "# The data for the explainer is the MLP test data\n",
        "lime_data = mlp_test\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=lime_data,\n",
        "    feature_names=feature_names,\n",
        "    class_names=['RI'],\n",
        "    mode='regression',\n",
        "    discretize_continuous=False\n",
        ")\n",
        "\n",
        "# Explain a single random sample from the test set\n",
        "random_idx = np.random.randint(0, len(y_test))\n",
        "print(f\"Explaining prediction for sample index {random_idx}:\")\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=lime_data[random_idx],\n",
        "    predict_fn=predict_fn_for_lime,\n",
        "    num_features=20\n",
        ")\n",
        "\n",
        "# Print the top 10 features and their importance\n",
        "print(\"Top 10 features for this prediction:\")\n",
        "for feature, weight in exp.as_list():\n",
        "    print(f\" - {feature}: {weight:.4f}\")\n",
        "\n",
        "# To visualize the explanation (optional, requires a display)\n",
        "# exp.show_in_notebook(show_table=True, show_all=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "751eb3eb-c9ec-4dea-9aed-cd5611beb3a9",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "alphaearth_integrated": true,
    "season": "winter"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}