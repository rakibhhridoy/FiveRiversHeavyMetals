{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4444d9-7637-43c0-97b3-2aff676b1418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "================================================================================\n",
      "Starting 5-Fold Cross-Validation...\n",
      "================================================================================\n",
      "Models will be saved in: 'models/dual_attention'\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 337ms/step - loss: 27521.2363 - val_loss: 15398.6846\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - loss: 8630.9287 - val_loss: 7040.1797\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - loss: 7361.0723 - val_loss: 8337.1611\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - loss: 8532.2197 - val_loss: 5890.3105\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 398ms/step - loss: 6143.8862 - val_loss: 5952.3257\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - loss: 6766.3140 - val_loss: 5793.5537\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 627ms/step - loss: 7590.5967 - val_loss: 5165.1592\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 535ms/step - loss: 5552.4453 - val_loss: 4831.8608\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - loss: 4919.3574 - val_loss: 5756.2866\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 395ms/step - loss: 8308.8604 - val_loss: 6630.1226\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 402ms/step - loss: 4825.8433 - val_loss: 3472.6414\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 444ms/step - loss: 5151.6826 - val_loss: 2959.6030\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 445ms/step - loss: 3396.7163 - val_loss: 2627.2695\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 399ms/step - loss: 2592.2878 - val_loss: 1708.9320\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - loss: 1662.7053 - val_loss: 1485.0623\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 437ms/step - loss: 1658.7474 - val_loss: 954.3014\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - loss: 1481.1758 - val_loss: 605.1960\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - loss: 946.1177 - val_loss: 956.3039\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 441ms/step - loss: 1707.0813 - val_loss: 604.1512\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 449ms/step - loss: 860.1598 - val_loss: 743.9929\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - loss: 1182.7731 - val_loss: 325.3651\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 390ms/step - loss: 724.5744 - val_loss: 298.8735\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - loss: 1163.5121 - val_loss: 288.0251\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - loss: 836.4406 - val_loss: 279.1098\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - loss: 795.4453 - val_loss: 348.3276\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403ms/step - loss: 524.2639 - val_loss: 389.7364\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - loss: 827.6889 - val_loss: 242.1667\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 463ms/step - loss: 1162.6200 - val_loss: 221.7820\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - loss: 642.0093 - val_loss: 344.5591\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 383ms/step - loss: 846.2926 - val_loss: 229.9010\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 264ms/step - loss: 763.7573 - val_loss: 391.9127\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 284ms/step - loss: 835.6476 - val_loss: 246.7491\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 389ms/step - loss: 588.1483 - val_loss: 191.3257\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - loss: 863.7929 - val_loss: 264.6208\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - loss: 711.5866 - val_loss: 835.0653\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - loss: 815.0854 - val_loss: 286.7114\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - loss: 391.9786 - val_loss: 448.1925\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 391ms/step - loss: 867.3107 - val_loss: 959.3057\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - loss: 1144.3037 - val_loss: 397.4696\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - loss: 552.9095 - val_loss: 462.8556\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - loss: 523.7907 - val_loss: 266.6606\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - loss: 841.7007 - val_loss: 263.5584\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 443ms/step - loss: 706.6425 - val_loss: 805.7811\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step\n",
      "Validation Metrics:\n",
      "R²: 0.9608\n",
      "MAE: 10.3815\n",
      "RMSE: 13.5515\n",
      "SMAPE: 5.9086%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R²: 0.8574\n",
      "MAE: 24.7233\n",
      "RMSE: 29.8539\n",
      "SMAPE: 12.1617%\n",
      "Model for Fold 1 saved.\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 707ms/step - loss: 32878.1680 - val_loss: 22197.4414\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 537ms/step - loss: 9871.6084 - val_loss: 8741.5371\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 565ms/step - loss: 7132.1729 - val_loss: 6905.6328\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 577ms/step - loss: 7828.3823 - val_loss: 8144.0732\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - loss: 7619.8843 - val_loss: 5936.4497\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 391ms/step - loss: 5983.3989 - val_loss: 4973.5396\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 387ms/step - loss: 5380.2070 - val_loss: 6965.9873\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - loss: 5064.6167 - val_loss: 6450.4624\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - loss: 4903.4873 - val_loss: 5300.4512\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - loss: 5789.8892 - val_loss: 4042.2422\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - loss: 4042.0276 - val_loss: 3590.9082\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - loss: 3310.5679 - val_loss: 3416.7351\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - loss: 2495.7803 - val_loss: 2421.9980\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - loss: 2372.9558 - val_loss: 4038.4258\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - loss: 2108.0261 - val_loss: 1955.5264\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 345ms/step - loss: 1258.0773 - val_loss: 1454.9155\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - loss: 1282.0559 - val_loss: 1335.1389\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - loss: 1304.4292 - val_loss: 1114.5598\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - loss: 1227.0015 - val_loss: 833.3576\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 322ms/step - loss: 1343.5764 - val_loss: 841.2808\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - loss: 955.5320 - val_loss: 703.3019\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 327ms/step - loss: 1031.7251 - val_loss: 663.8558\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 373ms/step - loss: 667.2140 - val_loss: 700.5651\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - loss: 583.8347 - val_loss: 607.7092\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - loss: 1134.6582 - val_loss: 540.7753\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 388ms/step - loss: 756.6080 - val_loss: 442.6327\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - loss: 614.2831 - val_loss: 449.0665\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - loss: 657.7748 - val_loss: 409.4370\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 332ms/step - loss: 568.5306 - val_loss: 421.5847\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - loss: 751.3328 - val_loss: 655.1645\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 401ms/step - loss: 995.2748 - val_loss: 450.2225\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 398ms/step - loss: 594.7686 - val_loss: 400.4131\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 392ms/step - loss: 579.5482 - val_loss: 434.9053\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 266ms/step - loss: 573.9678 - val_loss: 368.1347\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - loss: 572.3641 - val_loss: 390.9557\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - loss: 807.6540 - val_loss: 396.5465\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - loss: 352.1274 - val_loss: 415.7217\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 386ms/step - loss: 604.5399 - val_loss: 354.6461\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - loss: 373.5644 - val_loss: 412.8464\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 405ms/step - loss: 400.0334 - val_loss: 406.1889\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 398ms/step - loss: 379.2477 - val_loss: 406.5178\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 409ms/step - loss: 580.4289 - val_loss: 389.2132\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - loss: 766.9960 - val_loss: 338.7624\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - loss: 470.9531 - val_loss: 287.3221\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 376ms/step - loss: 680.5278 - val_loss: 363.8120\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - loss: 570.0939 - val_loss: 249.0992\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - loss: 321.7476 - val_loss: 435.4324\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 557ms/step - loss: 728.4948 - val_loss: 427.3908\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 392ms/step - loss: 458.6273 - val_loss: 239.3546\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - loss: 427.7823 - val_loss: 286.7428\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - loss: 527.3466 - val_loss: 309.2313\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - loss: 503.5236 - val_loss: 306.2510\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 299ms/step - loss: 291.8503 - val_loss: 264.0157\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - loss: 504.2559 - val_loss: 394.1440\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - loss: 609.2286 - val_loss: 248.3071\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - loss: 617.3885 - val_loss: 548.6203\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - loss: 632.6968 - val_loss: 364.4348\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 284ms/step - loss: 690.7892 - val_loss: 272.5865\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - loss: 416.2184 - val_loss: 518.2630\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step\n",
      "Validation Metrics:\n",
      "R²: 0.9540\n",
      "MAE: 10.2787\n",
      "RMSE: 14.8238\n",
      "SMAPE: 5.6671%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R²: 0.8840\n",
      "MAE: 20.1209\n",
      "RMSE: 26.9323\n",
      "SMAPE: 10.1698%\n",
      "Model for Fold 2 saved.\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 322ms/step - loss: 40900.2891 - val_loss: 47189.5352\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 323ms/step - loss: 16910.7559 - val_loss: 10691.8594\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - loss: 8265.2920 - val_loss: 5656.4067\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 319ms/step - loss: 5544.7959 - val_loss: 6054.7075\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 324ms/step - loss: 6378.0239 - val_loss: 6075.0693\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - loss: 4079.8865 - val_loss: 6522.1455\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - loss: 6216.9624 - val_loss: 5361.1714\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - loss: 6762.9248 - val_loss: 6429.7256\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 315ms/step - loss: 4460.3511 - val_loss: 5213.0376\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 302ms/step - loss: 4336.9492 - val_loss: 6034.7437\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - loss: 6392.1650 - val_loss: 5157.9844\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - loss: 2906.5176 - val_loss: 5568.7598\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 296ms/step - loss: 3262.1978 - val_loss: 3974.6016\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - loss: 2863.2263 - val_loss: 3211.3743\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 329ms/step - loss: 2850.4573 - val_loss: 2643.1592\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - loss: 2812.7915 - val_loss: 1261.4363\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - loss: 2303.5430 - val_loss: 1797.3948\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 323ms/step - loss: 1561.5428 - val_loss: 1819.7117\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - loss: 2066.2839 - val_loss: 781.6939\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 293ms/step - loss: 791.4623 - val_loss: 151.4227\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - loss: 1007.6911 - val_loss: 236.4961\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - loss: 1036.3895 - val_loss: 340.4469\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - loss: 1087.1591 - val_loss: 435.2397\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - loss: 726.0395 - val_loss: 668.9499\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - loss: 932.0728 - val_loss: 299.2265\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 285ms/step - loss: 836.7573 - val_loss: 152.8005\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - loss: 534.4862 - val_loss: 202.1377\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 297ms/step - loss: 566.1641 - val_loss: 619.2534\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - loss: 611.8835 - val_loss: 199.3586\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - loss: 653.5875 - val_loss: 375.2572\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step\n",
      "Validation Metrics:\n",
      "R²: 0.9601\n",
      "MAE: 10.7417\n",
      "RMSE: 13.8651\n",
      "SMAPE: 6.0935%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R²: 0.6789\n",
      "MAE: 38.6073\n",
      "RMSE: 44.8048\n",
      "SMAPE: 20.4703%\n",
      "Model for Fold 3 saved.\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 337ms/step - loss: 87959.8594 - val_loss: 18786.0996\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 395ms/step - loss: 16390.9922 - val_loss: 5213.4287\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 393ms/step - loss: 6277.9849 - val_loss: 5137.4062\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 327ms/step - loss: 5968.8809 - val_loss: 5889.4287\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 293ms/step - loss: 9242.7334 - val_loss: 6362.3433\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 324ms/step - loss: 5646.1479 - val_loss: 5736.6045\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - loss: 8103.5996 - val_loss: 5130.5625\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 317ms/step - loss: 7899.1182 - val_loss: 5288.9609\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 304ms/step - loss: 4403.7300 - val_loss: 4696.3589\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - loss: 4784.2866 - val_loss: 4658.8613\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 319ms/step - loss: 6804.9995 - val_loss: 5887.1558\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 299ms/step - loss: 7025.7832 - val_loss: 4881.5332\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - loss: 4310.1445 - val_loss: 4203.3857\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - loss: 4116.4512 - val_loss: 3836.6421\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - loss: 2858.2388 - val_loss: 3286.6167\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - loss: 3849.5972 - val_loss: 2851.6726\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - loss: 2378.7437 - val_loss: 2365.2441\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - loss: 2231.9160 - val_loss: 2287.0613\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 317ms/step - loss: 2961.4128 - val_loss: 2275.2515\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - loss: 1876.6719 - val_loss: 2566.0198\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - loss: 1954.5914 - val_loss: 2437.9143\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - loss: 1402.2162 - val_loss: 2124.5122\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 388ms/step - loss: 1571.8040 - val_loss: 1806.8743\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - loss: 1659.5431 - val_loss: 1779.4260\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - loss: 864.2642 - val_loss: 1751.3450\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - loss: 770.5812 - val_loss: 1506.4011\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 248ms/step - loss: 1737.6057 - val_loss: 1476.4454\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - loss: 1118.3757 - val_loss: 2993.4194\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - loss: 1597.6910 - val_loss: 1817.9695\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 291ms/step - loss: 1076.5896 - val_loss: 1649.6621\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 319ms/step - loss: 1173.3146 - val_loss: 1859.2361\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - loss: 858.4479 - val_loss: 1638.6641\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 414ms/step - loss: 886.6309 - val_loss: 1408.0920\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - loss: 1071.1049 - val_loss: 1664.0881\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 373ms/step - loss: 1038.4843 - val_loss: 2494.7695\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - loss: 784.5560 - val_loss: 1855.0494\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - loss: 808.8501 - val_loss: 1632.2581\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - loss: 867.1409 - val_loss: 1412.3392\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - loss: 970.0894 - val_loss: 1643.0970\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - loss: 1112.8550 - val_loss: 2045.9299\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 285ms/step - loss: 756.2744 - val_loss: 1535.1582\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - loss: 991.2999 - val_loss: 1805.6379\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - loss: 780.1720 - val_loss: 1737.5599\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
      "Validation Metrics:\n",
      "R²: 0.6508\n",
      "MAE: 25.0639\n",
      "RMSE: 37.5064\n",
      "SMAPE: 15.7533%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R²: 0.6648\n",
      "MAE: 35.7961\n",
      "RMSE: 45.7776\n",
      "SMAPE: 21.6686%\n",
      "Model for Fold 4 saved.\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Starting model training...\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 414ms/step - loss: 25755.5117 - val_loss: 21460.0957\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - loss: 10042.7363 - val_loss: 17113.9648\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - loss: 7661.6328 - val_loss: 9443.2969\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - loss: 9756.7314 - val_loss: 8320.0176\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 327ms/step - loss: 8076.9175 - val_loss: 7416.7334\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 317ms/step - loss: 7474.1621 - val_loss: 7094.1006\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - loss: 4122.1392 - val_loss: 8217.1797\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 326ms/step - loss: 7920.0415 - val_loss: 9217.6631\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - loss: 5284.4077 - val_loss: 5375.6821\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - loss: 4717.8662 - val_loss: 4755.2549\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - loss: 3139.7180 - val_loss: 3986.2124\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - loss: 2885.4482 - val_loss: 3489.3040\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - loss: 2229.6882 - val_loss: 3536.3113\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 310ms/step - loss: 2129.3306 - val_loss: 2610.0840\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - loss: 1891.1342 - val_loss: 2501.4785\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - loss: 1759.8481 - val_loss: 2156.2563\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 342ms/step - loss: 1698.1704 - val_loss: 2010.7332\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 322ms/step - loss: 953.0605 - val_loss: 1953.3086\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 320ms/step - loss: 857.6573 - val_loss: 1630.6052\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 323ms/step - loss: 809.9980 - val_loss: 1602.6084\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - loss: 811.1710 - val_loss: 1645.3313\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 549.4790 - val_loss: 1485.5808\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - loss: 999.0454 - val_loss: 1591.9819\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - loss: 870.2938 - val_loss: 1712.8467\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 387ms/step - loss: 910.7642 - val_loss: 1175.5697\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - loss: 450.5455 - val_loss: 1188.3809\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 326ms/step - loss: 677.6846 - val_loss: 2163.9429\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - loss: 881.3806 - val_loss: 1536.0906\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - loss: 551.6729 - val_loss: 1357.4689\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - loss: 521.5562 - val_loss: 1214.3293\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - loss: 656.9086 - val_loss: 1099.9193\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 302ms/step - loss: 699.3690 - val_loss: 1383.4792\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - loss: 850.5464 - val_loss: 1264.6643\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 387ms/step - loss: 616.7709 - val_loss: 1033.6117\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 327ms/step - loss: 627.3742 - val_loss: 626.6507\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - loss: 526.5602 - val_loss: 633.5869\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - loss: 779.1043 - val_loss: 640.2474\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - loss: 635.2018 - val_loss: 933.6127\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - loss: 575.1763 - val_loss: 600.8260\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - loss: 895.7954 - val_loss: 830.9297\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - loss: 639.8407 - val_loss: 1196.7424\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - loss: 751.0994 - val_loss: 1229.5166\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - loss: 491.9742 - val_loss: 480.8292\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - loss: 792.8040 - val_loss: 684.1039\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - loss: 365.0321 - val_loss: 795.8423\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 319ms/step - loss: 278.6450 - val_loss: 676.2173\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - loss: 613.2891 - val_loss: 564.6959\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 317ms/step - loss: 720.8715 - val_loss: 895.7367\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - loss: 478.7598 - val_loss: 1053.9714\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 331ms/step - loss: 426.0744 - val_loss: 1006.8690\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 397ms/step - loss: 442.0523 - val_loss: 696.8558\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - loss: 829.5582 - val_loss: 492.3446\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 332ms/step - loss: 530.1405 - val_loss: 484.4554\n",
      "Training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "Validation Metrics:\n",
      "R²: 0.8970\n",
      "MAE: 15.4607\n",
      "RMSE: 22.2936\n",
      "SMAPE: 9.3308%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R²: 0.6251\n",
      "MAE: 36.0202\n",
      "RMSE: 48.4156\n",
      "SMAPE: 17.6122%\n",
      "Model for Fold 5 saved.\n",
      "\n",
      "================================================================================\n",
      "Final Average Metrics Across All Folds:\n",
      "================================================================================\n",
      "\n",
      "Average Validation Metrics:\n",
      "Average R²: 0.8845\n",
      "Average MAE: 14.3853\n",
      "Average RMSE: 20.4081\n",
      "Average SMAPE: 8.5506%\n",
      "\n",
      "Average Independent Test Set Metrics:\n",
      "Average R²: 0.7420\n",
      "Average MAE: 31.0536\n",
      "Average RMSE: 39.1568\n",
      "Average SMAPE: 16.4165%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    "    Multiply\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "N_SPLITS = 5 # Number of folds for cross-validation\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: The data loading logic remains the same.\n",
    "# Replace with your actual data paths if needed\n",
    "orig = pd.read_csv(\"../../data/WinterSeason1.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100W.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Define Metric Functions ==================== #\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    # Avoid division by zero by setting the result to 0 where denominator is 0\n",
    "    return np.mean(np.where(denominator == 0, 0, numerator / denominator)) * 100\n",
    "\n",
    "# ==================== 4. Create a Custom Data Generator ==================== #\n",
    "\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 5. Define Custom Attention Layers ==================== #\n",
    "\n",
    "class SpatialAttention(Layer):\n",
    "    \"\"\"\n",
    "    A custom layer to apply spatial attention to a feature map.\n",
    "    It generates a spatial attention map and multiplies it with the input.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpatialAttention, self).__init__(**kwargs)\n",
    "        self.conv1 = Conv2D(1, (1, 1), activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Squeeze the channels and generate a 2D attention map\n",
    "        attention_map = self.conv1(inputs)\n",
    "        # Multiply the input feature map by the attention map\n",
    "        return Multiply()([inputs, attention_map])\n",
    "\n",
    "class FeatureAttention(Layer):\n",
    "    \"\"\"\n",
    "    A custom layer to apply feature-wise attention.\n",
    "    It learns a weight for each feature channel and multiplies it with the input.\n",
    "    Inspired by Squeeze-and-Excitation networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction_ratio=16, **kwargs):\n",
    "        super(FeatureAttention, self).__init__(**kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(FeatureAttention, self).build(input_shape)\n",
    "        if len(input_shape) == 4: # CNN output\n",
    "            self.avg_pool = GlobalAveragePooling2D()\n",
    "            self.dense1 = Dense(units=input_shape[-1] // self.reduction_ratio, activation='relu')\n",
    "            self.dense2 = Dense(units=input_shape[-1], activation='sigmoid')\n",
    "            self.reshape_output = Reshape((1, 1, input_shape[-1]))\n",
    "        else: # MLP or GNN output\n",
    "            self.dense1 = Dense(units=input_shape[-1] // self.reduction_ratio, activation='relu')\n",
    "            self.dense2 = Dense(units=input_shape[-1], activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if len(inputs.shape) == 4: # CNN branch\n",
    "            x = self.avg_pool(inputs)\n",
    "            x = self.dense1(x)\n",
    "            x = self.dense2(x)\n",
    "            x = self.reshape_output(x)\n",
    "        else: # MLP or GNN branch\n",
    "            x = self.dense1(inputs)\n",
    "            x = self.dense2(x)\n",
    "            \n",
    "        return Multiply()([inputs, x])\n",
    "\n",
    "# ==================== 6. Define the Dual Attention Model ==================== #\n",
    "def build_dual_attention_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- CNN Branch with Spatial and Feature Attention ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    \n",
    "    # Spatial Attention\n",
    "    cnn_spatial_attn = SpatialAttention()(cnn_branch)\n",
    "    \n",
    "    # Feature Attention\n",
    "    cnn_feature_attn = FeatureAttention()(cnn_spatial_attn)\n",
    "    \n",
    "    # Flatten and get embedding\n",
    "    cnn_embedding = Flatten()(cnn_feature_attn)\n",
    "    cnn_embedding = Dense(128, activation=\"relu\", name=\"cnn_embedding\")(cnn_embedding)\n",
    "\n",
    "    # --- MLP Branch with Embedding ---\n",
    "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(32, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch with Feature Attention and Embedding ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    \n",
    "    # Feature Attention\n",
    "    gnn_feature_attn = FeatureAttention()(gnn_branch)\n",
    "    gnn_embedding = Dense(32, activation=\"relu\", name=\"gnn_embedding\")(gnn_feature_attn)\n",
    "\n",
    "    # --- Attention Fusion ---\n",
    "    # Concatenate all embeddings\n",
    "    combined_embedding = Concatenate(name=\"combined_embedding\")([cnn_embedding, mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined_embedding)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4):\n",
    "    \"\"\"\n",
    "    Evaluates a model on the given data and returns a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    num_samples = len(y)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    # Get patch dimensions\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords[i:i+batch_size]\n",
    "        batch_mlp = mlp_data[i:i+batch_size]\n",
    "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    smape_val = smape(y, y_pred)\n",
    "\n",
    "    return {\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'SMAPE': smape_val\n",
    "    }\n",
    "\n",
    "# ==================== 7. Run K-Fold Cross-Validation ==================== #\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Starting {N_SPLITS}-Fold Cross-Validation...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a folder to save models\n",
    "model_save_dir = \"models/dual_attention\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "print(f\"Models will be saved in: '{model_save_dir}'\")\n",
    "\n",
    "# Prepare data for K-Fold\n",
    "combined_indices = np.arange(len(train_combined))\n",
    "coords_all = train_combined[['Long','Lat']].values\n",
    "data_all = train_combined[numeric_cols].values\n",
    "gnn_input_all = np.exp(-distance_matrix(coords_all, coords_all)/10)\n",
    "y_all = train_combined['RI'].values\n",
    "batch_size = 4\n",
    "\n",
    "# Store metrics for each fold\n",
    "fold_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "# Initialize K-Fold\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(combined_indices)):\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} ---\")\n",
    "\n",
    "    # Split data for the current fold\n",
    "    coords_train_fold = coords_all[train_indices]\n",
    "    coords_val_fold = coords_all[val_indices]\n",
    "    mlp_train_fold = data_all[train_indices]\n",
    "    mlp_val_fold = data_all[val_indices]\n",
    "    y_train_fold = y_all[train_indices]\n",
    "    y_val_fold = y_all[val_indices]\n",
    "\n",
    "    # Scale MLP data and prepare GNN matrices for the current fold\n",
    "    scaler_fold = StandardScaler()\n",
    "    mlp_train_scaled = scaler_fold.fit_transform(mlp_train_fold)\n",
    "    mlp_val_scaled = scaler_fold.transform(mlp_val_fold)\n",
    "    \n",
    "    dist_mat_train_fold = distance_matrix(coords_train_fold, coords_train_fold)\n",
    "    gnn_train_fold = np.exp(-dist_mat_train_fold/10)\n",
    "    \n",
    "    dist_mat_val_fold = distance_matrix(coords_val_fold, coords_train_fold)\n",
    "    gnn_val_fold = np.exp(-dist_mat_val_fold/10)\n",
    "\n",
    "    # Re-initialize and compile the model for each fold\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "    \n",
    "    model = build_dual_attention_model(cnn_patch_shape, len(coords_train_fold), mlp_train_fold.shape[1])\n",
    "    \n",
    "    # Create Data Generators for the current fold\n",
    "    train_generator = DataGenerator(\n",
    "        coords=coords_train_fold,\n",
    "        mlp_data=mlp_train_scaled,\n",
    "        gnn_data=gnn_train_fold,\n",
    "        y=y_train_fold,\n",
    "        raster_paths=raster_paths,\n",
    "        buffer_meters=BUFFER_METERS,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = DataGenerator(\n",
    "        coords=coords_val_fold,\n",
    "        mlp_data=mlp_val_scaled,\n",
    "        gnn_data=gnn_val_fold,\n",
    "        y=y_val_fold,\n",
    "        raster_paths=raster_paths,\n",
    "        buffer_meters=BUFFER_METERS,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    print(\"Starting model training...\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=val_generator\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    fold_result = evaluate_model(model, coords_val_fold, mlp_val_scaled, gnn_val_fold, y_val_fold, raster_paths, BUFFER_METERS, batch_size)\n",
    "    fold_metrics.append(fold_result)\n",
    "    print(\"Validation Metrics:\")\n",
    "    print(f\"R²: {fold_result['R2']:.4f}\")\n",
    "    print(f\"MAE: {fold_result['MAE']:.4f}\")\n",
    "    print(f\"RMSE: {fold_result['RMSE']:.4f}\")\n",
    "    print(f\"SMAPE: {fold_result['SMAPE']:.4f}%\")\n",
    "\n",
    "    # Prepare and evaluate on the independent test set\n",
    "    dist_mat_test_train = distance_matrix(test_orig[['Long','Lat']].values, coords_train_fold)\n",
    "    gnn_test_fold = np.exp(-dist_mat_test_train/10)\n",
    "    \n",
    "    mlp_test_scaled = scaler_fold.transform(test_orig[numeric_cols].values)\n",
    "\n",
    "    test_result = evaluate_model(model, test_orig[['Long','Lat']].values, mlp_test_scaled, gnn_test_fold, test_orig['RI'].values, raster_paths, BUFFER_METERS, batch_size)\n",
    "    test_metrics.append(test_result)\n",
    "    print(\"\\nIndependent Test Set Metrics:\")\n",
    "    print(f\"R²: {test_result['R2']:.4f}\")\n",
    "    print(f\"MAE: {test_result['MAE']:.4f}\")\n",
    "    print(f\"RMSE: {test_result['RMSE']:.4f}\")\n",
    "    print(f\"SMAPE: {test_result['SMAPE']:.4f}%\")\n",
    "    \n",
    "    # Save the trained model for the current fold\n",
    "    model.save(os.path.join(model_save_dir, f\"fold_{fold+1}.keras\"))\n",
    "    print(f\"Model for Fold {fold+1} saved.\")\n",
    "\n",
    "    # Clean up to free memory\n",
    "    del model, train_generator, val_generator, early_stopping, history\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# ==================== 8. Print Final Averages ==================== #\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_fold_metrics = pd.DataFrame(fold_metrics).mean().to_dict()\n",
    "avg_test_metrics = pd.DataFrame(test_metrics).mean().to_dict()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Final Average Metrics Across All Folds:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nAverage Validation Metrics:\")\n",
    "print(f\"Average R²: {avg_fold_metrics['R2']:.4f}\")\n",
    "print(f\"Average MAE: {avg_fold_metrics['MAE']:.4f}\")\n",
    "print(f\"Average RMSE: {avg_fold_metrics['RMSE']:.4f}\")\n",
    "print(f\"Average SMAPE: {avg_fold_metrics['SMAPE']:.4f}%\")\n",
    "\n",
    "print(\"\\nAverage Independent Test Set Metrics:\")\n",
    "print(f\"Average R²: {avg_test_metrics['R2']:.4f}\")\n",
    "print(f\"Average MAE: {avg_test_metrics['MAE']:.4f}\")\n",
    "print(f\"Average RMSE: {avg_test_metrics['RMSE']:.4f}\")\n",
    "print(f\"Average SMAPE: {avg_test_metrics['SMAPE']:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ab8c0e-c3ae-4c92-bbd7-cc771fc936d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - ClayW.tif\n",
      "  - CdW.tif\n",
      "  - SandW.tif\n",
      "  - SiltW.tif\n",
      "  - AsW.tif\n",
      "  - CrW.tif\n",
      "  - NiW.tif\n",
      "  - PbW.tif\n",
      "  - CuW.tif\n",
      "================================================================================\n",
      "Starting Single-Run Training and Evaluation...\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialAttention</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span> │ spatial_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FeatureAttention</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ feature_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FeatureAttention</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,128</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ feature_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ gnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ combined_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │         \u001b[38;5;34m65\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialAttention\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m580\u001b[0m │ spatial_attentio… │\n",
       "│ (\u001b[38;5;33mFeatureAttention\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ feature_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,024\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m580\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mFeatureAttention\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m5,120,128\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ feature_attentio… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ cnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ gnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ combined_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,192,682</span> (19.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,192,682\u001b[0m (19.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,192,682</span> (19.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,192,682\u001b[0m (19.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training on the full training set...\n",
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - loss: 37111.2578\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 13821.6318\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 7732.9692\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 5934.8594\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 4979.3237\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 5315.3164\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 6560.0806\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 5397.1084\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 6492.4751\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 4568.0347\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 3860.8833\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 4059.4106\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 2770.4309\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 2858.0417\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 2131.7058\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 1878.1021\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 1371.2357\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 1079.1910\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 946.6491\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - loss: 1221.0094\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 771.6356\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 778.1300\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 661.5933\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 765.5969\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 814.0245\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 936.4201\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 644.6251\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - loss: 671.3043\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 888.5734\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - loss: 523.3878\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 527.9056\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 704.3393\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 446.0396\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 596.2667\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - loss: 666.7212\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 944.7629\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 728.9420\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - loss: 468.6294\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 556.3849\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - loss: 419.3982\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 570.1678\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - loss: 539.8303\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 485.7515\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 259ms/step - loss: 931.6223\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 242ms/step - loss: 506.6766\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 262ms/step - loss: 670.8580\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 568.7740\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - loss: 464.2352\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 909.2498\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - loss: 509.3945\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 790.8355\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - loss: 364.1677\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 637.3625\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 444.9041\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 465.5895\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 449.1528\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 285.3068\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 435.6112\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 315.4480\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 374.6313\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 699.9344\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 350.6736\n",
      "Epoch 63/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - loss: 461.6442\n",
      "Epoch 64/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 392.6639\n",
      "Epoch 65/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - loss: 529.6357\n",
      "Epoch 66/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 324ms/step - loss: 495.1120\n",
      "Epoch 67/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - loss: 393.7792\n",
      "Epoch 68/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - loss: 470.5983\n",
      "Epoch 69/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 303ms/step - loss: 396.8203\n",
      "Epoch 70/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 299ms/step - loss: 329.5108\n",
      "Epoch 71/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - loss: 666.1786\n",
      "Epoch 72/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - loss: 574.5892\n",
      "Epoch 73/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - loss: 463.9643\n",
      "Epoch 74/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 366ms/step - loss: 376.3552\n",
      "Epoch 75/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 298ms/step - loss: 393.6678\n",
      "Epoch 76/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 328ms/step - loss: 319.8693\n",
      "Epoch 77/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 321ms/step - loss: 473.9707\n",
      "Epoch 78/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 323ms/step - loss: 407.1761\n",
      "Epoch 79/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 372ms/step - loss: 367.0865\n",
      "Epoch 80/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - loss: 325.7318\n",
      "Epoch 81/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 336ms/step - loss: 317.2938\n",
      "Epoch 82/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 364ms/step - loss: 220.7827\n",
      "Epoch 83/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 439ms/step - loss: 235.5950\n",
      "Epoch 84/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 340ms/step - loss: 380.4614\n",
      "Epoch 85/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 352ms/step - loss: 560.6717\n",
      "Epoch 86/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - loss: 371.3907\n",
      "Epoch 87/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 312ms/step - loss: 286.8803\n",
      "Epoch 88/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 350ms/step - loss: 356.4818\n",
      "Epoch 89/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 323ms/step - loss: 231.1653\n",
      "Epoch 90/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 348ms/step - loss: 353.8187\n",
      "Epoch 91/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - loss: 587.1363\n",
      "Epoch 92/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 272ms/step - loss: 487.3443\n",
      "Epoch 93/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 273ms/step - loss: 346.2479\n",
      "Epoch 94/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 259ms/step - loss: 565.4344\n",
      "Epoch 95/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 280ms/step - loss: 689.1516\n",
      "Epoch 96/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 244ms/step - loss: 254.1859\n",
      "Epoch 97/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 380.4953\n",
      "Epoch 98/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 546.9460\n",
      "Epoch 99/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 317ms/step - loss: 373.6172\n",
      "Epoch 100/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - loss: 236.7663\n",
      "Training complete.\n",
      "\n",
      "Evaluating on Independent Test Set...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "\n",
      "Independent Test Set Metrics:\n",
      "R²: 0.8201\n",
      "MAE: 30.2765\n",
      "RMSE: 33.5328\n",
      "SMAPE: 20.6597%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    "    Multiply\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: The data loading logic remains the same.\n",
    "# Replace with your actual data paths if needed\n",
    "try:\n",
    "    orig = pd.read_csv(\"../../data/WinterSeason1.csv\")\n",
    "    river_100 = pd.read_csv(\"../data/Samples_100W.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please ensure the data files are in the correct paths.\")\n",
    "    sys.exit()\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "try:\n",
    "    raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "    raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "    raster_paths += glob.glob(\"../IDWW/*.tif\")\n",
    "except Exception as e:\n",
    "    print(f\"Error collecting rasters: {e}\")\n",
    "    print(\"Please ensure the raster folders exist.\")\n",
    "    sys.exit()\n",
    "\n",
    "if not raster_paths:\n",
    "    print(\"Warning: No raster layers found. CNN branch will not function as expected.\")\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Define Metric Functions ==================== #\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    # Avoid division by zero by setting the result to 0 where denominator is 0\n",
    "    return np.mean(np.where(denominator == 0, 0, numerator / denominator)) * 100\n",
    "\n",
    "# ==================== 4. Create a Custom Data Generator ==================== #\n",
    "\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            try:\n",
    "                with rasterio.open(rfile) as src:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        if self.raster_paths:\n",
    "            with rasterio.open(self.raster_paths[0]) as src:\n",
    "                res_x, res_y = src.res\n",
    "                self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "                self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "                self.patch_width = 2 * self.buffer_pixels_x\n",
    "                self.patch_height = 2 * self.buffer_pixels_y\n",
    "        else:\n",
    "            self.buffer_pixels_x = self.buffer_pixels_y = self.patch_width = self.patch_height = 0\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 5. Define Custom Attention Layers ==================== #\n",
    "\n",
    "class SpatialAttention(Layer):\n",
    "    \"\"\"\n",
    "    A custom layer to apply spatial attention to a feature map.\n",
    "    It generates a spatial attention map and multiplies it with the input.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpatialAttention, self).__init__(**kwargs)\n",
    "        self.conv1 = Conv2D(1, (1, 1), activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Squeeze the channels and generate a 2D attention map\n",
    "        attention_map = self.conv1(inputs)\n",
    "        # Multiply the input feature map by the attention map\n",
    "        return Multiply()([inputs, attention_map])\n",
    "\n",
    "class FeatureAttention(Layer):\n",
    "    \"\"\"\n",
    "    A custom layer to apply feature-wise attention.\n",
    "    It learns a weight for each feature channel and multiplies it with the input.\n",
    "    Inspired by Squeeze-and-Excitation networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction_ratio=16, **kwargs):\n",
    "        super(FeatureAttention, self).__init__(**kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(FeatureAttention, self).build(input_shape)\n",
    "        if len(input_shape) == 4: # CNN output\n",
    "            self.avg_pool = GlobalAveragePooling2D()\n",
    "            self.dense1 = Dense(units=input_shape[-1] // self.reduction_ratio, activation='relu')\n",
    "            self.dense2 = Dense(units=input_shape[-1], activation='sigmoid')\n",
    "            self.reshape_output = Reshape((1, 1, input_shape[-1]))\n",
    "        else: # MLP or GNN output\n",
    "            self.dense1 = Dense(units=input_shape[-1] // self.reduction_ratio, activation='relu')\n",
    "            self.dense2 = Dense(units=input_shape[-1], activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if len(inputs.shape) == 4: # CNN branch\n",
    "            x = self.avg_pool(inputs)\n",
    "            x = self.dense1(x)\n",
    "            x = self.dense2(x)\n",
    "            x = self.reshape_output(x)\n",
    "        else: # MLP or GNN branch\n",
    "            x = self.dense1(inputs)\n",
    "            x = self.dense2(x)\n",
    "            \n",
    "        return Multiply()([inputs, x])\n",
    "\n",
    "# ==================== 6. Define the Dual Attention Model ==================== #\n",
    "def build_dual_attention_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- CNN Branch with Spatial and Feature Attention ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    \n",
    "    # Spatial Attention\n",
    "    cnn_spatial_attn = SpatialAttention()(cnn_branch)\n",
    "    \n",
    "    # Feature Attention\n",
    "    cnn_feature_attn = FeatureAttention()(cnn_spatial_attn)\n",
    "    \n",
    "    # Flatten and get embedding\n",
    "    cnn_embedding = Flatten()(cnn_feature_attn)\n",
    "    cnn_embedding = Dense(128, activation=\"relu\", name=\"cnn_embedding\")(cnn_embedding)\n",
    "\n",
    "    # --- MLP Branch with Embedding ---\n",
    "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(32, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch with Feature Attention and Embedding ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    \n",
    "    # Feature Attention\n",
    "    gnn_feature_attn = FeatureAttention()(gnn_branch)\n",
    "    gnn_embedding = Dense(32, activation=\"relu\", name=\"gnn_embedding\")(gnn_feature_attn)\n",
    "\n",
    "    # --- Attention Fusion ---\n",
    "    # Concatenate all embeddings\n",
    "    combined_embedding = Concatenate(name=\"combined_embedding\")([cnn_embedding, mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined_embedding)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4):\n",
    "    \"\"\"\n",
    "    Evaluates a model on the given data and returns a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    num_samples = len(y)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    # Get patch dimensions\n",
    "    if raster_paths:\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            buffer_pixels_x = int(buffer_meters / res_x)\n",
    "            buffer_pixels_y = int(buffer_meters / res_y)\n",
    "            patch_width = 2 * buffer_pixels_x\n",
    "            patch_height = 2 * buffer_pixels_y\n",
    "    else:\n",
    "        # Handle case with no rasters\n",
    "        print(\"Warning: No rasters found, skipping CNN evaluation.\")\n",
    "        return {'R2': np.nan, 'MAE': np.nan, 'RMSE': np.nan, 'SMAPE': np.nan}\n",
    "\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords[i:i+batch_size]\n",
    "        batch_mlp = mlp_data[i:i+batch_size]\n",
    "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    smape_val = smape(y, y_pred)\n",
    "\n",
    "    return {\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'SMAPE': smape_val\n",
    "    }\n",
    "\n",
    "# ==================== 7. Train and Evaluate the Model ==================== #\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Starting Single-Run Training and Evaluation...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data for training and testing\n",
    "coords_train_set = train_combined[['Long','Lat']].values\n",
    "mlp_train_set = train_combined[numeric_cols].values\n",
    "y_train_set = train_combined['RI'].values\n",
    "batch_size = 4\n",
    "\n",
    "coords_test_set = test_orig[['Long','Lat']].values\n",
    "mlp_test_set = test_orig[numeric_cols].values\n",
    "y_test_set = test_orig['RI'].values\n",
    "\n",
    "# Scale MLP data\n",
    "scaler = StandardScaler()\n",
    "mlp_train_scaled = scaler.fit_transform(mlp_train_set)\n",
    "mlp_test_scaled = scaler.transform(mlp_test_set)\n",
    "\n",
    "# Prepare GNN adjacency matrices\n",
    "dist_mat_train = distance_matrix(coords_train_set, coords_train_set)\n",
    "gnn_train_set = np.exp(-dist_mat_train/10)\n",
    "\n",
    "dist_mat_test_train = distance_matrix(coords_test_set, coords_train_set)\n",
    "gnn_test_set = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "# Build the model\n",
    "if raster_paths:\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "else:\n",
    "    cnn_patch_shape = (0, 0, 0) # Placeholder if no rasters exist\n",
    "\n",
    "model = build_dual_attention_model(cnn_patch_shape, len(coords_train_set), mlp_train_set.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# Create Data Generators\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train_set,\n",
    "    mlp_data=mlp_train_scaled,\n",
    "    gnn_data=gnn_train_set,\n",
    "    y=y_train_set,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Starting model training on the full training set...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Evaluate on the independent test set\n",
    "print(\"\\nEvaluating on Independent Test Set...\")\n",
    "test_metrics = evaluate_model(model, coords_test_set, mlp_test_scaled, gnn_test_set, y_test_set, raster_paths, BUFFER_METERS, batch_size)\n",
    "\n",
    "print(\"\\nIndependent Test Set Metrics:\")\n",
    "print(f\"R²: {test_metrics['R2']:.4f}\")\n",
    "print(f\"MAE: {test_metrics['MAE']:.4f}\")\n",
    "print(f\"RMSE: {test_metrics['RMSE']:.4f}\")\n",
    "print(f\"SMAPE: {test_metrics['SMAPE']:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a5a03-7c81-4626-9a0b-5f3bec738b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
