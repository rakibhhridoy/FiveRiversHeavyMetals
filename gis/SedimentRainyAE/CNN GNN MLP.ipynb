{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c814a-fe3e-4dca-8b1d-044aa01fe5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "# Define the buffer size in meters\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# --- IMPUTATION FIX: Fill NaN values with 0 before further processing ---\n",
    "orig.fillna(0, inplace=True)\n",
    "river_100.fillna(0, inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "np.random.seed(42)\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # --- NORMALIZATION FIX: Add a small epsilon to avoid division by zero ---\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if max_val != 0:\n",
    "                        arr /= max_val + 1e-8 # Add epsilon for stability\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, batch_size=4, shuffle=True, buffer_meters=BUFFER_METERS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# --- IMPUTATION FIX: Fill NaN in raw MLP data before scaling ---\n",
    "train_combined.fillna(0, inplace=True)\n",
    "test_orig.fillna(0, inplace=True)\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define Enhanced CNN\u2013GNN\u2013MLP Model ==================== #\n",
    "def build_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # CNN branch (for raster data)\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    x = Conv2D(32, (3,3), activation=\"relu\")(cnn_input)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    cnn_out = Dense(128, activation=\"relu\", name=\"cnn_out\")(x)\n",
    "\n",
    "    # MLP branch (for numerical site features)\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    m = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_out = Dense(32, activation=\"relu\", name=\"mlp_out\")(m)\n",
    "\n",
    "    # GNN branch (for spatial connectivity)\n",
    "    # The GNN input dimension is now the number of training samples\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    g = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_out = Dense(32, activation=\"relu\", name=\"gnn_out\")(g)\n",
    "\n",
    "    # Fusion Layer\n",
    "    combined = Concatenate()([cnn_out, mlp_out, gnn_out])\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# We need to determine the final GNN input dimension for the model\n",
    "# It's the total number of training samples\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Helper function to get CNN patch shape from rasters\n",
    "def get_cnn_patch_shape(raster_paths, buffer_meters):\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, _ = src.res\n",
    "        buffer_pixels = int(buffer_meters / res_x)\n",
    "        return (2 * buffer_pixels, 2 * buffer_pixels, len(raster_paths))\n",
    "\n",
    "cnn_patch_shape = get_cnn_patch_shape(raster_paths, BUFFER_METERS)\n",
    "model = build_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "# We create a separate generator for the validation data.\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    buffer_meters=BUFFER_METERS\n",
    ")\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn), verbose=0).flatten())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "        y_pred[np.isnan(y_pred)] = 0\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing with CNN\u2013GNN\u2013MLP Model ({BUFFER_METERS}m)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator # Using the same generator for validation for this example\n",
    ")\n",
    "\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "# Re-create a data generator without shuffling for evaluation on the training set\n",
    "train_eval_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    buffer_meters=BUFFER_METERS\n",
    ")\n",
    "\n",
    "y_pred_train = model.predict(train_eval_generator, verbose=0).flatten()\n",
    "# --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "y_pred_train[np.isnan(y_pred_train)] = 0\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n\u2705 CNN\u2013GNN\u2013MLP Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "y_pred_baseline[np.isnan(y_pred_baseline)] = 0\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "print(f\"\\nBaseline Performance on Test Set: R\u00b2 = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test), verbose=0).flatten()\n",
    "y_pred_cnn_ablated[np.isnan(y_pred_cnn_ablated)] = 0\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test), verbose=0).flatten()\n",
    "y_pred_mlp_ablated[np.isnan(y_pred_mlp_ablated)] = 0\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated), verbose=0).flatten()\n",
    "y_pred_gnn_ablated[np.isnan(y_pred_gnn_ablated)] = 0\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R\u00b2 drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R\u00b2 drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R\u00b2 drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "mlp_data_test_raw = test_orig[numeric_cols]\n",
    "for i, feature_name in enumerate(mlp_data_test_raw.columns):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test), verbose=0).flatten()\n",
    "    y_pred_shuffled[np.isnan(y_pred_shuffled)] = 0\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# ==================== 10. Save Model and Data for Reproducibility ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Saving Model, Data, and Feature Importance Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create the single output directory\n",
    "output_dir = \"cnn_gnn_mlp\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the trained model in the Keras native format\n",
    "model_filename = os.path.join(output_dir, f\"fusion_model_{BUFFER_METERS}m.keras\")\n",
    "model.save(model_filename)\n",
    "print(f\"\u2705 Model saved to '{model_filename}'\")\n",
    "\n",
    "# Save the training history using pickle\n",
    "history_filename = os.path.join(output_dir, \"training_history.pkl\")\n",
    "with open(history_filename, 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(f\"\u2705 Training history saved to '{history_filename}'\")\n",
    "\n",
    "# --- New: Save Feature Importance Results ---\n",
    "feature_importance_results = {\n",
    "    \"mlp_feature_names\": test_orig[numeric_cols].columns.tolist(),\n",
    "    \"mlp_permutation_importance\": mlp_feature_importance,\n",
    "    \"cnn_ablation_importance\": importance_cnn,\n",
    "    \"mlp_ablation_importance\": importance_mlp,\n",
    "    \"gnn_ablation_importance\": importance_gnn\n",
    "}\n",
    "importance_filename = os.path.join(output_dir, \"feature_importance.pkl\")\n",
    "with open(importance_filename, 'wb') as f:\n",
    "    pickle.dump(feature_importance_results, f)\n",
    "print(f\"\u2705 Feature importance results saved to '{importance_filename}'\")\n",
    "\n",
    "# Save processed NumPy arrays for later use\n",
    "np.savez_compressed(\n",
    "    os.path.join(output_dir, \"processed_train_data.npz\"),\n",
    "    coords=coords_train,\n",
    "    mlp=mlp_train,\n",
    "    y=y_train\n",
    ")\n",
    "np.savez_compressed(\n",
    "    os.path.join(output_dir, \"processed_test_data.npz\"),\n",
    "    coords=coords_test,\n",
    "    mlp=mlp_test,\n",
    "    y=y_test\n",
    ")\n",
    "np.savez_compressed(\n",
    "    os.path.join(output_dir, \"gnn_data.npz\"),\n",
    "    gnn_train=gnn_train,\n",
    "    gnn_test=gnn_test\n",
    ")\n",
    "print(f\"\u2705 Processed data arrays saved to '{output_dir}'\")\n",
    "\n",
    "# Save the raw dataframes to CSV for easy inspection\n",
    "train_combined.to_csv(os.path.join(output_dir, \"train_combined.csv\"), index=False)\n",
    "test_orig.to_csv(os.path.join(output_dir, \"test_orig.csv\"), index=False)\n",
    "print(f\"\u2705 Raw dataframes saved to '{output_dir}'\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f26d0d-f2f2-4242-a428-32d475ad1e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaEarth Integration Enabled\n",
    "\n",
    "This notebook has been enhanced with AlphaEarth satellite embeddings.\n",
    "\n",
    "## Integration Options:\n",
    "- **Option A**: Replace indices with AlphaEarth (64 bands)\n",
    "- **Option B**: Add AlphaEarth to features (RECOMMENDED)\n",
    "- **Option C**: PCA-reduced AlphaEarth (20 components)\n",
    "- **Option D**: MLP enhancement only\n",
    "\n",
    "Expected improvement: +0.5% to +0.8% in R\u00b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== ALPHAEARTH CONFIGURATION ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Select which AlphaEarth option to use\n",
    "ALPHA_EARTH_OPTION = 'B'  # Options: A, B (recommended), C, D\n",
    "USE_ALPHA_EARTH = True\n",
    "\n",
    "# Paths to AlphaEarth data files (created by 00_AlphaEarth_Data_Preparation.ipynb)\n",
    "option_file = f'Option_{ALPHA_EARTH_OPTION}_RainyAE.csv'  # or WinterAE\n",
    "\n",
    "# Load AlphaEarth data\n",
    "if os.path.exists(option_file):\n",
    "    ae_data = pd.read_csv(option_file)\n",
    "    print(f'Loaded AlphaEarth Option {ALPHA_EARTH_OPTION}')\n",
    "    print(f'Shape: {ae_data.shape}')\n",
    "else:\n",
    "    print(f'WARNING: {option_file} not found')\n",
    "    print('Please run 00_AlphaEarth_Data_Preparation.ipynb first')\n",
    "    USE_ALPHA_EARTH = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acdece-73a9-44d8-8b23-99f12e3044cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a1ce6-26f3-499f-b35f-c24e1d28d443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7ae458-39dc-40dc-9f7e-0bd5c65839c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Starting 5-Fold Cross-Validation for CNN\u2013GNN\u2013MLP Model (500m)\n",
      "================================================================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - loss: 44134.1289 - val_loss: 40436.1250\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 22020.5684 - val_loss: 5833.9082\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 9585.7969 - val_loss: 5279.7607\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 10165.6523 - val_loss: 4190.1006\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 7924.8765 - val_loss: 4949.9209\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - loss: 7585.0928 - val_loss: 3648.3979\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 8994.9482 - val_loss: 3906.3289\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 6841.9399 - val_loss: 4170.2739\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - loss: 5679.7090 - val_loss: 3946.9004\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 6507.0669 - val_loss: 3626.5913\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 4593.5962 - val_loss: 3621.8445\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 4803.1426 - val_loss: 4473.4141\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 5799.6631 - val_loss: 3655.2144\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 4162.8325 - val_loss: 3483.8997\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 3377.0464 - val_loss: 3338.8086\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 2244.1838 - val_loss: 2274.8638\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 3060.9438 - val_loss: 2155.4775\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 2875.8892 - val_loss: 2133.7344\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 1750.2527 - val_loss: 1710.8324\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 1717.0668 - val_loss: 1017.8026\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - loss: 1061.2817 - val_loss: 600.6105\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 834.3510 - val_loss: 781.2107\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 967.9692 - val_loss: 878.1583\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 1281.5898 - val_loss: 1114.1218\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 1029.7880 - val_loss: 1130.2444\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 740.1296 - val_loss: 1279.5510\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 1263.5901 - val_loss: 1656.6179\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 943.2518 - val_loss: 1431.5026\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 659.9095 - val_loss: 1409.2386\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 1647.4385 - val_loss: 1368.1530\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 540.2981 - val_loss: 1351.7535\n",
      "Fold 1 - R\u00b2: 0.8194, MAE: 14.9138, RMSE: 23.2679, SMAPE: 9.4305\n",
      "   -> New best model found in Fold 1\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - loss: 38241.5156 - val_loss: 25393.3242\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 19056.2676 - val_loss: 9455.9727\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 8724.8936 - val_loss: 9309.8877\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 11025.9248 - val_loss: 8035.9478\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 9997.7803 - val_loss: 8178.0693\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 8309.0498 - val_loss: 7881.2900\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 5968.6406 - val_loss: 7786.1265\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 6754.0444 - val_loss: 7726.1045\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 4958.5518 - val_loss: 8276.5469\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 5607.2734 - val_loss: 9121.7227\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 5345.1372 - val_loss: 7781.6001\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 4835.8789 - val_loss: 6687.6577\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 5001.0723 - val_loss: 7281.0244\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 3921.5852 - val_loss: 5664.0186\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - loss: 5000.4463 - val_loss: 4717.1885\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 2289.6592 - val_loss: 3937.5327\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 2590.2986 - val_loss: 3187.5181\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 2288.0510 - val_loss: 2756.2083\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 1649.2070 - val_loss: 1873.2483\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 1310.8273 - val_loss: 1405.7952\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 1745.2610 - val_loss: 1123.5377\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 1098.3036 - val_loss: 1005.6793\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 1017.5432 - val_loss: 774.7112\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 1534.0146 - val_loss: 616.1298\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 1093.6655 - val_loss: 566.6443\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 935.5815 - val_loss: 599.4962\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 1028.9667 - val_loss: 446.3562\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - loss: 668.9633 - val_loss: 475.0204\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 1089.7848 - val_loss: 449.4301\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 1101.2889 - val_loss: 366.1361\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 883.6216 - val_loss: 367.0473\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 197ms/step - loss: 1192.9824 - val_loss: 325.0036\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 767.2316 - val_loss: 627.8109\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 1049.9851 - val_loss: 316.0248\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 856.7272 - val_loss: 314.9464\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 612.5469 - val_loss: 297.3376\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 636.5179 - val_loss: 302.5871\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 1004.5331 - val_loss: 347.2370\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 1138.9841 - val_loss: 612.5177\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 1146.5326 - val_loss: 490.5912\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 696.3517 - val_loss: 359.0579\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 738.6865 - val_loss: 267.1765\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 503.5054 - val_loss: 263.5115\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 570.2914 - val_loss: 371.8973\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 938.5046 - val_loss: 242.2854\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 431.4383 - val_loss: 239.7836\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 571.2404 - val_loss: 296.8258\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 548.2443 - val_loss: 216.9965\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 614.0952 - val_loss: 441.3817\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 600.4201 - val_loss: 892.7701\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 657.4683 - val_loss: 1385.4961\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 1058.3889 - val_loss: 212.0315\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step - loss: 384.6936 - val_loss: 580.3611\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 637.3409 - val_loss: 341.4621\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - loss: 489.9632 - val_loss: 384.7074\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 567.5056 - val_loss: 273.7771\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 718.3701 - val_loss: 301.7188\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 794.6348 - val_loss: 640.8026\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 599.0692 - val_loss: 328.8535\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - loss: 509.7669 - val_loss: 167.1373\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 439.5054 - val_loss: 218.8258\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 403.1169 - val_loss: 436.7240\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - loss: 516.9249 - val_loss: 239.2428\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 618.1123 - val_loss: 177.5373\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 846.3666 - val_loss: 520.1291\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 973.0057 - val_loss: 658.1248\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 585.2792 - val_loss: 368.0860\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 464.5027 - val_loss: 633.4439\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 371.1159 - val_loss: 917.9074\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 732.4327 - val_loss: 616.9540\n",
      "Fold 2 - R\u00b2: 0.9668, MAE: 11.6062, RMSE: 14.6776, SMAPE: 8.5471\n",
      "   -> New best model found in Fold 2\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - loss: 38658.2227 - val_loss: 24835.5664\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 204ms/step - loss: 13555.8818 - val_loss: 7507.9243\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 15021.0234 - val_loss: 4588.9185\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 8023.3843 - val_loss: 4953.8325\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 7694.7148 - val_loss: 3598.4429\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 5951.4229 - val_loss: 7904.9883\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 7110.8232 - val_loss: 3071.5417\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - loss: 7208.3691 - val_loss: 2959.9905\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - loss: 5688.9873 - val_loss: 3021.9473\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 6704.8145 - val_loss: 3053.3542\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 4270.0771 - val_loss: 2798.4292\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 4976.7744 - val_loss: 2462.7400\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 4280.0874 - val_loss: 2167.7026\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 3522.2161 - val_loss: 2636.8481\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 3867.2568 - val_loss: 1977.3336\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 3539.1355 - val_loss: 1526.4948\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 2773.0435 - val_loss: 1218.9681\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 2405.9641 - val_loss: 810.5927\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 2215.6938 - val_loss: 1688.5217\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - loss: 2638.0125 - val_loss: 1015.6102\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 1408.7261 - val_loss: 760.7137\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 1670.7610 - val_loss: 668.7407\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 849.9895 - val_loss: 658.8654\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 852.0646 - val_loss: 687.1758\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 1822.9390 - val_loss: 590.9815\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 1005.1542 - val_loss: 432.3675\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 936.3724 - val_loss: 332.3777\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 1006.8235 - val_loss: 458.8481\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 970.4676 - val_loss: 855.0745\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 646.4419 - val_loss: 991.5410\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 974.9910 - val_loss: 800.3216\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 728.0723 - val_loss: 666.2120\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 940.9425 - val_loss: 493.6143\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 520.2449 - val_loss: 607.9752\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 788.3848 - val_loss: 389.6151\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 898.1127 - val_loss: 475.3906\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 894.9685 - val_loss: 321.6031\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - loss: 813.0015 - val_loss: 328.0954\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step - loss: 815.7310 - val_loss: 332.6231\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 942.5201 - val_loss: 330.1821\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 777.5137 - val_loss: 500.0558\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 575.7006 - val_loss: 638.3554\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 828.0654 - val_loss: 633.6186\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - loss: 517.1981 - val_loss: 687.6703\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 621.7821 - val_loss: 708.6927\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 205ms/step - loss: 600.3035 - val_loss: 371.1672\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - loss: 888.6928 - val_loss: 322.0920\n",
      "Fold 3 - R\u00b2: 0.9392, MAE: 11.9733, RMSE: 16.8915, SMAPE: 8.2300\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - loss: 66990.3281 - val_loss: 26811.9219\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - loss: 28485.0508 - val_loss: 20238.7500\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - loss: 16430.3047 - val_loss: 6028.5234\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - loss: 8141.0312 - val_loss: 6427.0713\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 7873.1729 - val_loss: 4471.9736\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - loss: 4675.0020 - val_loss: 4728.1851\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 6142.8032 - val_loss: 4582.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - loss: 4788.5698 - val_loss: 4631.8037\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 5086.3306 - val_loss: 4683.0454\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - loss: 4870.0688 - val_loss: 4868.6768\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 4478.4824 - val_loss: 4110.4414\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 5327.0215 - val_loss: 3723.1392\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 3114.9128 - val_loss: 3190.6099\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step - loss: 3707.2029 - val_loss: 2031.2097\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 3269.0535 - val_loss: 1781.2623\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 230ms/step - loss: 3571.7954 - val_loss: 1533.2656\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 1707.4708 - val_loss: 1393.8994\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1438.7007 - val_loss: 1749.5596\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - loss: 2277.2622 - val_loss: 872.1036\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - loss: 1008.8935 - val_loss: 1089.0889\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - loss: 1091.0826 - val_loss: 885.4627\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - loss: 1104.4498 - val_loss: 1251.6752\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - loss: 996.5513 - val_loss: 1434.7987\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 230ms/step - loss: 933.1867 - val_loss: 852.7759\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - loss: 860.8057 - val_loss: 786.8149\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 240ms/step - loss: 678.1794 - val_loss: 869.3421\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1037.2360 - val_loss: 590.1742\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 788.9418 - val_loss: 853.9303\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1245.2545 - val_loss: 589.3121\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - loss: 862.8005 - val_loss: 876.8748\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 506.9528 - val_loss: 760.7704\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 876.2488 - val_loss: 621.0801\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1062.2664 - val_loss: 417.0791\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - loss: 770.8696 - val_loss: 1069.1931\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - loss: 741.8266 - val_loss: 515.8647\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 664.5444 - val_loss: 613.0664\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 785.5482 - val_loss: 403.4816\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 235ms/step - loss: 828.1193 - val_loss: 433.0383\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - loss: 916.4355 - val_loss: 539.0123\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - loss: 794.8642 - val_loss: 909.7334\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - loss: 704.8125 - val_loss: 867.8441\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - loss: 862.6847 - val_loss: 429.2453\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - loss: 846.7393 - val_loss: 511.6783\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 763.6614 - val_loss: 967.9313\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 579.3960 - val_loss: 730.3912\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 243ms/step - loss: 686.9616 - val_loss: 1420.5626\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 470.5361 - val_loss: 634.5233\n",
      "Fold 4 - R\u00b2: 0.9123, MAE: 15.0247, RMSE: 19.4938, SMAPE: 9.1164\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - loss: 57986.3789 - val_loss: 25744.3398\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 19393.9551 - val_loss: 14832.1094\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - loss: 10932.3145 - val_loss: 9276.7715\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - loss: 9341.9395 - val_loss: 12113.5566\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 9007.7354 - val_loss: 9069.3232\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 4992.8228 - val_loss: 9681.9277\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 4816.2246 - val_loss: 8778.9922\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 6712.5610 - val_loss: 7812.6392\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 6335.8145 - val_loss: 7448.2783\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 6188.6235 - val_loss: 7438.8877\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - loss: 4494.4600 - val_loss: 6971.0469\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 5848.4155 - val_loss: 7070.8765\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 5645.9829 - val_loss: 6813.3203\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - loss: 7501.3379 - val_loss: 6991.1040\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 4741.5039 - val_loss: 5129.1851\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 3364.4673 - val_loss: 4200.2290\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 4346.9761 - val_loss: 3364.3000\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 2810.1162 - val_loss: 2302.8315\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 2202.4800 - val_loss: 3751.2437\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - loss: 1740.4899 - val_loss: 1405.1472\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 1440.6394 - val_loss: 1374.5037\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step - loss: 1177.6206 - val_loss: 1243.6189\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 1051.9447 - val_loss: 829.3959\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - loss: 1483.7139 - val_loss: 945.7126\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 1493.7607 - val_loss: 700.5905\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 663.1309 - val_loss: 867.1727\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - loss: 953.8261 - val_loss: 961.3094\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 791.3552 - val_loss: 1247.8806\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 1075.6459 - val_loss: 1187.6273\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - loss: 1284.0754 - val_loss: 1629.2062\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 833.7079 - val_loss: 1241.0736\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 1030.2930 - val_loss: 1205.1072\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 771.3754 - val_loss: 744.8354\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 854.4940 - val_loss: 818.0072\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 1154.7762 - val_loss: 608.7820\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 685.9336 - val_loss: 745.0422\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 785.3232 - val_loss: 1121.7844\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 393.5928 - val_loss: 1071.3199\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 662.6920 - val_loss: 1018.0579\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 1073.1731 - val_loss: 827.5056\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 526.4420 - val_loss: 895.8898\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 654.1703 - val_loss: 957.6300\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 658.6779 - val_loss: 992.1707\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 660.4460 - val_loss: 969.7302\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 684.2867 - val_loss: 924.3071\n",
      "Fold 5 - R\u00b2: 0.8918, MAE: 18.3222, RMSE: 23.8556, SMAPE: 10.4525\n",
      "\n",
      "================================================================================\n",
      "Cross-Validation Complete\n",
      "Best model from Fold 2 with Validation R\u00b2: 0.9668\n",
      "Loading the best model for final evaluation.\n",
      "================================================================================\n",
      "\n",
      "\u2705 CNN\u2013GNN\u2013MLP Model Final Performance on Test Set (500m):\n",
      "R\u00b2 Test: 0.9607 | MAE Test: 7.7114 | RMSE Test: 9.4957 | SMAPE Test: 5.8128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "import pickle\n",
    "",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "# Remove 'Source' column if it exists in river_100 dataframe\n",
    "if 'Source' in river_100.columns:\n",
    "    river_100.drop(columns=\"Source\", inplace=True)\n",
    "",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "",
    "# --- IMPUTATION FIX: Fill NaN values with 0 before further processing ---\n",
    "orig.fillna(0, inplace=True)\n",
    "river_100.fillna(0, inplace=True)\n",
    "",
    "# --- Use an 80/20 train-test split for a larger test set ---\n",
    "np.random.seed(42)\n",
    "train_orig, test_orig = train_test_split(orig, test_size=0.2, random_state=42)\n",
    "",
    "# Combine the river data with the new training set\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "",
    "                    # --- NORMALIZATION FIX: Add a small epsilon to avoid division by zero ---\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if max_val != 0:\n",
    "                        arr /= max_val + 1e-8 # Add epsilon for stability\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "",
    "        self.on_epoch_end()\n",
    "",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "",
    "        batch_y = self.y[batch_indices]\n",
    "",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "",
    "scaler = StandardScaler()\n",
    "# --- IMPUTATION FIX: Fill NaN in raw MLP data before scaling ---\n",
    "train_combined.fillna(0, inplace=True)\n",
    "test_orig.fillna(0, inplace=True)\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "",
    "# ==================== 5. Define Enhanced CNN\u2013GNN\u2013MLP Model ==================== #\n",
    "def build_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # CNN branch (for raster data)\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    x = Conv2D(32, (3,3), activation=\"relu\")(cnn_input)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    cnn_out = Dense(128, activation=\"relu\", name=\"cnn_out\")(x)\n",
    "",
    "    # MLP branch (for numerical site features)\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    m = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_out = Dense(32, activation=\"relu\", name=\"mlp_out\")(m)\n",
    "",
    "    # GNN branch (for spatial connectivity)\n",
    "    # The GNN input dimension is now the number of training samples\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    g = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_out = Dense(32, activation=\"relu\", name=\"gnn_out\")(g)\n",
    "",
    "    # Fusion Layer\n",
    "    combined = Concatenate()([cnn_out, mlp_out, gnn_out])\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "",
    "# We need to determine the final GNN input dimension for the model\n",
    "# It's the total number of training samples\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "",
    "# Helper function to get CNN patch shape from rasters\n",
    "def get_cnn_patch_shape(raster_paths, buffer_meters):\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, _ = src.res\n",
    "        buffer_pixels = int(buffer_meters / res_x)\n",
    "        return (2 * buffer_pixels, 2 * buffer_pixels, len(raster_paths))\n",
    "",
    "cnn_patch_shape = get_cnn_patch_shape(raster_paths, BUFFER_METERS)\n",
    "",
    "",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    \n",
    "    # Handle the case where both y_true and y_pred are zero to avoid division by zero\n",
    "    return np.mean(numerator / (denominator + 1e-8)) * 100\n",
    "",
    "",
    "def evaluate_model(model, coords, mlp_data, gnn_data, y_true, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataset and returns the metrics or predictions.\n",
    "    \"\"\"\n",
    "    num_samples = len(y_true)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords[i:i+batch_size]\n",
    "        batch_mlp = mlp_data[i:i+batch_size]\n",
    "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn), verbose=0).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    # --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "    y_pred[np.isnan(y_pred)] = 0\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        smap = smape(y_true, y_pred)\n",
    "        return r2, mae, rmse, smap\n",
    "",
    "",
    "# ==================== 6. K-Fold Cross-Validation and Model Saving ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Starting 5-Fold Cross-Validation for CNN\u2013GNN\u2013MLP Model ({BUFFER_METERS}m)\")\n",
    "print(\"=\"*80)\n",
    "",
    "# Create the directory to save the models\n",
    "output_dir = \"models/cnn_gnn_mlp\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "",
    "# Combine all training data for K-Fold splitting\n",
    "all_coords = coords_train\n",
    "all_mlp = mlp_train\n",
    "all_gnn = gnn_train\n",
    "all_y = y_train\n",
    "",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "best_r2_val = -np.inf\n",
    "best_model = None\n",
    "best_fold = -1\n",
    "fold_num = 1\n",
    "",
    "for train_index, val_index in kf.split(all_y):\n",
    "    print(f\"\\n--- Fold {fold_num}/{kf.n_splits} ---\")\n",
    "    \n",
    "    # Split the data for the current fold\n",
    "    fold_train_coords, fold_val_coords = all_coords[train_index], all_coords[val_index]\n",
    "    fold_train_mlp, fold_val_mlp = all_mlp[train_index], all_mlp[val_index]\n",
    "    # GNN matrix slicing needs to be handled carefully. The adjacency matrix depends on the training data.\n",
    "    fold_train_gnn = all_gnn[train_index, :]\n",
    "    fold_val_gnn = all_gnn[val_index, :]\n",
    "    fold_train_y, fold_val_y = all_y[train_index], all_y[val_index]\n",
    "    \n",
    "    # Create generators for the current fold's data\n",
    "    fold_train_generator = DataGenerator(\n",
    "        coords=fold_train_coords,\n",
    "        mlp_data=fold_train_mlp,\n",
    "        gnn_data=fold_train_gnn,\n",
    "        y=fold_train_y,\n",
    "        raster_paths=raster_paths,\n",
    "        buffer_meters=BUFFER_METERS,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Validation generator for evaluation\n",
    "    fold_val_generator = DataGenerator(\n",
    "        coords=fold_val_coords,\n",
    "        mlp_data=fold_val_mlp,\n",
    "        gnn_data=fold_val_gnn,\n",
    "        y=fold_val_y,\n",
    "        raster_paths=raster_paths,\n",
    "        buffer_meters=BUFFER_METERS,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Build and compile a new model for each fold\n",
    "    model = build_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_train.shape[1])\n",
    "    \n",
    "    # Define a unique filename for each fold's best model\n",
    "    checkpoint_filepath = os.path.join(output_dir, f'best_model_fold_{fold_num}.keras')\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        fold_train_generator,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, model_checkpoint_callback],\n",
    "        validation_data=fold_val_generator\n",
    "    )\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    val_r2, val_mae, val_rmse, val_smape = evaluate_model(\n",
    "        model, \n",
    "        fold_val_coords, \n",
    "        fold_val_mlp, \n",
    "        fold_val_gnn, \n",
    "        fold_val_y, \n",
    "        raster_paths, \n",
    "        BUFFER_METERS, \n",
    "        batch_size\n",
    "    )\n",
    "",
    "    print(f\"Fold {fold_num} - R\u00b2: {val_r2:.4f}, MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}, SMAPE: {val_smape:.4f}\")\n",
    "    fold_results.append({\n",
    "        'fold': fold_num,\n",
    "        'val_r2': val_r2,\n",
    "        'val_mae': val_mae,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_smape': val_smape\n",
    "    })\n",
    "    \n",
    "    # Check if this fold produced the best model so far\n",
    "    if val_r2 > best_r2_val:\n",
    "        best_r2_val = val_r2\n",
    "        best_fold = fold_num\n",
    "        best_model = tf.keras.models.load_model(checkpoint_filepath)\n",
    "        print(f\"   -> New best model found in Fold {fold_num}\")\n",
    "    \n",
    "    fold_num += 1\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cross-Validation Complete\")\n",
    "print(f\"Best model from Fold {best_fold} with Validation R\u00b2: {best_r2_val:.4f}\")\n",
    "print(\"Loading the best model for final evaluation.\")\n",
    "model = best_model\n",
    "print(\"=\"*80)\n",
    "",
    "# ==================== 7. Final Evaluation on Test Set ==================== #\n",
    "r2_test, mae_test, rmse_test, smape_test = evaluate_model(\n",
    "    model, \n",
    "    coords_test, \n",
    "    mlp_test, \n",
    "    gnn_test, \n",
    "    y_test, \n",
    "    raster_paths, \n",
    "    buffer_meters=BUFFER_METERS, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "",
    "print(f\"\\n\u2705 CNN\u2013GNN\u2013MLP Model Final Performance on Test Set ({BUFFER_METERS}m):\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | MAE Test: {mae_test:.4f} | RMSE Test: {rmse_test:.4f} | SMAPE Test: {smape_test:.4f}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f69ad0-670b-4963-b1bf-e8375de9bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 8. Save Final Results ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Saving Training and Evaluation Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save the fold results and final metrics\n",
    "results_filename = os.path.join(output_dir, \"training_results.pkl\")\n",
    "final_metrics = {\n",
    "    'test_r2': r2_test,\n",
    "    'test_rmse': rmse_test,\n",
    "    'kfold_results': fold_results\n",
    "}\n",
    "with open(results_filename, 'wb') as f:\n",
    "    pickle.dump(final_metrics, f)\n",
    "print(f\"\u2705 Training results saved to '{results_filename}'\")\n",
    "\n",
    "# Save processed NumPy arrays for later use\n",
    "np.savez_compressed(\n",
    "    os.path.join(output_dir, \"processed_train_data.npz\"),\n",
    "    coords=coords_train,\n",
    "    mlp=mlp_train,\n",
    "    y=y_train\n",
    ")\n",
    "np.savez_compressed(\n",
    "    os.path.join(output_dir, \"processed_test_data.npz\"),\n",
    "    coords=coords_test,\n",
    "    mlp=mlp_test,\n",
    "    y=y_test\n",
    ")\n",
    "np.savez_compressed(\n",
    "    os.path.join(output_dir, \"gnn_data.npz\"),\n",
    "    gnn_train=gnn_train,\n",
    "    gnn_test=gnn_test\n",
    ")\n",
    "print(f\"\u2705 Processed data arrays saved to '{output_dir}'\")\n",
    "\n",
    "# Save the raw dataframes to CSV for easy inspection\n",
    "train_combined.to_csv(os.path.join(output_dir, \"train_combined.csv\"), index=False)\n",
    "test_orig.to_csv(os.path.join(output_dir, \"test_orig.csv\"), index=False)\n",
    "print(f\"\u2705 Raw dataframes saved to '{output_dir}'\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7866d7d-3ed4-440d-9b07-5295a285e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503<span style=\"font-weight: bold\"> Layer (type)        </span>\u2503<span style=\"font-weight: bold\"> Output Shape      </span>\u2503<span style=\"font-weight: bold\">    Param # </span>\u2503<span style=\"font-weight: bold\"> Connected to      </span>\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 cnn_input           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> \u2502 cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \u2502 max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d_1     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_input           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_input           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)     \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \u2502 mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> \u2502 gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 cnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,333,696</span> \u2502 flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> \u2502 dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> \u2502 dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 concatenate         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 cnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       \u2502                   \u2502            \u2502 mlp_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \u2502\n",
       "\u2502                     \u2502                   \u2502            \u2502 gnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> \u2502 concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \u2502 dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 final_output        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         \u2502         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \u2502 dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 cnn_input           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502 \u001b[38;5;34m26\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d (\u001b[38;5;33mConv2D\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m,    \u2502      \u001b[38;5;34m7,520\u001b[0m \u2502 cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u2502                     \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \u2502\n",
       "\u2502 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m,    \u2502     \u001b[38;5;34m18,496\u001b[0m \u2502 max_pooling2d[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502                     \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d_1     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n",
       "\u2502 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_input           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_input           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 flatten (\u001b[38;5;33mFlatten\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)     \u2502          \u001b[38;5;34m0\u001b[0m \u2502 max_pooling2d_1[\u001b[38;5;34m\u2026\u001b[0m \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense (\u001b[38;5;33mDense\u001b[0m)       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m1,024\u001b[0m \u2502 mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_1 (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m7,104\u001b[0m \u2502 gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 cnn_out (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502  \u001b[38;5;34m4,333,696\u001b[0m \u2502 flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_out (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        \u2502      \u001b[38;5;34m2,080\u001b[0m \u2502 dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_out (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        \u2502      \u001b[38;5;34m2,080\u001b[0m \u2502 dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 concatenate         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 cnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \u2502\n",
       "\u2502 (\u001b[38;5;33mConcatenate\u001b[0m)       \u2502                   \u2502            \u2502 mlp_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \u2502\n",
       "\u2502                     \u2502                   \u2502            \u2502 gnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_2 (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502     \u001b[38;5;34m24,704\u001b[0m \u2502 concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout (\u001b[38;5;33mDropout\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_3 (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m8,256\u001b[0m \u2502 dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 final_output        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         \u2502         \u001b[38;5;34m65\u001b[0m \u2502 dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,405,025</span> (16.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,405,025\u001b[0m (16.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,405,025</span> (16.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,405,025\u001b[0m (16.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Analyzing with CNN\u2013GNN\u2013MLP Model (500m)\n",
      "================================================================================\n",
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - loss: 88821.1719 - val_loss: 26399.3652\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 21459.3887 - val_loss: 7417.1338\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - loss: 9312.0996 - val_loss: 5423.7163\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - loss: 6399.6509 - val_loss: 6299.8564\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 5870.4849 - val_loss: 5586.7271\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 6533.3853 - val_loss: 5195.3242\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 5540.9858 - val_loss: 4376.9526\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 6576.1450 - val_loss: 3711.9126\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 4759.5186 - val_loss: 3973.8125\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 4563.0337 - val_loss: 4165.7012\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 3083.8735 - val_loss: 3249.5332\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - loss: 3462.3591 - val_loss: 2516.0999\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 2288.2312 - val_loss: 2143.6423\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 1519.3973 - val_loss: 1214.1562\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 1531.5652 - val_loss: 1274.3275\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 1156.8400 - val_loss: 1333.1661\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 1598.7546 - val_loss: 966.7903\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 1128.1998 - val_loss: 966.1395\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - loss: 923.2676 - val_loss: 850.2262\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - loss: 598.5069 - val_loss: 495.9891\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 248ms/step - loss: 943.6600 - val_loss: 337.7316\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 677.0455 - val_loss: 702.9923\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - loss: 771.1122 - val_loss: 472.1964\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 754.9441 - val_loss: 369.4129\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - loss: 599.4437 - val_loss: 366.7510\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 248ms/step - loss: 812.4029 - val_loss: 470.6770\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 498.2251 - val_loss: 1294.4851\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 787.0772 - val_loss: 473.1003\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 1029.1765 - val_loss: 308.9764\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 735.6985 - val_loss: 662.9534\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 206ms/step - loss: 689.1568 - val_loss: 514.9716\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 544.6975 - val_loss: 481.4787\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - loss: 772.6733 - val_loss: 1118.1913\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 620.9172 - val_loss: 1034.4916\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 550.3770 - val_loss: 394.6200\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 1025.3691 - val_loss: 417.1536\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - loss: 515.5964 - val_loss: 397.4656\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 473.9398 - val_loss: 170.4707\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - loss: 900.7134 - val_loss: 1423.5861\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 668.9971 - val_loss: 818.4598\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 761.2259 - val_loss: 1005.1480\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - loss: 422.1120 - val_loss: 659.4565\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 633.6868 - val_loss: 825.4378\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 501.5427 - val_loss: 1385.3665\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 579.1624 - val_loss: 942.9288\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - loss: 397.5869 - val_loss: 659.3133\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 418.7186 - val_loss: 370.0385\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 497.0472 - val_loss: 1454.3069\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 551.2468 - val_loss: 394.5013\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - loss: 679.4574 - val_loss: 591.5351\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 378.9464 - val_loss: 593.4277\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 448.6423 - val_loss: 835.3222\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 259ms/step - loss: 493.3789 - val_loss: 504.4600\n",
      "\n",
      "\u2705 CNN\u2013GNN\u2013MLP Model Performance (500m):\n",
      "R\u00b2 Train: 0.9636 | RMSE Train: 13.0357 | MAE Train: 10.6598 | SMAPE Train: 6.3861\n",
      "R\u00b2 Test: 0.9089 | RMSE Test: 23.8654 | MAE Test: 20.9455 | SMAPE Test: 13.4076\n",
      "\n",
      "--------------------------------------------------\n",
      "Feature Importance Analysis for 500m\n",
      "--------------------------------------------------\n",
      "\n",
      "Baseline Performance on Test Set: R\u00b2 = 0.9089 | RMSE = 23.8654 | MAE = 20.9455 | SMAPE = 13.4076\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R\u00b2 drop): 1.5353 | (RMSE drop): -76.9711 | (MAE drop): -75.7541 | (SMAPE drop): -71.5758\n",
      "MLP Branch Importance (R\u00b2 drop): 0.7877 | (RMSE drop): -50.2599 | (MAE drop): -33.1862 | (SMAPE drop): -16.8697\n",
      "GNN Branch Importance (R\u00b2 drop): 0.0353 | (RMSE drop): -4.2449 | (MAE drop): -3.6660 | (SMAPE drop): -3.0501\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "FeR                 : R\u00b2 Drop: 0.0685 | RMSE Drop: -7.7270 | MAE Drop: -4.9588 | SMAPE Drop: -2.8764\n",
      "NiR                 : R\u00b2 Drop: 0.0475 | RMSE Drop: -5.5689 | MAE Drop: -4.4239 | SMAPE Drop: -1.1613\n",
      "AsR                 : R\u00b2 Drop: 0.0402 | RMSE Drop: -4.7889 | MAE Drop: -3.1019 | SMAPE Drop: -0.4995\n",
      "CuR                 : R\u00b2 Drop: 0.0246 | RMSE Drop: -3.0259 | MAE Drop: -0.8946 | SMAPE Drop: -0.9557\n",
      "PbR                 : R\u00b2 Drop: 0.0239 | RMSE Drop: -2.9488 | MAE Drop: -1.0788 | SMAPE Drop: -0.0246\n",
      "MR                  : R\u00b2 Drop: 0.0048 | RMSE Drop: -0.6187 | MAE Drop: -0.4025 | SMAPE Drop: 0.2972\n",
      "hydro_dist_ind      : R\u00b2 Drop: -0.0000 | RMSE Drop: 0.0000 | MAE Drop: -0.0000 | SMAPE Drop: 0.0000\n",
      "hydro_dist_brick    : R\u00b2 Drop: -0.0000 | RMSE Drop: 0.0000 | MAE Drop: 0.0000 | SMAPE Drop: 0.0000\n",
      "CrR                 : R\u00b2 Drop: -0.0001 | RMSE Drop: 0.0191 | MAE Drop: 0.0470 | SMAPE Drop: 0.0390\n",
      "ClayR               : R\u00b2 Drop: -0.0011 | RMSE Drop: 0.1437 | MAE Drop: 0.3748 | SMAPE Drop: -0.0820\n",
      "CdR                 : R\u00b2 Drop: -0.0048 | RMSE Drop: 0.6336 | MAE Drop: 1.1374 | SMAPE Drop: 0.1399\n",
      "SandR               : R\u00b2 Drop: -0.0058 | RMSE Drop: 0.7714 | MAE Drop: 1.5759 | SMAPE Drop: 0.5870\n",
      "num_brick_field     : R\u00b2 Drop: -0.0070 | RMSE Drop: 0.9312 | MAE Drop: 1.7521 | SMAPE Drop: -0.0799\n",
      "SiltR               : R\u00b2 Drop: -0.0172 | RMSE Drop: 2.3649 | MAE Drop: 2.8661 | SMAPE Drop: 2.9171\n",
      "num_industry        : R\u00b2 Drop: -0.0210 | RMSE Drop: 2.9241 | MAE Drop: 3.0947 | SMAPE Drop: 2.3782\n",
      "\n",
      "================================================================================\n",
      "Saving Model, Data, and Feature Importance Results\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "# Define the buffer size in meters\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# --- IMPUTATION FIX: Fill NaN values with 0 before further processing ---\n",
    "orig.fillna(0, inplace=True)\n",
    "river_100.fillna(0, inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "np.random.seed(42)\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # --- NORMALIZATION FIX: Add a small epsilon to avoid division by zero ---\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if max_val != 0:\n",
    "                        arr /= max_val + 1e-8 # Add epsilon for stability\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, batch_size=4, shuffle=True, buffer_meters=BUFFER_METERS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# --- IMPUTATION FIX: Fill NaN in raw MLP data before scaling ---\n",
    "train_combined.fillna(0, inplace=True)\n",
    "test_orig.fillna(0, inplace=True)\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define Enhanced CNN\u2013GNN\u2013MLP Model ==================== #\n",
    "def build_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # CNN branch (for raster data)\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    x = Conv2D(32, (3,3), activation=\"relu\")(cnn_input)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    cnn_out = Dense(128, activation=\"relu\", name=\"cnn_out\")(x)\n",
    "\n",
    "    # MLP branch (for numerical site features)\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    m = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_out = Dense(32, activation=\"relu\", name=\"mlp_out\")(m)\n",
    "\n",
    "    # GNN branch (for spatial connectivity)\n",
    "    # The GNN input dimension is now the number of training samples\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    g = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_out = Dense(32, activation=\"relu\", name=\"gnn_out\")(g)\n",
    "\n",
    "    # Fusion Layer\n",
    "    combined = Concatenate()([cnn_out, mlp_out, gnn_out])\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# We need to determine the final GNN input dimension for the model\n",
    "# It's the total number of training samples\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Helper function to get CNN patch shape from rasters\n",
    "def get_cnn_patch_shape(raster_paths, buffer_meters):\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, _ = src.res\n",
    "        buffer_pixels = int(buffer_meters / res_x)\n",
    "        return (2 * buffer_pixels, 2 * buffer_pixels, len(raster_paths))\n",
    "\n",
    "cnn_patch_shape = get_cnn_patch_shape(raster_paths, BUFFER_METERS)\n",
    "model = build_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "# We create a separate generator for the validation data.\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    buffer_meters=BUFFER_METERS\n",
    ")\n",
    "\n",
    "def smape_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    epsilon = 1e-8\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / (denominator + epsilon)) * 100\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn), verbose=0).flatten())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "        y_pred[np.isnan(y_pred)] = 0\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        smape = smape_metric(y_test, y_pred)\n",
    "        return r2, rmse, mae, smape\n",
    "\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing with CNN\u2013GNN\u2013MLP Model ({BUFFER_METERS}m)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator # Using the same generator for validation for this example\n",
    ")\n",
    "\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "# Re-create a data generator without shuffling for evaluation on the training set\n",
    "train_eval_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    buffer_meters=BUFFER_METERS\n",
    ")\n",
    "\n",
    "y_pred_train = model.predict(train_eval_generator, verbose=0).flatten()\n",
    "# --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "y_pred_train[np.isnan(y_pred_train)] = 0\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "mae_train = mean_absolute_error(y_train[:len(y_pred_train)], y_pred_train)\n",
    "smape_train = smape_metric(y_train[:len(y_pred_train)], y_pred_train)\n",
    "\n",
    "r2_test, rmse_test, mae_test, smape_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n\u2705 CNN\u2013GNN\u2013MLP Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f} | MAE Train: {mae_train:.4f} | SMAPE Train: {smape_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f} | MAE Test: {mae_test:.4f} | SMAPE Test: {smape_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "y_pred_baseline[np.isnan(y_pred_baseline)] = 0\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "baseline_mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "baseline_smape = smape_metric(y_test, y_pred_baseline)\n",
    "print(f\"\\nBaseline Performance on Test Set: R\u00b2 = {baseline_r2:.4f} | RMSE = {baseline_rmse:.4f} | MAE = {baseline_mae:.4f} | SMAPE = {baseline_smape:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test), verbose=0).flatten()\n",
    "y_pred_cnn_ablated[np.isnan(y_pred_cnn_ablated)] = 0\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "rmse_cnn_ablated = np.sqrt(mean_squared_error(y_test, y_pred_cnn_ablated))\n",
    "mae_cnn_ablated = mean_absolute_error(y_test, y_pred_cnn_ablated)\n",
    "smape_cnn_ablated = smape_metric(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn_r2 = baseline_r2 - r2_cnn_ablated\n",
    "importance_cnn_rmse = baseline_rmse - rmse_cnn_ablated\n",
    "importance_cnn_mae = baseline_mae - mae_cnn_ablated\n",
    "importance_cnn_smape = baseline_smape - smape_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test), verbose=0).flatten()\n",
    "y_pred_mlp_ablated[np.isnan(y_pred_mlp_ablated)] = 0\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "rmse_mlp_ablated = np.sqrt(mean_squared_error(y_test, y_pred_mlp_ablated))\n",
    "mae_mlp_ablated = mean_absolute_error(y_test, y_pred_mlp_ablated)\n",
    "smape_mlp_ablated = smape_metric(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp_r2 = baseline_r2 - r2_mlp_ablated\n",
    "importance_mlp_rmse = baseline_rmse - rmse_mlp_ablated\n",
    "importance_mlp_mae = baseline_mae - mae_mlp_ablated\n",
    "importance_mlp_smape = baseline_smape - smape_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated), verbose=0).flatten()\n",
    "y_pred_gnn_ablated[np.isnan(y_pred_gnn_ablated)] = 0\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "rmse_gnn_ablated = np.sqrt(mean_squared_error(y_test, y_pred_gnn_ablated))\n",
    "mae_gnn_ablated = mean_absolute_error(y_test, y_pred_gnn_ablated)\n",
    "smape_gnn_ablated = smape_metric(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn_r2 = baseline_r2 - r2_gnn_ablated\n",
    "importance_gnn_rmse = baseline_rmse - rmse_gnn_ablated\n",
    "importance_gnn_mae = baseline_mae - mae_gnn_ablated\n",
    "importance_gnn_smape = baseline_smape - smape_gnn_ablated\n",
    "\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R\u00b2 drop): {importance_cnn_r2:.4f} | (RMSE drop): {importance_cnn_rmse:.4f} | (MAE drop): {importance_cnn_mae:.4f} | (SMAPE drop): {importance_cnn_smape:.4f}\")\n",
    "print(f\"MLP Branch Importance (R\u00b2 drop): {importance_mlp_r2:.4f} | (RMSE drop): {importance_mlp_rmse:.4f} | (MAE drop): {importance_mlp_mae:.4f} | (SMAPE drop): {importance_mlp_smape:.4f}\")\n",
    "print(f\"GNN Branch Importance (R\u00b2 drop): {importance_gnn_r2:.4f} | (RMSE drop): {importance_gnn_rmse:.4f} | (MAE drop): {importance_gnn_mae:.4f} | (SMAPE drop): {importance_gnn_smape:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "mlp_feature_importance_rmse = {}\n",
    "mlp_feature_importance_mae = {}\n",
    "mlp_feature_importance_smape = {}\n",
    "mlp_data_test_raw = test_orig[numeric_cols]\n",
    "for i, feature_name in enumerate(mlp_data_test_raw.columns):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test), verbose=0).flatten()\n",
    "    y_pred_shuffled[np.isnan(y_pred_shuffled)] = 0\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    rmse_shuffled = np.sqrt(mean_squared_error(y_test, y_pred_shuffled))\n",
    "    mae_shuffled = mean_absolute_error(y_test, y_pred_shuffled)\n",
    "    smape_shuffled = smape_metric(y_test, y_pred_shuffled)\n",
    "\n",
    "    mlp_feature_importance[feature_name] = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance_rmse[feature_name] = baseline_rmse - rmse_shuffled\n",
    "    mlp_feature_importance_mae[feature_name] = baseline_mae - mae_shuffled\n",
    "    mlp_feature_importance_smape[feature_name] = baseline_smape - smape_shuffled\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: R\u00b2 Drop: {importance:.4f} | RMSE Drop: {mlp_feature_importance_rmse[feature]:.4f} | MAE Drop: {mlp_feature_importance_mae[feature]:.4f} | SMAPE Drop: {mlp_feature_importance_smape[feature]:.4f}\")\n",
    "    \n",
    "# ==================== 10. Save Model and Data for Reproducibility ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Saving Model, Data, and Feature Importance Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_importance_results = {\n",
    "    \"mlp_feature_names\": test_orig[numeric_cols].columns.tolist(),\n",
    "    \"mlp_permutation_importance_r2\": mlp_feature_importance,\n",
    "    \"mlp_permutation_importance_rmse\": mlp_feature_importance_rmse,\n",
    "    \"mlp_permutation_importance_mae\": mlp_feature_importance_mae,\n",
    "    \"mlp_permutation_importance_smape\": mlp_feature_importance_smape,\n",
    "    \"cnn_ablation_importance_r2\": importance_cnn_r2,\n",
    "    \"cnn_ablation_importance_rmse\": importance_cnn_rmse,\n",
    "    \"cnn_ablation_importance_mae\": importance_cnn_mae,\n",
    "    \"cnn_ablation_importance_smape\": importance_cnn_smape,\n",
    "    \"mlp_ablation_importance_r2\": importance_mlp_r2,\n",
    "    \"mlp_ablation_importance_rmse\": importance_mlp_rmse,\n",
    "    \"mlp_ablation_importance_mae\": importance_mlp_mae,\n",
    "    \"mlp_ablation_importance_smape\": importance_mlp_smape,\n",
    "    \"gnn_ablation_importance_r2\": importance_gnn_r2,\n",
    "    \"gnn_ablation_importance_rmse\": importance_gnn_rmse,\n",
    "    \"gnn_ablation_importance_mae\": importance_gnn_mae,\n",
    "    \"gnn_ablation_importance_smape\": importance_gnn_smape\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d590ff1a-511c-45dc-ad62-39e0162c6f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlp_feature_names': ['hydro_dist_brick',\n",
       "  'num_brick_field',\n",
       "  'hydro_dist_ind',\n",
       "  'num_industry',\n",
       "  'CrR',\n",
       "  'NiR',\n",
       "  'CuR',\n",
       "  'AsR',\n",
       "  'CdR',\n",
       "  'PbR',\n",
       "  'MR',\n",
       "  'SandR',\n",
       "  'SiltR',\n",
       "  'ClayR',\n",
       "  'FeR'],\n",
       " 'mlp_permutation_importance_r2': {'hydro_dist_brick': -1.1388364240527693e-07,\n",
       "  'num_brick_field': -0.006970773588405699,\n",
       "  'hydro_dist_ind': -3.905270751225487e-08,\n",
       "  'num_industry': -0.02095616350653362,\n",
       "  'CrR': -0.00014576190420356738,\n",
       "  'NiR': 0.04747569175040778,\n",
       "  'CuR': 0.0245657169309057,\n",
       "  'AsR': 0.04022863034921342,\n",
       "  'CdR': -0.0047726373606334915,\n",
       "  'PbR': 0.023903498150566027,\n",
       "  'MR': 0.004784931446373819,\n",
       "  'SandR': -0.005794305627008778,\n",
       "  'SiltR': -0.01716015310182728,\n",
       "  'ClayR': -0.0010939078148722858,\n",
       "  'FeR': 0.06854094402155908},\n",
       " 'mlp_permutation_importance_rmse': {'hydro_dist_brick': 1.491710115431033e-05,\n",
       "  'num_brick_field': 0.931238387011156,\n",
       "  'hydro_dist_ind': 5.115335767413853e-06,\n",
       "  'num_industry': 2.9240878197401656,\n",
       "  'CrR': 0.019100327274003348,\n",
       "  'NiR': -5.5688849584379945,\n",
       "  'CuR': -3.0259204716756614,\n",
       "  'AsR': -4.78888825964529,\n",
       "  'CdR': 0.6335554194081681,\n",
       "  'PbR': -2.9488294311870433,\n",
       "  'MR': -0.6187355470327915,\n",
       "  'SandR': 0.7714377442950102,\n",
       "  'SiltR': 2.3649031436779815,\n",
       "  'ClayR': 0.14371871381391088,\n",
       "  'FeR': -7.726970232531539},\n",
       " 'mlp_permutation_importance_mae': {'hydro_dist_brick': 1.0899135034492247e-06,\n",
       "  'num_brick_field': 1.7520886666434166,\n",
       "  'hydro_dist_ind': -1.0899135034492247e-06,\n",
       "  'num_industry': 3.0947238595145095,\n",
       "  'CrR': 0.0470406668526806,\n",
       "  'NiR': -4.423931100027897,\n",
       "  'CuR': -0.894579729352678,\n",
       "  'AsR': -3.1019352504185314,\n",
       "  'CdR': 1.1374419294084852,\n",
       "  'PbR': -1.0787556675502223,\n",
       "  'MR': -0.4025388445172986,\n",
       "  'SandR': 1.575895036969868,\n",
       "  'SiltR': 2.866112845284597,\n",
       "  'ClayR': 0.3747776576450903,\n",
       "  'FeR': -4.958776811872209},\n",
       " 'mlp_permutation_importance_smape': {'hydro_dist_brick': 3.900734544259876e-07,\n",
       "  'num_brick_field': -0.0798622337780408,\n",
       "  'hydro_dist_ind': 3.446437997212115e-07,\n",
       "  'num_industry': 2.378237698280424,\n",
       "  'CrR': 0.039031917241558745,\n",
       "  'NiR': -1.1613428915906354,\n",
       "  'CuR': -0.9557006275893958,\n",
       "  'AsR': -0.4995109035237082,\n",
       "  'CdR': 0.13991379382363078,\n",
       "  'PbR': -0.024584708222999296,\n",
       "  'MR': 0.2971696986543204,\n",
       "  'SandR': 0.587006381842972,\n",
       "  'SiltR': 2.917113862755354,\n",
       "  'ClayR': -0.08203909943887133,\n",
       "  'FeR': -2.8764193717128865},\n",
       " 'cnn_ablation_importance_r2': 1.5352504449376205,\n",
       " 'cnn_ablation_importance_rmse': -76.9710650148635,\n",
       " 'cnn_ablation_importance_mae': -75.75409481593539,\n",
       " 'cnn_ablation_importance_smape': -71.57578126481602,\n",
       " 'mlp_ablation_importance_r2': 0.7877433294125289,\n",
       " 'mlp_ablation_importance_rmse': -50.259865026146244,\n",
       " 'mlp_ablation_importance_mae': -33.18617832728795,\n",
       " 'mlp_ablation_importance_smape': -16.869686029965663,\n",
       " 'gnn_ablation_importance_r2': 0.03528940165585848,\n",
       " 'gnn_ablation_importance_rmse': -4.244882719828652,\n",
       " 'gnn_ablation_importance_mae': -3.6659987095424107,\n",
       " 'gnn_ablation_importance_smape': -3.0501140324657836}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346ab1f-196c-44ae-b709-7b7bc29d078c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "alphaearth_integrated": true,
  "season": "rainy"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}