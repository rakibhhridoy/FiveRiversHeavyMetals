{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bda13-c04f-466c-81b8-edce76807b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pickle # Import the pickle library for saving objects\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# We are not using rasters in this GNN-MLP model, but the paths are still\n",
    "# defined for consistency with previous versions.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(\"Note: Raster data is not used in this GNN-MLP model.\")\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define GNN-MLP Fusion Model ==================== #\n",
    "def build_gnn_mlp_model(mlp_dim, gnn_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Concatenate Embeddings ---\n",
    "    combined = Concatenate()([mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, mlp_test, gnn_test_matrix, y_test, return_preds=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on given data and returns R\u00b2, RMSE, and predictions.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict((mlp_test, gnn_test_matrix)).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "def calculate_permutation_importance(model, mlp_data, gnn_data, y_true):\n",
    "    \"\"\"\n",
    "    Calculates permutation feature importance for the MLP and GNN branches.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Permutation Feature Importance Analysis...\")\n",
    "    # Get baseline R\u00b2 on the unshuffled data\n",
    "    baseline_r2, _ = evaluate_model(model, mlp_data, gnn_data, y_true)\n",
    "    print(f\"Baseline R\u00b2 on test set: {baseline_r2:.4f}\")\n",
    "\n",
    "    importance = {}\n",
    "    \n",
    "    # Permute MLP input\n",
    "    shuffled_mlp_data = mlp_data.copy()\n",
    "    np.random.shuffle(shuffled_mlp_data)\n",
    "    shuffled_r2, _ = evaluate_model(model, shuffled_mlp_data, gnn_data, y_true)\n",
    "    importance['MLP'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    # Permute GNN input\n",
    "    shuffled_gnn_data = gnn_data.copy()\n",
    "    np.random.shuffle(shuffled_gnn_data)\n",
    "    shuffled_r2, _ = evaluate_model(model, mlp_data, shuffled_gnn_data, y_true)\n",
    "    importance['GNN'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    return importance\n",
    "        \n",
    "# ==================== Run the Analysis ==================== #\n",
    "# Redirect output to a string for later saving\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = captured_output = StringIO()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP Fusion Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_gnn_mlp_model(mlp_input_dim, gnn_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate & Perform Feature Importance ==================== #\n",
    "# Predict on the training data using the generator\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "# Evaluate on the test data using the updated function\n",
    "r2_test, rmse_test = evaluate_model(model, mlp_test, gnn_test, y_test)\n",
    "y_pred_test = evaluate_model(model, mlp_test, gnn_test, y_test, return_preds=True)\n",
    "\n",
    "print(f\"\\n GNN-MLP Fusion Model Performance:\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# Calculate and print feature importance\n",
    "feature_importance = calculate_permutation_importance(model, mlp_test, gnn_test, y_test)\n",
    "print(\"\\n--- Feature Importance (Permutation) ---\")\n",
    "sorted_importance = sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, score in sorted_importance:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "# ==================== 9. Save all info to a folder ==================== #\n",
    "# Restore standard output\n",
    "sys.stdout = old_stdout\n",
    "printed_output = captured_output.getvalue()\n",
    "\n",
    "output_folder = \"gnn_mlp\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(f\"\\nCreating folder: '{output_folder}' and saving results...\")\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(output_folder, \"gnn_mlp_model.keras\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save the predictions and true labels\n",
    "np.save(os.path.join(output_folder, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(output_folder, \"y_test.npy\"), y_test)\n",
    "np.save(os.path.join(output_folder, \"y_pred_train.npy\"), y_pred_train)\n",
    "np.save(os.path.join(output_folder, \"y_pred_test.npy\"), y_pred_test)\n",
    "print(f\"Predictions and true labels saved as .npy files.\")\n",
    "\n",
    "# Save the printed output to a text file\n",
    "output_path = os.path.join(output_folder, \"analysis_output.txt\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(printed_output)\n",
    "print(f\"Analysis results saved to: {output_path}\")\n",
    "\n",
    "# Save the feature importance dictionary as a .pkl file\n",
    "importance_path = os.path.join(output_folder, \"feature_importance.pkl\")\n",
    "with open(importance_path, 'wb') as f:\n",
    "    pickle.dump(feature_importance, f)\n",
    "print(f\"Feature importance results saved to: {importance_path}\")\n",
    "\n",
    "print(\"\\nAll information successfully saved.\")\n",
    "\n",
    "# Garbage collect to free up memory now that everything is saved\n",
    "del model, history, train_generator\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e094891-8cc6-4f81-af2d-21583ae7e370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaEarth Integration Enabled\n",
    "\n",
    "This notebook has been enhanced with AlphaEarth satellite embeddings.\n",
    "\n",
    "## Integration Options:\n",
    "- **Option A**: Replace indices with AlphaEarth (64 bands)\n",
    "- **Option B**: Add AlphaEarth to features (RECOMMENDED)\n",
    "- **Option C**: PCA-reduced AlphaEarth (20 components)\n",
    "- **Option D**: MLP enhancement only\n",
    "\n",
    "Expected improvement: +0.5% to +0.8% in R\u00b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== ALPHAEARTH CONFIGURATION ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Select which AlphaEarth option to use\n",
    "ALPHA_EARTH_OPTION = 'B'  # Options: A, B (recommended), C, D\n",
    "USE_ALPHA_EARTH = True\n",
    "\n",
    "# Paths to AlphaEarth data files (created by 00_AlphaEarth_Data_Preparation.ipynb)\n",
    "option_file = f'Option_{ALPHA_EARTH_OPTION}_RainyAE.csv'  # or WinterAE\n",
    "\n",
    "# Load AlphaEarth data\n",
    "if os.path.exists(option_file):\n",
    "    ae_data = pd.read_csv(option_file)\n",
    "    print(f'Loaded AlphaEarth Option {ALPHA_EARTH_OPTION}')\n",
    "    print(f'Shape: {ae_data.shape}')\n",
    "else:\n",
    "    print(f'WARNING: {option_file} not found')\n",
    "    print('Please run 00_AlphaEarth_Data_Preparation.ipynb first')\n",
    "    USE_ALPHA_EARTH = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e14240-b709-4ff4-aa0d-e900371685b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Analyzing GNN-MLP-Raster Fusion Model with 5-Fold Cross-Validation\n",
      "Using a uniform patch size of 100 pixels for a 500m buffer.\n",
      "================================================================================\n",
      "\n",
      "--- Starting Fold 1/5 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503<span style=\"font-weight: bold\"> Layer (type)        </span>\u2503<span style=\"font-weight: bold\"> Output Shape      </span>\u2503<span style=\"font-weight: bold\">    Param # </span>\u2503<span style=\"font-weight: bold\"> Connected to      </span>\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 raster_input        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> \u2502 raster_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n",
       "\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d_26    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \u2502 max_pooling2d_26\u2026 \u2502\n",
       "\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_input           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_input           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)        \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d_27    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \u2502 mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,032</span> \u2502 gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 flatten_13          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)     \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 max_pooling2d_27\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_embedding       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \u2502 dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_embedding       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \u2502 dense_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 raster_embedding    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,166,848</span> \u2502 flatten_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 concatenate_13      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 mlp_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       \u2502                   \u2502            \u2502 gnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502                     \u2502                   \u2502            \u2502 raster_embedding\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> \u2502 concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_13          \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dense_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \u2502 dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 final_output        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         \u2502         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \u2502 dense_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 raster_input        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502 \u001b[38;5;34m26\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m,    \u2502      \u001b[38;5;34m7,520\u001b[0m \u2502 raster_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n",
       "\u2502                     \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d_26    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u2502 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m,    \u2502     \u001b[38;5;34m18,496\u001b[0m \u2502 max_pooling2d_26\u2026 \u2502\n",
       "\u2502                     \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_input           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_input           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m)        \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 max_pooling2d_27    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u2502 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_52 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502      \u001b[38;5;34m2,048\u001b[0m \u2502 mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_53 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502     \u001b[38;5;34m12,032\u001b[0m \u2502 gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 flatten_13          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)     \u2502          \u001b[38;5;34m0\u001b[0m \u2502 max_pooling2d_27\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mFlatten\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_embedding       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m8,256\u001b[0m \u2502 dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_embedding       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m8,256\u001b[0m \u2502 dense_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 raster_embedding    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502  \u001b[38;5;34m2,166,848\u001b[0m \u2502 flatten_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 concatenate_13      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 mlp_embedding[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mConcatenate\u001b[0m)       \u2502                   \u2502            \u2502 gnn_embedding[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502                     \u2502                   \u2502            \u2502 raster_embedding\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_54 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502     \u001b[38;5;34m24,704\u001b[0m \u2502 concatenate_13[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout_13          \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dense_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n",
       "\u2502 (\u001b[38;5;33mDropout\u001b[0m)           \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_55 (\u001b[38;5;33mDense\u001b[0m)    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m8,256\u001b[0m \u2502 dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 final_output        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         \u2502         \u001b[38;5;34m65\u001b[0m \u2502 dense_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,256,481</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,256,481\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,256,481</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,256,481\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 888437.6875 - val_loss: 24513.5371\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 28460.4863 - val_loss: 8236.4229\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 73215.8203 - val_loss: 3990.4648\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 16451.0371 - val_loss: 3824.1907\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 9662.1064 - val_loss: 2485.3337\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 17893.7188 - val_loss: 1866.4838\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 8753.3789 - val_loss: 3065.6008\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7144.3447 - val_loss: 2154.1130\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 5084.5200 - val_loss: 1537.3500\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4679.3452 - val_loss: 1207.9838\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5014.5132 - val_loss: 1029.5520\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 4168.9009 - val_loss: 961.9681\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 3042.7358 - val_loss: 1787.6606\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 3780.6511 - val_loss: 887.4617\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1810.6351 - val_loss: 741.6960\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 3338.1724 - val_loss: 1328.8832\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 2217.8479 - val_loss: 732.3926\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 2697.0330 - val_loss: 583.1699\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2177.8994 - val_loss: 475.5130\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2989.2510 - val_loss: 1413.6483\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2006.6134 - val_loss: 514.0947\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2019.8219 - val_loss: 883.4924\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2977.4451 - val_loss: 548.3947\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 2574.8347 - val_loss: 918.3508\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 3743.2466 - val_loss: 526.7252\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1879.5367 - val_loss: 392.8858\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 2719.8127 - val_loss: 491.3611\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1887.8715 - val_loss: 451.1107\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1801.5745 - val_loss: 435.7833\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 2908.8738 - val_loss: 2642.5896\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1371.8600 - val_loss: 1705.2015\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1773.2482 - val_loss: 602.3683\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2162.2629 - val_loss: 377.2633\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1798.1735 - val_loss: 328.9385\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1643.5620 - val_loss: 251.6842\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1025.3053 - val_loss: 194.8052\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1552.6376 - val_loss: 224.7323\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 2367.3323 - val_loss: 615.7951\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1660.8517 - val_loss: 285.2763\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1123.9639 - val_loss: 360.8235\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 708.4202 - val_loss: 256.5468\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1717.2877 - val_loss: 444.9297\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1515.8136 - val_loss: 276.5661\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1255.2770 - val_loss: 869.9739\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1262.6793 - val_loss: 594.1265\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 893.7027 - val_loss: 302.3999\n",
      "Fold 1 Test Metrics:\n",
      "R\u00b2: 0.9621 | RMSE: 13.9573 | MAE: 10.9503 | SMAPE: 7.1866%\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "Baseline R\u00b2: 0.9621\n",
      "Permuting MLP features...\n",
      "Permuting GNN features...\n",
      "Permuting Raster features...\n",
      "\n",
      "--- Starting Fold 2/5 ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 143420.5781 - val_loss: 462871.4062\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 88884.4453 - val_loss: 12024.0039\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 21645.1719 - val_loss: 10728.4385\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8766.5488 - val_loss: 3293.3503\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 15319.0732 - val_loss: 1891.7793\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 4551.8501 - val_loss: 2138.1482\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 3043.9766 - val_loss: 1711.3531\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5444.2852 - val_loss: 1492.2670\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4890.0151 - val_loss: 1962.3336\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 3743.4058 - val_loss: 1980.0123\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 3413.6440 - val_loss: 2507.8591\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2207.3230 - val_loss: 3040.3518\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 2816.7683 - val_loss: 1579.3848\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1639.1614 - val_loss: 3434.7522\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1749.2128 - val_loss: 2641.2322\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 2267.7305 - val_loss: 1437.0536\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1922.8683 - val_loss: 1453.9183\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1581.6873 - val_loss: 1143.4137\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 2847.8008 - val_loss: 1690.1820\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1627.2867 - val_loss: 1575.7041\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1177.4574 - val_loss: 1586.6696\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1624.3079 - val_loss: 1335.3027\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1127.6401 - val_loss: 1726.6637\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 938.0930 - val_loss: 1674.4794\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1828.8795 - val_loss: 1249.6515\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1401.6500 - val_loss: 1074.6978\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 761.0744 - val_loss: 1693.3477\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 2136.2278 - val_loss: 1233.8131\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1220.9875 - val_loss: 972.8577\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1592.1174 - val_loss: 1444.4989\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 987.4435 - val_loss: 3083.3440\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1651.6722 - val_loss: 2252.6553\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 880.0179 - val_loss: 739.4962\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 885.2888 - val_loss: 4436.9731\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1715.4525 - val_loss: 1999.3965\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 938.8865 - val_loss: 2453.8040\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 575.2549 - val_loss: 1469.4930\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1070.1122 - val_loss: 2127.9060\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 780.4026 - val_loss: 1457.2583\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 806.7145 - val_loss: 1489.4258\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 508.3838 - val_loss: 1870.9047\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1327.1167 - val_loss: 1200.3574\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1050.7585 - val_loss: 2940.1980\n",
      "Fold 2 Test Metrics:\n",
      "R\u00b2: 0.8525 | RMSE: 27.1937 | MAE: 19.7629 | SMAPE: 12.0376%\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "Baseline R\u00b2: 0.8525\n",
      "Permuting MLP features...\n",
      "Permuting GNN features...\n",
      "Permuting Raster features...\n",
      "\n",
      "--- Starting Fold 3/5 ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 594712.0000 - val_loss: 67780.6719\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 256101.7969 - val_loss: 41270.5977\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 22654.4727 - val_loss: 24764.8750\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 15564.7314 - val_loss: 20555.1797\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5839.1016 - val_loss: 17465.2812\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 6442.4800 - val_loss: 13395.2500\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 7179.7832 - val_loss: 8981.3965\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 13172.3975 - val_loss: 4452.6924\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4461.6606 - val_loss: 2772.3052\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7952.8960 - val_loss: 3568.8984\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 8555.6602 - val_loss: 1941.9066\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 4758.4092 - val_loss: 2458.5002\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 3105.0981 - val_loss: 1669.9955\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 5101.2881 - val_loss: 1542.2469\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 2716.4656 - val_loss: 1486.6774\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 3916.0125 - val_loss: 3177.9624\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 3090.0627 - val_loss: 1880.3812\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1957.0631 - val_loss: 2390.3025\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 2350.0967 - val_loss: 1514.9821\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 2849.0356 - val_loss: 2094.9946\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 2374.4746 - val_loss: 2240.1443\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 2086.9197 - val_loss: 1314.2822\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1761.4755 - val_loss: 1567.4349\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 3449.6436 - val_loss: 1752.9388\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1888.5507 - val_loss: 2801.4380\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1899.8547 - val_loss: 3956.3638\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 2453.2334 - val_loss: 1798.8262\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1414.6139 - val_loss: 1726.0264\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1532.5940 - val_loss: 2114.8608\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1392.7224 - val_loss: 1135.0608\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 977.0100 - val_loss: 1090.4092\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1111.4774 - val_loss: 1861.8223\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1057.1368 - val_loss: 1173.3845\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1114.1306 - val_loss: 977.7371\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 937.9351 - val_loss: 795.1292\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1480.0294 - val_loss: 1999.5654\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1020.6857 - val_loss: 961.2593\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 893.1864 - val_loss: 700.5966\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 823.1116 - val_loss: 728.9222\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1317.9294 - val_loss: 1272.7440\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1101.6080 - val_loss: 968.4842\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 572.7518 - val_loss: 730.7414\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 578.7065 - val_loss: 646.7835\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 1291.4656 - val_loss: 639.2097\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1643.0785 - val_loss: 672.5515\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 629.5302 - val_loss: 669.6942\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 848.6220 - val_loss: 697.8061\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 918.1401 - val_loss: 611.0502\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 877.4592 - val_loss: 989.7523\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1227.7373 - val_loss: 852.9299\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1059.7594 - val_loss: 570.7476\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 830.2571 - val_loss: 523.4094\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 743.9649 - val_loss: 877.8282\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 850.8297 - val_loss: 461.9865\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1049.0248 - val_loss: 497.4578\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 760.3041 - val_loss: 530.9922\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 650.2819 - val_loss: 564.3302\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 634.2676 - val_loss: 531.8781\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1124.8856 - val_loss: 421.6647\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 966.3925 - val_loss: 372.6494\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 714.5583 - val_loss: 456.8061\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1334.4010 - val_loss: 411.3949\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 805.1320 - val_loss: 419.4993\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 680.5507 - val_loss: 522.5869\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 636.6712 - val_loss: 453.7431\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 561.5873 - val_loss: 463.8364\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 896.4738 - val_loss: 377.1574\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 700.2241 - val_loss: 345.9723\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 794.8486 - val_loss: 288.5561\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 472.7379 - val_loss: 289.6194\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 557.3872 - val_loss: 406.6852\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 546.7739 - val_loss: 465.7764\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 865.4267 - val_loss: 246.6598\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 936.4147 - val_loss: 288.7031\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 938.0784 - val_loss: 522.7245\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 958.3878 - val_loss: 317.4504\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 774.7795 - val_loss: 459.5658\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 628.6494 - val_loss: 559.5346\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 643.0770 - val_loss: 342.4533\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 801.2507 - val_loss: 459.9220\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 448.8218 - val_loss: 341.2704\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 524.2961 - val_loss: 331.6874\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 471.6642 - val_loss: 370.7976\n",
      "Fold 3 Test Metrics:\n",
      "R\u00b2: 0.9152 | RMSE: 15.7054 | MAE: 13.6975 | SMAPE: 9.3705%\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "Baseline R\u00b2: 0.9099\n",
      "Permuting MLP features...\n",
      "Permuting GNN features...\n",
      "Permuting Raster features...\n",
      "\n",
      "--- Starting Fold 4/5 ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 227258.7500 - val_loss: 302643.7500\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 60661.6797 - val_loss: 13965.1123\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 25852.3594 - val_loss: 3237.5366\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6948.4531 - val_loss: 2608.9937\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 18352.6289 - val_loss: 2660.5239\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4965.4980 - val_loss: 1824.3904\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 4126.8726 - val_loss: 1419.0815\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5822.2954 - val_loss: 1475.3627\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 2594.2117 - val_loss: 1033.2271\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2900.2043 - val_loss: 1504.2777\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2809.1721 - val_loss: 1213.5182\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 2627.3562 - val_loss: 2025.8459\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 2834.5527 - val_loss: 1164.3015\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 2616.3665 - val_loss: 790.9962\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 2081.1414 - val_loss: 772.6598\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 2197.9187 - val_loss: 764.9082\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1994.8149 - val_loss: 965.4274\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 2595.6597 - val_loss: 906.8383\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 3060.7546 - val_loss: 3050.1394\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 2308.5352 - val_loss: 671.2296\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1552.0640 - val_loss: 497.8276\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1458.3734 - val_loss: 494.7345\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1485.6750 - val_loss: 593.3438\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 2467.1357 - val_loss: 386.5897\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1187.5419 - val_loss: 431.6380\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1258.3447 - val_loss: 363.8257\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1054.0656 - val_loss: 605.3885\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1850.2849 - val_loss: 443.2527\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 915.2326 - val_loss: 836.4313\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1217.1195 - val_loss: 459.4998\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1061.2067 - val_loss: 275.9960\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1225.3101 - val_loss: 205.2266\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 1147.2968 - val_loss: 248.9123\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1075.7344 - val_loss: 262.1151\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1094.7527 - val_loss: 311.6838\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1283.5502 - val_loss: 201.2699\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 937.7375 - val_loss: 355.3286\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1842.5129 - val_loss: 538.2253\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 862.1873 - val_loss: 732.5118\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 761.4810 - val_loss: 1561.1516\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1311.1246 - val_loss: 1146.7844\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 853.6249 - val_loss: 1131.4780\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 669.7302 - val_loss: 496.1175\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1033.4106 - val_loss: 758.6149\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 785.2088 - val_loss: 256.5366\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1020.1866 - val_loss: 287.5290\n",
      "Fold 4 Test Metrics:\n",
      "R\u00b2: 0.9642 | RMSE: 14.1870 | MAE: 10.9991 | SMAPE: 6.2836%\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "Baseline R\u00b2: 0.9587\n",
      "Permuting MLP features...\n",
      "Permuting GNN features...\n",
      "Permuting Raster features...\n",
      "\n",
      "--- Starting Fold 5/5 ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 145525.4531 - val_loss: 19765.9160\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 132560.4062 - val_loss: 7110.1416\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 33191.6094 - val_loss: 7673.8955\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 14137.4346 - val_loss: 3024.1177\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 6926.7793 - val_loss: 3003.2993\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6690.0371 - val_loss: 1931.4629\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4265.2925 - val_loss: 1015.4894\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 6501.6504 - val_loss: 1078.9135\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2451.7688 - val_loss: 952.9697\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 3819.3008 - val_loss: 1282.5862\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 3076.6248 - val_loss: 606.1868\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 2352.2866 - val_loss: 414.3908\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 3053.2617 - val_loss: 2499.7559\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2156.6753 - val_loss: 202.3612\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 2518.6094 - val_loss: 326.3537\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 1895.4125 - val_loss: 314.5398\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1623.0216 - val_loss: 547.4663\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2066.0630 - val_loss: 265.4420\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2632.4128 - val_loss: 359.5557\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 1661.1356 - val_loss: 542.4720\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1797.7534 - val_loss: 362.8677\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 2265.4761 - val_loss: 1557.1891\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 2273.5996 - val_loss: 670.5400\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 1419.1920 - val_loss: 2077.8960\n",
      "Fold 5 Test Metrics:\n",
      "R\u00b2: 0.9609 | RMSE: 14.2254 | MAE: 11.7955 | SMAPE: 6.9776%\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "Baseline R\u00b2: 0.9594\n",
      "Permuting MLP features...\n",
      "Permuting GNN features...\n",
      "Permuting Raster features...\n",
      "\n",
      "================================================================================\n",
      "Final Cross-Validation Results (Averaged over 5 folds):\n",
      "================================================================================\n",
      "Average R\u00b2: 0.9310\n",
      "Average RMSE: 17.0537\n",
      "Average MAE: 13.4411\n",
      "Average SMAPE: 8.3712%\n",
      "\n",
      "--- Average Feature Importance (Permutation) ---\n",
      "Raster_SiltR.tif: 338.6204\n",
      "Raster_SandR.tif: 333.7619\n",
      "Raster_CdR.tif: 291.9129\n",
      "Raster_NiR.tif: 263.9737\n",
      "Raster_AsR.tif: 259.0488\n",
      "Raster_CuR.tif: 180.9664\n",
      "Raster_ClayR.tif: 152.9006\n",
      "Raster_Pb_R.tif: 130.4276\n",
      "Raster_CrR.tif: 126.2236\n",
      "MLP_PbR: 0.0241\n",
      "MLP_NiR: 0.0113\n",
      "MLP_CuR: 0.0095\n",
      "MLP_ClayR: 0.0092\n",
      "MLP_FeR: 0.0071\n",
      "MLP_CdR: 0.0053\n",
      "MLP_SandR: 0.0028\n",
      "MLP_MR: 0.0017\n",
      "MLP_hydro_dist_ind: 0.0011\n",
      "MLP_num_industry: 0.0005\n",
      "GNN: 0.0002\n",
      "Raster_bui.tif: 0.0000\n",
      "Raster_ndsi.tif: 0.0000\n",
      "Raster_savi.tif: 0.0000\n",
      "Raster_ndbsi.tif: 0.0000\n",
      "Raster_ui.tif: 0.0000\n",
      "Raster_ndwi.tif: 0.0000\n",
      "Raster_ndbi.tif: 0.0000\n",
      "Raster_awei.tif: 0.0000\n",
      "Raster_evi.tif: 0.0000\n",
      "Raster_mndwi.tif: 0.0000\n",
      "Raster_ndvi.tif: 0.0000\n",
      "Raster_LULC2020.tif: 0.0000\n",
      "Raster_LULC2021.tif: 0.0000\n",
      "Raster_LULC2022.tif: 0.0000\n",
      "Raster_LULC2019.tif: 0.0000\n",
      "Raster_LULC2018.tif: 0.0000\n",
      "Raster_LULC2017.tif: 0.0000\n",
      "MLP_AsR: -0.0001\n",
      "MLP_num_brick_field: -0.0001\n",
      "MLP_hydro_dist_brick: -0.0002\n",
      "MLP_SiltR: -0.0003\n",
      "MLP_CrR: -0.0008\n",
      "\n",
      "Analysis complete. Results are printed above.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "import sys\n",
    "import pickle # Import the pickle library for saving objects\n",
    "# Set a consistent seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: This script assumes the following file paths are correct.\n",
    "try:\n",
    "    orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "    river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Required data file not found. Please check your file paths.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    sys.exit()\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "# ==================== 2. Collect ALL Rasters and Metadata ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "# Get the pixel resolution from the first raster to set a uniform patch size\n",
    "try:\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        pixel_size = src.transform.a\n",
    "except IndexError:\n",
    "    print(\"Error: No raster files found in the specified directories.\")\n",
    "    sys.exit()\n",
    "# Create a dictionary to store raster metadata for fast access\n",
    "raster_metadata = {}\n",
    "for path in raster_paths:\n",
    "    with rasterio.open(path) as src:\n",
    "        raster_metadata[path] = {\n",
    "            'transform': src.transform,\n",
    "            'crs': src.crs,\n",
    "            'width': src.width,\n",
    "            'height': src.height\n",
    "        }\n",
    "# ==================== 3. Define a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Custom Keras Sequence for generating batches of data.\n",
    "    Handles three different input types: MLP features, GNN features,\n",
    "    and raster image patches, loading rasters on-the-fly to save memory.\n",
    "    \"\"\"\n",
    "    def __init__(self, mlp_data, gnn_data, y, coords, raster_paths, buffer_radius_m, pixel_size, batch_size=4, shuffle=True):\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.coords = coords\n",
    "        self.raster_paths = raster_paths\n",
    "        # Calculate the uniform patch size in pixels based on the buffer radius and pixel size\n",
    "        # We need a square patch, so the size is 2 * radius / pixel_size\n",
    "        self.patch_size = int(round((2 * buffer_radius_m) / pixel_size))\n",
    "        # Ensure patch size is at least 1 and is an even number for easy centering\n",
    "        if self.patch_size % 2 != 0:\n",
    "            self.patch_size += 1\n",
    "        self.patch_size = max(self.patch_size, 2)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def get_raster_patches(self, coords_batch):\n",
    "        \"\"\"\n",
    "        Extracts a patch of raster data for each coordinate in the batch.\n",
    "        Loads rasters on-the-fly to save memory and robustly handles boundaries.\n",
    "        \"\"\"\n",
    "        patches_for_rasters = []\n",
    "        for path in self.raster_paths:\n",
    "            patches_for_this_raster = []\n",
    "            try:\n",
    "                with rasterio.open(path) as src:\n",
    "                    for lon, lat in coords_batch:\n",
    "                        # Get pixel coordinates\n",
    "                        row, col = src.index(lon, lat)\n",
    "                        \n",
    "                        # Define a window to read around the pixel, handling boundaries\n",
    "                        half_patch = self.patch_size // 2\n",
    "                        left = int(col - half_patch)\n",
    "                        top = int(row - half_patch)\n",
    "                        right = int(col + half_patch)\n",
    "                        bottom = int(row + half_patch)\n",
    "                        # Create a new, empty array for the final padded patch\n",
    "                        padded_patch = np.zeros((self.patch_size, self.patch_size), dtype='float32')\n",
    "                        # Calculate the window in the raster's coordinate space to read from\n",
    "                        # And the offset in the padded_patch to write to\n",
    "                        read_left = max(0, left)\n",
    "                        read_top = max(0, top)\n",
    "                        read_right = min(src.width, right)\n",
    "                        read_bottom = min(src.height, bottom)\n",
    "                        # Check if the calculated window has a valid size\n",
    "                        read_width = read_right - read_left\n",
    "                        read_height = read_bottom - read_top\n",
    "                        \n",
    "                        if read_width > 0 and read_height > 0:\n",
    "                            write_left = read_left - left\n",
    "                            write_top = read_top - top\n",
    "                            write_right = write_left + read_width\n",
    "                            write_bottom = write_top + read_height\n",
    "                            # Create the window object for rasterio to read from\n",
    "                            window = Window(read_left, read_top, read_width, read_height)\n",
    "                            # Read the data from the raster\n",
    "                            patch_data = src.read(1, window=window)\n",
    "                            # Place the read data into the padded patch\n",
    "                            padded_patch[write_top:write_bottom, write_left:write_right] = patch_data\n",
    "                        \n",
    "                        patches_for_this_raster.append(padded_patch)\n",
    "            \n",
    "                # Stack the patches for this raster\n",
    "                patches_for_rasters.append(np.stack(patches_for_this_raster, axis=0))\n",
    "            except Exception as e:\n",
    "                # This handles cases where a raster file might be missing or corrupted\n",
    "                patches_for_rasters.append(np.zeros((len(coords_batch), self.patch_size, self.patch_size), dtype='float32'))\n",
    "        # Stack all raster patches together\n",
    "        final_patches = np.stack(patches_for_rasters, axis=-1)\n",
    "        return final_patches\n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        \n",
    "        # Get raster data for the current batch\n",
    "        batch_rasters = self.get_raster_patches(batch_coords)\n",
    "        \n",
    "        # Return a dictionary of inputs and the output\n",
    "        return {\"mlp_input\": batch_mlp, \"gnn_input\": batch_gnn, \"raster_input\": batch_rasters}, batch_y\n",
    "# ==================== 4. Define GNN-MLP-Raster Fusion Model ==================== #\n",
    "def build_fusion_model(mlp_dim, gnn_dim, raster_patch_size, num_rasters):\n",
    "    \"\"\"\n",
    "    Builds the multi-input Keras model with branches for MLP, GNN, and Rasters.\n",
    "    \"\"\"\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    raster_input = Input(shape=(raster_patch_size, raster_patch_size, num_rasters), name=\"raster_input\")\n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "    \n",
    "    # --- Raster Branch (using a simple CNN) ---\n",
    "    raster_conv = Conv2D(32, (3, 3), activation=\"relu\")(raster_input)\n",
    "    raster_pool = MaxPooling2D((2, 2))(raster_conv)\n",
    "    raster_conv = Conv2D(64, (3, 3), activation=\"relu\")(raster_pool)\n",
    "    raster_pool = MaxPooling2D((2, 2))(raster_conv)\n",
    "    raster_flatten = Flatten()(raster_pool)\n",
    "    raster_embedding = Dense(64, activation=\"relu\", name=\"raster_embedding\")(raster_flatten)\n",
    "    # --- Concatenate Embeddings ---\n",
    "    combined = Concatenate()([mlp_embedding, gnn_embedding, raster_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input, raster_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "# ==================== 5. Define Evaluation & Importance Functions ==================== #\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    \"\"\"Calculates Symmetric Mean Absolute Percentage Error (SMAPE).\"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    # Avoid division by zero\n",
    "    mask = denominator == 0\n",
    "    smape_val = np.where(mask, 0, numerator / denominator)\n",
    "    return 100 * np.mean(smape_val)\n",
    "def evaluate_model(model, data_inputs, y_test, return_preds=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on given data and returns R\u00b2, RMSE, MAE, and SMAPE.\n",
    "    Handles both Keras Generators and direct numpy arrays.\n",
    "    \"\"\"\n",
    "    if isinstance(data_inputs, DataGenerator):\n",
    "        y_pred = model.predict(data_inputs, verbose=0).flatten()\n",
    "    else:\n",
    "        y_pred = model.predict(data_inputs, verbose=0).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # Align true labels with predictions if using a generator\n",
    "        y_true_aligned = y_test[:len(y_pred)]\n",
    "        r2 = r2_score(y_true_aligned, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_aligned, y_pred))\n",
    "        mae = mean_absolute_error(y_true_aligned, y_pred)\n",
    "        smape = calculate_smape(y_true_aligned, y_pred)\n",
    "        return r2, rmse, mae, smape\n",
    "def calculate_permutation_importance(model, mlp_data, gnn_data, raster_data, y_true, mlp_features, raster_features):\n",
    "    \"\"\"\n",
    "    Calculates permutation feature importance for all individual features.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Permutation Feature Importance Analysis...\")\n",
    "    \n",
    "    # Create the combined input for the model\n",
    "    initial_inputs = {\"mlp_input\": mlp_data, \"gnn_input\": gnn_data, \"raster_input\": raster_data}\n",
    "    \n",
    "    # Get baseline R\u00b2 on the unshuffled data\n",
    "    baseline_r2, _, _, _ = evaluate_model(model, initial_inputs, y_true)\n",
    "    print(f\"Baseline R\u00b2: {baseline_r2:.4f}\")\n",
    "    \n",
    "    importance = {}\n",
    "    \n",
    "    # 1. Permute individual MLP features\n",
    "    print(\"Permuting MLP features...\")\n",
    "    for i, feature in enumerate(mlp_features):\n",
    "        shuffled_mlp_data = mlp_data.copy()\n",
    "        np.random.shuffle(shuffled_mlp_data[:, i])\n",
    "        shuffled_inputs = {\"mlp_input\": shuffled_mlp_data, \"gnn_input\": gnn_data, \"raster_input\": raster_data}\n",
    "        shuffled_r2, _, _, _ = evaluate_model(model, shuffled_inputs, y_true)\n",
    "        importance[f'MLP_{feature}'] = baseline_r2 - shuffled_r2\n",
    "    \n",
    "    # 2. Permute GNN input\n",
    "    print(\"Permuting GNN features...\")\n",
    "    shuffled_gnn_data = gnn_data.copy()\n",
    "    np.random.shuffle(shuffled_gnn_data)\n",
    "    shuffled_inputs = {\"mlp_input\": mlp_data, \"gnn_input\": shuffled_gnn_data, \"raster_input\": raster_data}\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, shuffled_inputs, y_true)\n",
    "    importance['GNN'] = baseline_r2 - shuffled_r2\n",
    "    \n",
    "    # 3. Permute Raster inputs\n",
    "    print(\"Permuting Raster features...\")\n",
    "    for i, feature in enumerate(raster_features):\n",
    "        shuffled_raster_data = raster_data.copy()\n",
    "        # Shuffle a single channel (raster band)\n",
    "        shuffled_raster_data[:, :, :, i] = np.random.permutation(shuffled_raster_data[:, :, :, i].flatten()).reshape(shuffled_raster_data.shape[0], shuffled_raster_data.shape[1], shuffled_raster_data.shape[2])\n",
    "        shuffled_inputs = {\"mlp_input\": mlp_data, \"gnn_input\": gnn_data, \"raster_input\": shuffled_raster_data}\n",
    "        shuffled_r2, _, _, _ = evaluate_model(model, shuffled_inputs, y_true)\n",
    "        importance[f'Raster_{os.path.basename(feature)}'] = baseline_r2 - shuffled_r2\n",
    "        \n",
    "    return importance\n",
    "# ==================== 6. Main Analysis with Train/Test CV ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP-Raster Fusion Model with 5-Fold Single Split\")\n",
    "print(f\"Using a uniform patch size of {int(round((2 * 500) / pixel_size))} pixels for a 500m buffer.\")\n",
    "print(\"=\"*80)\n",
    "# Combine all data for Train/Test splitting\n",
    "full_data = pd.concat([orig, river_100], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "full_coords = full_data[['Long','Lat']].values\n",
    "full_y = full_data['RI'].values\n",
    "full_mlp_data = full_data[numeric_cols].values\n",
    "full_raster_data = full_coords # This will be processed by the generator\n",
    "# Pre-process MLP data with StandardScaler\n",
    "scaler = StandardScaler()\n",
    "full_mlp_data = scaler.fit_transform(full_mlp_data)\n",
    "# Train/Test setup\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "all_feature_importances = {}\n",
    "buffer_radius_m = 500\n",
    "raster_patch_size = int(round((2 * buffer_radius_m) / pixel_size))\n",
    "if raster_patch_size % 2 != 0:\n",
    "    raster_patch_size += 1\n",
    "raster_patch_size = max(raster_patch_size, 2)\n",
    "num_rasters = len(raster_paths)\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(full_data)):\n",
    "    print(f\"\\n--- Starting Fold {fold+1}/{n_splits} ---\")\n",
    "    \n",
    "    # Get train and test data for this fold\n",
    "    train_mlp, test_mlp = full_mlp_data[train_index], full_mlp_data[test_index]\n",
    "    train_coords, test_coords = full_coords[train_index], full_coords[test_index]\n",
    "    y_train, y_test = full_y[train_index], full_y[test_index]\n",
    "    \n",
    "    # Prepare GNN input (adjacency matrix based on distances)\n",
    "    dist_mat_train = distance_matrix(train_coords, train_coords)\n",
    "    gnn_train = np.exp(-dist_mat_train / 10)\n",
    "    \n",
    "    dist_mat_test_train = distance_matrix(test_coords, train_coords)\n",
    "    gnn_test = np.exp(-dist_mat_test_train / 10)\n",
    "    # Clean up memory\n",
    "    del dist_mat_train, dist_mat_test_train\n",
    "    gc.collect()\n",
    "    # Re-build and compile the model for each fold\n",
    "    model = build_fusion_model(mlp_dim=train_mlp.shape[1], gnn_dim=gnn_train.shape[1], \n",
    "                               raster_patch_size=raster_patch_size, num_rasters=num_rasters)\n",
    "    \n",
    "    if fold == 0:\n",
    "        model.summary()\n",
    "    \n",
    "    # Create data generators\n",
    "    train_generator = DataGenerator(\n",
    "        mlp_data=train_mlp, gnn_data=gnn_train, y=y_train, coords=train_coords,\n",
    "        raster_paths=raster_paths, buffer_radius_m=buffer_radius_m, pixel_size=pixel_size, batch_size=4, shuffle=True\n",
    "    )\n",
    "    test_generator = DataGenerator(\n",
    "        mlp_data=test_mlp, gnn_data=gnn_test, y=y_test, coords=test_coords,\n",
    "        raster_paths=raster_paths, buffer_radius_m=buffer_radius_m, pixel_size=pixel_size, batch_size=4, shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=test_generator\n",
    "    )\n",
    "    # Evaluate on the test data\n",
    "    r2_test, rmse_test, mae_test, smape_test = evaluate_model(model, test_generator, y_test)\n",
    "    fold_results.append({'R2': r2_test, 'RMSE': rmse_test, 'MAE': mae_test, 'SMAPE': smape_test})\n",
    "    \n",
    "    print(f\"Fold {fold+1} Test Metrics:\")\n",
    "    print(f\"R\u00b2: {r2_test:.4f} | RMSE: {rmse_test:.4f} | MAE: {mae_test:.4f} | SMAPE: {smape_test:.4f}%\")\n",
    "    # Calculate and store feature importance for this fold\n",
    "    # Get all test data as numpy arrays for importance calculation\n",
    "    test_mlp_full = test_generator.mlp_data\n",
    "    test_gnn_full = test_generator.gnn_data\n",
    "    test_y_full = test_generator.y\n",
    "    test_coords_full = test_generator.coords\n",
    "    \n",
    "    # Create a single batch for raster data\n",
    "    test_rasters_full = test_generator.get_raster_patches(test_coords_full)\n",
    "    \n",
    "    importance = calculate_permutation_importance(model, test_mlp_full, test_gnn_full, test_rasters_full, test_y_full, numeric_cols, raster_paths)\n",
    "    for feature, score in importance.items():\n",
    "        if feature not in all_feature_importances:\n",
    "            all_feature_importances[feature] = []\n",
    "        all_feature_importances[feature].append(score)\n",
    "    del model, history, train_generator, test_generator\n",
    "    gc.collect()\n",
    "# Calculate and print final averages\n",
    "avg_results = pd.DataFrame(fold_results).mean()\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Final Single Split Results (Averaged over {n_splits} folds):\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Average R\u00b2: {avg_results['R2']:.4f}\")\n",
    "print(f\"Average RMSE: {avg_results['RMSE']:.4f}\")\n",
    "print(f\"Average MAE: {avg_results['MAE']:.4f}\")\n",
    "print(f\"Average SMAPE: {avg_results['SMAPE']:.4f}%\")\n",
    "# Calculate and print average feature importance\n",
    "print(\"\\n--- Average Feature Importance (Permutation) ---\")\n",
    "avg_importance = {k: np.mean(v) for k, v in all_feature_importances.items()}\n",
    "sorted_importance = sorted(avg_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, score in sorted_importance:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "# ==================== 7. Save all info to a folder ==================== #\n",
    "# NOTE: Removed the file saving functionality as requested. The output is now\n",
    "# printed directly to the console.\n",
    "print(\"\\nAnalysis complete. Results are printed above.\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a98a2fd-2a6b-4b98-9e02-c62a60b9c79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data is not used in this GNN-MLP model.\n",
      "\n",
      "================================================================================\n",
      "Analyzing GNN-MLP Fusion Model\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503<span style=\"font-weight: bold\"> Layer (type)        </span>\u2503<span style=\"font-weight: bold\"> Output Shape      </span>\u2503<span style=\"font-weight: bold\">    Param # </span>\u2503<span style=\"font-weight: bold\"> Connected to      </span>\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 mlp_input           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_input           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \u2502 mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> \u2502 gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_embedding       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \u2502 dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_embedding       \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \u2502 dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 concatenate         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 mlp_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       \u2502                   \u2502            \u2502 gnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \u2502 concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \u2502 dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 final_output        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         \u2502         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \u2502 dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \u2502\n",
       "\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502 mlp_input           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_input           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n",
       "\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense (\u001b[38;5;33mDense\u001b[0m)       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502      \u001b[38;5;34m2,048\u001b[0m \u2502 mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_1 (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502     \u001b[38;5;34m14,208\u001b[0m \u2502 gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 mlp_embedding       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m8,256\u001b[0m \u2502 dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 gnn_embedding       \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m8,256\u001b[0m \u2502 dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 concatenate         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 mlp_embedding[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u2502 (\u001b[38;5;33mConcatenate\u001b[0m)       \u2502                   \u2502            \u2502 gnn_embedding[\u001b[38;5;34m0\u001b[0m]\u2026 \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_2 (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502     \u001b[38;5;34m16,512\u001b[0m \u2502 concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dropout (\u001b[38;5;33mDropout\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       \u2502          \u001b[38;5;34m0\u001b[0m \u2502 dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 dense_3 (\u001b[38;5;33mDense\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        \u2502      \u001b[38;5;34m8,256\u001b[0m \u2502 dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
       "\u2502 final_output        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         \u2502         \u001b[38;5;34m65\u001b[0m \u2502 dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \u2502\n",
       "\u2502 (\u001b[38;5;33mDense\u001b[0m)             \u2502                   \u2502            \u2502                   \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,601</span> (225.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,601\u001b[0m (225.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,601</span> (225.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,601\u001b[0m (225.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 34869.8086 - val_loss: 27263.4980\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22140.6328 - val_loss: 4379.2148\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6086.4219 - val_loss: 3959.1904\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4269.3799 - val_loss: 2795.8623\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3444.9170 - val_loss: 1546.6180\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1516.3749 - val_loss: 739.7513\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 984.8546 - val_loss: 492.2373\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1120.9398 - val_loss: 432.6407\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1244.4910 - val_loss: 330.7098\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1000.5280 - val_loss: 358.6404\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 937.8305 - val_loss: 265.6169\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 697.1331 - val_loss: 263.8956\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 858.1591 - val_loss: 251.7075\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 756.8206 - val_loss: 289.9380\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 645.9982 - val_loss: 172.8805\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 579.0536 - val_loss: 177.2223\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 556.3744 - val_loss: 190.7613\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 595.7156 - val_loss: 187.0734\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 725.0087 - val_loss: 233.7430\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 575.6282 - val_loss: 133.0437\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 548.2478 - val_loss: 172.5680\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 823.0203 - val_loss: 134.8356\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 707.1078 - val_loss: 284.3262\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 711.5809 - val_loss: 103.2103\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 683.5203 - val_loss: 94.5982\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514.7531 - val_loss: 99.0470\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 590.0814 - val_loss: 99.7877\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 583.7627 - val_loss: 81.4177\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 580.8514 - val_loss: 74.5204\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 703.7590 - val_loss: 66.3046\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 472.6118 - val_loss: 72.6664\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 438.8012 - val_loss: 119.6753\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549.1289 - val_loss: 113.9504\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 886.8763 - val_loss: 71.9953\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 472.2539 - val_loss: 97.7964\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 367.3943 - val_loss: 160.1549\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 563.3185 - val_loss: 71.5966\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 549.2110 - val_loss: 147.5350\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 414.5316 - val_loss: 110.5732\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 629.6912 - val_loss: 55.2842\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 538.7237 - val_loss: 86.4305\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 567.3627 - val_loss: 231.5479\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 500.2021 - val_loss: 80.4254\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 598.6512 - val_loss: 113.0004\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 380.9169 - val_loss: 72.4743\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 472.3493 - val_loss: 37.5611\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 313.1037 - val_loss: 36.2351\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 280.3429 - val_loss: 44.1539\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486.1622 - val_loss: 193.8652\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 640.7919 - val_loss: 50.9757\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 289.8378 - val_loss: 74.8253\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 366.5481 - val_loss: 42.7818\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 528.3158 - val_loss: 133.4993\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 528.0286 - val_loss: 365.6050\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 697.7337 - val_loss: 60.5882\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 390.6406 - val_loss: 104.5864\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 318.7555 - val_loss: 55.8557\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 324.5998 - val_loss: 98.7786\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 412.2546 - val_loss: 117.7382\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 467.1036 - val_loss: 57.5950\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 259.1342 - val_loss: 118.5118\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 428.0603 - val_loss: 163.1122\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      " GNN-MLP Fusion Model Performance:\n",
      "R\u00b2 Train: -0.9373 | RMSE Train: 95.0370 | MAE Train: 68.8006 | SMAPE Train: 36.3338\n",
      "R\u00b2 Test: 0.9519 | RMSE Test: 17.3337 | MAE Test: 15.7284 | SMAPE Test: 10.9342\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Baseline R\u00b2 on test set: 0.9519\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "--- Feature Importance (Permutation) ---\n",
      "MLP: 1.8987\n",
      "GNN: 0.0011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pickle # Import the pickle library for saving objects\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# We are not using rasters in this GNN-MLP model, but the paths are still\n",
    "# defined for consistency with previous versions.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(\"Note: Raster data is not used in this GNN-MLP model.\")\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define GNN-MLP Fusion Model ==================== #\n",
    "def build_gnn_mlp_model(mlp_dim, gnn_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Concatenate Embeddings ---\n",
    "    combined = Concatenate()([mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, mlp_test, gnn_test_matrix, y_test, return_preds=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on given data and returns R\u00b2, RMSE, MAE, SMAPE, and predictions.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict((mlp_test, gnn_test_matrix)).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # Calculate R-squared and RMSE\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        # Calculate Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # Calculate Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "        # Add a small epsilon to the denominator to avoid division by zero\n",
    "        denominator = np.abs(y_test) + np.abs(y_pred)\n",
    "        smape = np.mean(2 * np.abs(y_pred - y_test) / (denominator + 1e-8)) * 100\n",
    "        \n",
    "        return r2, rmse, mae, smape\n",
    "\n",
    "def calculate_permutation_importance(model, mlp_data, gnn_data, y_true):\n",
    "    \"\"\"\n",
    "    Calculates permutation feature importance for the MLP and GNN branches.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Permutation Feature Importance Analysis...\")\n",
    "    # Get baseline R\u00b2 on the unshuffled data\n",
    "    baseline_r2, _, _, _ = evaluate_model(model, mlp_data, gnn_data, y_true)\n",
    "    print(f\"Baseline R\u00b2 on test set: {baseline_r2:.4f}\")\n",
    "\n",
    "    importance = {}\n",
    "    \n",
    "    # Permute MLP input\n",
    "    shuffled_mlp_data = mlp_data.copy()\n",
    "    np.random.shuffle(shuffled_mlp_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, shuffled_mlp_data, gnn_data, y_true)\n",
    "    importance['MLP'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    # Permute GNN input\n",
    "    shuffled_gnn_data = gnn_data.copy()\n",
    "    np.random.shuffle(shuffled_gnn_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, mlp_data, shuffled_gnn_data, y_true)\n",
    "    importance['GNN'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    return importance\n",
    "        \n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP Fusion Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_gnn_mlp_model(mlp_input_dim, gnn_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate & Perform Feature Importance ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "mae_train = mean_absolute_error(y_train[:len(y_pred_train)], y_pred_train)\n",
    "denominator_train = np.abs(y_train[:len(y_pred_train)]) + np.abs(y_pred_train)\n",
    "smape_train = np.mean(2 * np.abs(y_pred_train - y_train[:len(y_pred_train)]) / (denominator_train + 1e-8)) * 100\n",
    "\n",
    "# Evaluate on the test data using the updated function\n",
    "r2_test, rmse_test, mae_test, smape_test = evaluate_model(model, mlp_test, gnn_test, y_test)\n",
    "y_pred_test = evaluate_model(model, mlp_test, gnn_test, y_test, return_preds=True)\n",
    "\n",
    "print(f\"\\n GNN-MLP Fusion Model Performance:\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f} | MAE Train: {mae_train:.4f} | SMAPE Train: {smape_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f} | MAE Test: {mae_test:.4f} | SMAPE Test: {smape_test:.4f}\")\n",
    "\n",
    "feature_importance = calculate_permutation_importance(model, mlp_test, gnn_test, y_test)\n",
    "print(\"\\n--- Feature Importance (Permutation) ---\")\n",
    "sorted_importance = sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, score in sorted_importance:\n",
    "    print(f\"{feature}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be42ef-8f67-4712-967c-a0b794d3a68d",
   "metadata": {},
   "source": [
    "#### GNN MLP is the fastest runned code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84609e6c-de15-45e3-bf50-2e7d70598742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data is not used in this GNN-MLP model.\n",
      "\n",
      "================================================================================\n",
      "Analyzing GNN-MLP Fusion Model\n",
      "================================================================================\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      " GNN-MLP Fusion Model Performance:\n",
      "R\u00b2 Train: -1.1912 | RMSE Train: 101.0737 | MAE Train: 79.0743 | SMAPE Train: 42.1135\n",
      "R\u00b2 Test: 0.9687 | RMSE Test: 13.9777 | MAE Test: 11.3563 | SMAPE Test: 7.1694\n",
      "\n",
      "--- Permutation-based Feature Importance ---\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Baseline R\u00b2 on test set: 0.9687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "MLP: 1.7868\n",
      "GNN: 0.0019\n",
      "\n",
      "--- Intrinsic Feature Importance (Gradient Boosting) ---\n",
      "\n",
      "Training a Gradient Boosting Regressor on the MLP features...\n",
      "PbR: 0.8533\n",
      "NiR: 0.0988\n",
      "AsR: 0.0128\n",
      "CrR: 0.0121\n",
      "CuR: 0.0117\n",
      "CdR: 0.0035\n",
      "SiltR: 0.0031\n",
      "SandR: 0.0020\n",
      "hydro_dist_ind: 0.0012\n",
      "ClayR: 0.0005\n",
      "FeR: 0.0005\n",
      "MR: 0.0004\n",
      "hydro_dist_brick: 0.0001\n",
      "num_brick_field: 0.0000\n",
      "num_industry: 0.0000\n",
      "\n",
      "--- LIME Explanation for a single test point (index 3) ---\n",
      "\n",
      "Generating LIME explanation for a single data point...\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Feature: PbR > 0.63 | Weight: 45.7077\n",
      "Feature: FeR > 1.13 | Weight: 17.1990\n",
      "Feature: num_industry > 7.73 | Weight: 16.3417\n",
      "Feature: ClayR > -0.24 | Weight: 7.4671\n",
      "Feature: -0.03 < CuR <= 0.07 | Weight: -6.5905\n",
      "Feature: SiltR > 0.33 | Weight: -6.2936\n",
      "Feature: num_brick_field > 7.99 | Weight: -5.6863\n",
      "Feature: -0.11 < NiR <= 1.28 | Weight: 5.4198\n",
      "Feature: -0.68 < CdR <= 0.13 | Weight: -5.0643\n",
      "Feature: hydro_dist_ind <= -0.89 | Weight: -1.9134\n",
      "Feature: CrR <= -0.70 | Weight: -1.7367\n",
      "Feature: MR > 0.81 | Weight: 1.5458\n",
      "Feature: -1.14 < hydro_dist_brick <= -1.14 | Weight: -1.0697\n",
      "Feature: -1.00 < SandR <= 1.43 | Weight: 0.7463\n",
      "Feature: -0.58 < AsR <= 0.82 | Weight: -0.4704\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingRegressor # For intrinsic importance\n",
    "import lime # For LIME importance\n",
    "from lime import lime_tabular # For LIME importance\n",
    "import gc\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# We are not using rasters in this GNN-MLP model, but the paths are still\n",
    "# defined for consistency with previous versions.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(\"Note: Raster data is not used in this GNN-MLP model.\")\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define GNN-MLP Fusion Model ==================== #\n",
    "def build_gnn_mlp_model(mlp_dim, gnn_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Concatenate Embeddings ---\n",
    "    combined = Concatenate()([mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, mlp_test, gnn_test_matrix, y_test, return_preds=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on given data and returns R\u00b2, RMSE, MAE, SMAPE, and predictions.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict((mlp_test, gnn_test_matrix)).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # Calculate R-squared and RMSE\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        # Calculate Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # Calculate Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "        # Add a small epsilon to the denominator to avoid division by zero\n",
    "        denominator = np.abs(y_test) + np.abs(y_pred)\n",
    "        smape = np.mean(2 * np.abs(y_pred - y_test) / (denominator + 1e-8)) * 100\n",
    "        \n",
    "        return r2, rmse, mae, smape\n",
    "\n",
    "def calculate_permutation_importance(model, mlp_data, gnn_data, y_true):\n",
    "    \"\"\"\n",
    "    Calculates permutation feature importance for the MLP and GNN branches.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Permutation Feature Importance Analysis...\")\n",
    "    # Get baseline R\u00b2 on the unshuffled data\n",
    "    baseline_r2, _, _, _ = evaluate_model(model, mlp_data, gnn_data, y_true)\n",
    "    print(f\"Baseline R\u00b2 on test set: {baseline_r2:.4f}\")\n",
    "\n",
    "    importance = {}\n",
    "    \n",
    "    # Permute MLP input\n",
    "    shuffled_mlp_data = mlp_data.copy()\n",
    "    np.random.shuffle(shuffled_mlp_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, shuffled_mlp_data, gnn_data, y_true)\n",
    "    importance['MLP'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    # Permute GNN input\n",
    "    shuffled_gnn_data = gnn_data.copy()\n",
    "    np.random.shuffle(shuffled_gnn_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, mlp_data, shuffled_gnn_data, y_true)\n",
    "    importance['GNN'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    return importance\n",
    "\n",
    "def calculate_intrinsic_importance(mlp_data, y_true, feature_names):\n",
    "    \"\"\"\n",
    "    Calculates intrinsic feature importance using a tree-based model.\n",
    "    \"\"\"\n",
    "    print(\"\\nTraining a Gradient Boosting Regressor on the MLP features...\")\n",
    "    gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gbr.fit(mlp_data, y_true)\n",
    "    \n",
    "    importance = {}\n",
    "    for i, name in enumerate(feature_names):\n",
    "        importance[name] = gbr.feature_importances_[i]\n",
    "    return importance\n",
    "\n",
    "def get_lime_explanation(model, mlp_data, gnn_data, feature_names, sample_index):\n",
    "    \"\"\"\n",
    "    Generates a LIME explanation for a single data point.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating LIME explanation for a single data point...\")\n",
    "    \n",
    "    # Create a wrapper prediction function for LIME\n",
    "    # The wrapper takes only the MLP data and combines it with the GNN data\n",
    "    # for the main model's prediction.\n",
    "    def predict_fn(x):\n",
    "        # We need to reshape x to be a 2D array if it's not already\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        # Create the full input for the GNN-MLP model\n",
    "        gnn_input_for_lime = np.tile(gnn_data[sample_index:sample_index+1, :], (x.shape[0], 1))\n",
    "        # Predict using the full model\n",
    "        return model.predict([x, gnn_input_for_lime])\n",
    "    \n",
    "    # Initialize the LIME explainer\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=mlp_data,\n",
    "        feature_names=list(feature_names),\n",
    "        mode='regression',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Explain the selected instance\n",
    "    explanation = explainer.explain_instance(\n",
    "        data_row=mlp_data[sample_index],\n",
    "        predict_fn=predict_fn,\n",
    "        num_features=len(feature_names),\n",
    "        num_samples=5000 # Increase samples for better stability\n",
    "    )\n",
    "    \n",
    "    # Extract the feature weights\n",
    "    lime_weights = explanation.as_list()\n",
    "    return lime_weights\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP Fusion Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_gnn_mlp_model(mlp_input_dim, gnn_input_dim)\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate & Perform Feature Importance ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "mae_train = mean_absolute_error(y_train[:len(y_pred_train)], y_pred_train)\n",
    "denominator_train = np.abs(y_train[:len(y_pred_train)]) + np.abs(y_pred_train)\n",
    "smape_train = np.mean(2 * np.abs(y_pred_train - y_train[:len(y_pred_train)]) / (denominator_train + 1e-8)) * 100\n",
    "\n",
    "# Evaluate on the test data using the updated function\n",
    "r2_test, rmse_test, mae_test, smape_test = evaluate_model(model, mlp_test, gnn_test, y_test)\n",
    "y_pred_test = evaluate_model(model, mlp_test, gnn_test, y_test, return_preds=True)\n",
    "\n",
    "print(f\"\\n GNN-MLP Fusion Model Performance:\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f} | MAE Train: {mae_train:.4f} | SMAPE Train: {smape_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f} | MAE Test: {mae_test:.4f} | SMAPE Test: {smape_test:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate and print feature importance\n",
    "print(\"\\n--- Permutation-based Feature Importance ---\")\n",
    "feature_importance_perm = calculate_permutation_importance(model, mlp_test, gnn_test, y_test)\n",
    "sorted_importance_perm = sorted(feature_importance_perm.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, score in sorted_importance_perm:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "print(\"\\n--- Intrinsic Feature Importance (Gradient Boosting) ---\")\n",
    "feature_importance_intrinsic = calculate_intrinsic_importance(mlp_train, y_train, numeric_cols)\n",
    "sorted_importance_intrinsic = sorted(feature_importance_intrinsic.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, score in sorted_importance_intrinsic:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "    \n",
    "# Get LIME explanation for a single test point\n",
    "lime_sample_index = np.random.randint(0, len(mlp_test))\n",
    "print(f\"\\n--- LIME Explanation for a single test point (index {lime_sample_index}) ---\")\n",
    "lime_explanation = get_lime_explanation(model, mlp_test, gnn_test, numeric_cols, lime_sample_index)\n",
    "for feature, weight in lime_explanation:\n",
    "    print(f\"Feature: {feature} | Weight: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc61dde-07e2-4159-9ae0-f58165646b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data will now be integrated into the MLP input.\n",
      "Found 26 raster files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Analyzing GNN-MLP Fusion Model with Raster Data\n",
      "================================================================================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/1933853490.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 33249.9336 - val_loss: 30478.7344\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27342.2598 - val_loss: 8082.3784\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6094.9326 - val_loss: 3694.0234\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3800.7034 - val_loss: 2338.7400\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2502.9082 - val_loss: 1227.0741\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1752.1050 - val_loss: 657.3976\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242.1130 - val_loss: 570.2490\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1030.2278 - val_loss: 397.0659\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1057.2302 - val_loss: 413.1942\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 802.7853 - val_loss: 309.0204\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 540.7701 - val_loss: 288.9327\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 661.9765 - val_loss: 226.6628\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.4478 - val_loss: 279.1385\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 834.8066 - val_loss: 176.1626\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 773.5718 - val_loss: 259.1441\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 757.5969 - val_loss: 151.9990\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 548.4001 - val_loss: 157.2304\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 589.3400 - val_loss: 137.7976\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 700.9227 - val_loss: 116.4009\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 580.2036 - val_loss: 373.7668\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 788.0535 - val_loss: 105.4288\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 630.9600 - val_loss: 84.8311\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 495.7552 - val_loss: 112.4447\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 432.8104 - val_loss: 78.3544\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 503.0136 - val_loss: 84.2377\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 419.3063 - val_loss: 137.0889\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 575.5599 - val_loss: 72.1302\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 451.5682 - val_loss: 82.0880\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477.7957 - val_loss: 60.3073\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.6702 - val_loss: 72.5024\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.0954 - val_loss: 86.7249\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 560.4398 - val_loss: 104.0205\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 521.4862 - val_loss: 60.3260\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 486.4398 - val_loss: 117.4423\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.8063 - val_loss: 88.0446\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 678.9200 - val_loss: 59.2054\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.3849 - val_loss: 96.4844\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 341.0206 - val_loss: 171.8588\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357.5263 - val_loss: 86.9406\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.0140 - val_loss: 64.5112\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 551.0877 - val_loss: 78.5044\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.6908 - val_loss: 33.1069\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320.2657 - val_loss: 65.5183\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 546.4749 - val_loss: 69.3669\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 578.3353 - val_loss: 50.0629\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409.6041 - val_loss: 31.2390\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.2596 - val_loss: 25.5590\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 555.9518 - val_loss: 77.7961\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.2336 - val_loss: 31.9233\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349.6433 - val_loss: 100.9889\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509.1860 - val_loss: 96.8967\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 502.2556 - val_loss: 129.3776\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.8797 - val_loss: 59.6268\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.9068 - val_loss: 203.6690\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 519.8388 - val_loss: 208.2652\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 439.4771 - val_loss: 116.5886\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.4166 - val_loss: 103.3095\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443.8224 - val_loss: 23.7811\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.2181 - val_loss: 66.8741\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.5097 - val_loss: 31.4240\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.8200 - val_loss: 175.2425\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 322.9990 - val_loss: 84.5095\n",
      "Epoch 63/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.2253 - val_loss: 131.2309\n",
      "Epoch 64/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.9240 - val_loss: 75.1420\n",
      "Epoch 65/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.3198 - val_loss: 64.1434\n",
      "Epoch 66/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.9845 - val_loss: 322.4435\n",
      "Epoch 67/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301.3487 - val_loss: 83.3971\n",
      "Epoch 68/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 519.6960 - val_loss: 42.2663\n",
      "Epoch 69/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.0585 - val_loss: 57.0547\n",
      "Epoch 70/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367.9246 - val_loss: 109.5357\n",
      "Epoch 71/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 488.0986 - val_loss: 89.6480\n",
      "Epoch 72/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 537.8813 - val_loss: 34.6912\n",
      "Epoch 73/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316.9601 - val_loss: 78.0486\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      " GNN-MLP Fusion Model Performance:\n",
      "R\u00b2 Train: -0.5179 | RMSE Train: 84.1228 | MAE Train: 59.4919 | SMAPE Train: 31.0108\n",
      "R\u00b2 Test: 0.9280 | RMSE Test: 21.2233 | MAE Test: 18.7983 | SMAPE Test: 10.6927\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingRegressor # For intrinsic importance\n",
    "import lime # For LIME importance\n",
    "from lime import lime_tabular # For LIME importance\n",
    "import gc\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# We assume the data files are in the correct relative paths.\n",
    "try:\n",
    "    orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "    river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Required data file not found. Please ensure the files are at the correct paths.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI').tolist()\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "# Use os.path.join for robust path handling\n",
    "base_dir = \"../\"\n",
    "raster_paths += glob.glob(os.path.join(base_dir, \"CalIndices\", \"*.tif\"))\n",
    "raster_paths += glob.glob(os.path.join(base_dir, \"LULCMerged\", \"*.tif\"))\n",
    "raster_paths += glob.glob(os.path.join(base_dir, \"IDW\", \"*.tif\"))\n",
    "\n",
    "print(\"Note: Raster data will now be integrated into the MLP input.\")\n",
    "print(f\"Found {len(raster_paths)} raster files.\")\n",
    "\n",
    "# ==================== 3. Function to extract raster values using a buffer ==================== #\n",
    "def sample_rasters_with_buffer(df, raster_paths, buffer_meters):\n",
    "    \"\"\"\n",
    "    Extracts raster values by calculating the mean within a circular buffer\n",
    "    around each (Lat, Long) point.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'Lat' and 'Long' columns.\n",
    "        raster_paths (list): List of paths to raster files.\n",
    "        buffer_meters (int): The radius of the buffer in meters.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with a new column for each raster's aggregated value.\n",
    "    \"\"\"\n",
    "    raster_values = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for path in raster_paths:\n",
    "        try:\n",
    "            with rasterio.open(path) as src:\n",
    "                # Get the pixel size (resolution)\n",
    "                pixel_size_x, pixel_size_y = src.res\n",
    "                \n",
    "                # Convert the buffer in meters to pixels\n",
    "                buffer_pixels_x = int(np.ceil(buffer_meters / pixel_size_x))\n",
    "                buffer_pixels_y = int(np.ceil(buffer_meters / pixel_size_y))\n",
    "                \n",
    "                aggregated_data = []\n",
    "                for _, row in df.iterrows():\n",
    "                    long, lat = row['Long'], row['Lat']\n",
    "                    \n",
    "                    # Convert coordinates to raster indices (row, col)\n",
    "                    row_idx, col_idx = src.index(long, lat)\n",
    "                    \n",
    "                    # Define the window to read from the raster\n",
    "                    window = Window(\n",
    "                        col_off=col_idx - buffer_pixels_x,\n",
    "                        row_off=row_idx - buffer_pixels_y,\n",
    "                        width=2 * buffer_pixels_x + 1,\n",
    "                        height=2 * buffer_pixels_y + 1\n",
    "                    )\n",
    "                    \n",
    "                    # Read the data from the defined window\n",
    "                    try:\n",
    "                        data = src.read(1, window=window)\n",
    "                        # Calculate the mean of the pixels within the window\n",
    "                        # Use np.nanmean to handle NoData values\n",
    "                        aggregated_value = np.nanmean(data)\n",
    "                        aggregated_data.append(aggregated_value)\n",
    "                    except rasterio.errors.WindowError:\n",
    "                        # If the window goes outside the raster bounds, append NaN\n",
    "                        aggregated_data.append(np.nan)\n",
    "                \n",
    "                # Get a clean name for the new column\n",
    "                raster_name = os.path.splitext(os.path.basename(path))[0]\n",
    "                raster_values[raster_name] = aggregated_data\n",
    "\n",
    "        except rasterio.RasterioIOError:\n",
    "            print(f\"Warning: Could not open or read raster file at {path}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {path}: {e}\")\n",
    "            \n",
    "    return raster_values\n",
    "\n",
    "# ==================== 4. Extract Raster Data and Merge with Main Data ==================== #\n",
    "# Extract raster data for both training and testing sets\n",
    "train_raster_data = sample_rasters_with_buffer(train_combined, raster_paths, BUFFER_METERS)\n",
    "test_raster_data = sample_rasters_with_buffer(test_orig, raster_paths, BUFFER_METERS)\n",
    "\n",
    "# Now, we combine the original numeric features with the new raster features\n",
    "# Note: We must handle NaNs, as they can occur if a point is outside a raster's bounds.\n",
    "# A simple fillna(0) is used here, but a more sophisticated imputation might be needed.\n",
    "train_combined_with_rasters = pd.concat([train_combined, train_raster_data], axis=1).fillna(0)\n",
    "test_orig_with_rasters = pd.concat([test_orig, test_raster_data], axis=1).fillna(0)\n",
    "\n",
    "# Update the list of numeric columns to include the new raster features\n",
    "raster_cols = train_raster_data.columns.tolist()\n",
    "all_numeric_cols = numeric_cols + raster_cols\n",
    "\n",
    "# ==================== 5. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 6. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined_with_rasters[['Long','Lat']].values\n",
    "coords_test = test_orig_with_rasters[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# The scaler now fits on the combined original + raster data\n",
    "mlp_train = scaler.fit_transform(train_combined_with_rasters[all_numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig_with_rasters[all_numeric_cols])\n",
    "y_train = train_combined_with_rasters['RI'].values\n",
    "y_test = test_orig_with_rasters['RI'].values\n",
    "\n",
    "# ==================== 7. Define GNN-MLP Fusion Model ==================== #\n",
    "def build_gnn_mlp_model(mlp_dim, gnn_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Concatenate Embeddings ---\n",
    "    combined = Concatenate()([mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, mlp_test, gnn_test_matrix, y_test, return_preds=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on given data and returns R\u00b2, RMSE, MAE, SMAPE, and predictions.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict((mlp_test, gnn_test_matrix)).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # Calculate R-squared and RMSE\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        # Calculate Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # Calculate Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "        # Add a small epsilon to the denominator to avoid division by zero\n",
    "        denominator = np.abs(y_test) + np.abs(y_pred)\n",
    "        smape = np.mean(2 * np.abs(y_pred - y_test) / (denominator + 1e-8)) * 100\n",
    "        \n",
    "        return r2, rmse, mae, smape\n",
    "\n",
    "def calculate_permutation_importance(model, mlp_data, gnn_data, y_true):\n",
    "    \"\"\"\n",
    "    Calculates permutation feature importance for the MLP and GNN branches.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Permutation Feature Importance Analysis...\")\n",
    "    # Get baseline R\u00b2 on the unshuffled data\n",
    "    baseline_r2, _, _, _ = evaluate_model(model, mlp_data, gnn_data, y_true)\n",
    "    print(f\"Baseline R\u00b2 on test set: {baseline_r2:.4f}\")\n",
    "\n",
    "    importance = {}\n",
    "    \n",
    "    # Permute MLP input\n",
    "    shuffled_mlp_data = mlp_data.copy()\n",
    "    np.random.shuffle(shuffled_mlp_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, shuffled_mlp_data, gnn_data, y_true)\n",
    "    importance['MLP'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    # Permute GNN input\n",
    "    shuffled_gnn_data = gnn_data.copy()\n",
    "    np.random.shuffle(shuffled_gnn_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, mlp_data, shuffled_gnn_data, y_true)\n",
    "    importance['GNN'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    return importance\n",
    "\n",
    "def calculate_intrinsic_importance(mlp_data, y_true, feature_names):\n",
    "    \"\"\"\n",
    "    Calculates intrinsic feature importance using a tree-based model.\n",
    "    \"\"\"\n",
    "    print(\"\\nTraining a Gradient Boosting Regressor on the MLP features...\")\n",
    "    gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gbr.fit(mlp_data, y_true)\n",
    "    \n",
    "    importance = {}\n",
    "    for i, name in enumerate(feature_names):\n",
    "        importance[name] = gbr.feature_importances_[i]\n",
    "    return importance\n",
    "\n",
    "def get_lime_explanation(model, mlp_data, gnn_data, feature_names, sample_index):\n",
    "    \"\"\"\n",
    "    Generates a LIME explanation for a single data point.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating LIME explanation for a single data point...\")\n",
    "    \n",
    "    # Create a wrapper prediction function for LIME\n",
    "    # The wrapper takes only the MLP data and combines it with the GNN data\n",
    "    # for the main model's prediction.\n",
    "    def predict_fn(x):\n",
    "        # We need to reshape x to be a 2D array if it's not already\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        # Create the full input for the GNN-MLP model\n",
    "        gnn_input_for_lime = np.tile(gnn_data[sample_index:sample_index+1, :], (x.shape[0], 1))\n",
    "        # Predict using the full model\n",
    "        return model.predict([x, gnn_input_for_lime])\n",
    "    \n",
    "    # Initialize the LIME explainer\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=mlp_data,\n",
    "        feature_names=list(feature_names),\n",
    "        mode='regression',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Explain the selected instance\n",
    "    explanation = explainer.explain_instance(\n",
    "        data_row=mlp_data[sample_index],\n",
    "        predict_fn=predict_fn,\n",
    "        num_features=len(feature_names),\n",
    "        num_samples=5000 # Increase samples for better stability\n",
    "    )\n",
    "    \n",
    "    # Extract the feature weights\n",
    "    lime_weights = explanation.as_list()\n",
    "    return lime_weights\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP Fusion Model with Raster Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_gnn_mlp_model(mlp_input_dim, gnn_input_dim)\n",
    "\n",
    "# ==================== 8. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 9. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 10. Evaluate & Perform Feature Importance ==================== #\n",
    "# Evaluate on the training data using the updated function\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "mae_train = mean_absolute_error(y_train[:len(y_pred_train)], y_pred_train)\n",
    "denominator_train = np.abs(y_train[:len(y_pred_train)]) + np.abs(y_pred_train)\n",
    "smape_train = np.mean(2 * np.abs(y_pred_train - y_train[:len(y_pred_train)]) / (denominator_train + 1e-8)) * 100\n",
    "\n",
    "# Evaluate on the test data using the updated function\n",
    "r2_test, rmse_test, mae_test, smape_test = evaluate_model(model, mlp_test, gnn_test, y_test)\n",
    "y_pred_test = evaluate_model(model, mlp_test, gnn_test, y_test, return_preds=True)\n",
    "\n",
    "print(f\"\\n GNN-MLP Fusion Model Performance:\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f} | MAE Train: {mae_train:.4f} | SMAPE Train: {smape_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f} | MAE Test: {mae_test:.4f} | SMAPE Test: {smape_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc29f02-e3e2-4b78-8748-b9ce99f14c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data will now be integrated into the MLP input.\n",
      "Found 26 raster files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2784/2308733540.py:102: RuntimeWarning: Mean of empty slice\n",
      "  aggregated_value = np.nanmean(data)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rakibhhridoy/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Analyzing GNN-MLP Fusion Model with Raster Data\n",
      "================================================================================\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      " GNN-MLP Fusion Model Performance:\n",
      "R\u00b2 Train: -1.0381 | RMSE Train: 97.4803 | MAE Train: 74.9346 | SMAPE Train: 39.7962\n",
      "R\u00b2 Test: 0.9499 | RMSE Test: 17.7042 | MAE Test: 15.9653 | SMAPE Test: 10.1219\n",
      "\n",
      "--- Permutation-based Feature Importance ---\n",
      "\n",
      "Starting Permutation Feature Importance Analysis...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Baseline R\u00b2 on test set: 0.9499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "Calculating individual feature importance...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "MLP: 2.1119\n",
      "FeR: 0.0793\n",
      "num_industry: 0.0456\n",
      "awei: 0.0448\n",
      "MR: 0.0190\n",
      "num_brick_field: 0.0142\n",
      "bui: 0.0072\n",
      "ndwi: 0.0061\n",
      "ndsi: 0.0052\n",
      "GNN: 0.0003\n",
      "CrR: 0.0000\n",
      "NiR: 0.0000\n",
      "CuR: 0.0000\n",
      "AsR: 0.0000\n",
      "CdR: 0.0000\n",
      "PbR: 0.0000\n",
      "SandR: 0.0000\n",
      "SiltR: 0.0000\n",
      "ClayR: 0.0000\n",
      "savi: 0.0000\n",
      "ui: 0.0000\n",
      "ndbi: 0.0000\n",
      "evi: 0.0000\n",
      "mndwi: 0.0000\n",
      "ndvi: 0.0000\n",
      "LULC2020: 0.0000\n",
      "LULC2021: 0.0000\n",
      "LULC2022: 0.0000\n",
      "LULC2019: 0.0000\n",
      "LULC2018: 0.0000\n",
      "LULC2017: 0.0000\n",
      "Pb_R: 0.0000\n",
      "hydro_dist_ind: -0.0000\n",
      "hydro_dist_brick: -0.0000\n",
      "ndbsi: -0.0017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingRegressor # For intrinsic importance\n",
    "import lime # For LIME importance\n",
    "from lime import lime_tabular # For LIME importance\n",
    "import gc\n",
    "import sys\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# We assume the data files are in the correct relative paths.\n",
    "try:\n",
    "    orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "    river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Required data file not found. Please ensure the files are at the correct paths.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI').tolist()\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "# Use os.path.join for robust path handling\n",
    "base_dir = \"../\"\n",
    "raster_paths += glob.glob(os.path.join(base_dir, \"CalIndices\", \"*.tif\"))\n",
    "raster_paths += glob.glob(os.path.join(base_dir, \"LULCMerged\", \"*.tif\"))\n",
    "raster_paths += glob.glob(os.path.join(base_dir, \"IDW\", \"*.tif\"))\n",
    "\n",
    "print(\"Note: Raster data will now be integrated into the MLP input.\")\n",
    "print(f\"Found {len(raster_paths)} raster files.\")\n",
    "\n",
    "# ==================== 3. Function to extract raster values using a buffer ==================== #\n",
    "def sample_rasters_with_buffer(df, raster_paths, buffer_meters):\n",
    "    \"\"\"\n",
    "    Extracts raster values by calculating the mean within a circular buffer\n",
    "    around each (Lat, Long) point.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'Lat' and 'Long' columns.\n",
    "        raster_paths (list): List of paths to raster files.\n",
    "        buffer_meters (int): The radius of the buffer in meters.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with a new column for each raster's aggregated value.\n",
    "    \"\"\"\n",
    "    raster_values = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for path in raster_paths:\n",
    "        try:\n",
    "            with rasterio.open(path) as src:\n",
    "                # Get the pixel size (resolution)\n",
    "                pixel_size_x, pixel_size_y = src.res\n",
    "                \n",
    "                # Convert the buffer in meters to pixels\n",
    "                buffer_pixels_x = int(np.ceil(buffer_meters / pixel_size_x))\n",
    "                buffer_pixels_y = int(np.ceil(buffer_meters / pixel_size_y))\n",
    "                \n",
    "                aggregated_data = []\n",
    "                for _, row in df.iterrows():\n",
    "                    long, lat = row['Long'], row['Lat']\n",
    "                    \n",
    "                    # Convert coordinates to raster indices (row, col)\n",
    "                    row_idx, col_idx = src.index(long, lat)\n",
    "                    \n",
    "                    # Define the window to read from the raster\n",
    "                    window = Window(\n",
    "                        col_off=col_idx - buffer_pixels_x,\n",
    "                        row_off=row_idx - buffer_pixels_y,\n",
    "                        width=2 * buffer_pixels_x + 1,\n",
    "                        height=2 * buffer_pixels_y + 1\n",
    "                    )\n",
    "                    \n",
    "                    # Read the data from the defined window\n",
    "                    try:\n",
    "                        data = src.read(1, window=window)\n",
    "                        # Calculate the mean of the pixels within the window\n",
    "                        # Use np.nanmean to handle NoData values\n",
    "                        aggregated_value = np.nanmean(data)\n",
    "                        aggregated_data.append(aggregated_value)\n",
    "                    except rasterio.errors.WindowError:\n",
    "                        # If the window goes outside the raster bounds, append NaN\n",
    "                        aggregated_data.append(np.nan)\n",
    "                \n",
    "                # Get a clean name for the new column\n",
    "                raster_name = os.path.splitext(os.path.basename(path))[0]\n",
    "                raster_values[raster_name] = aggregated_data\n",
    "\n",
    "        except rasterio.RasterioIOError:\n",
    "            print(f\"Warning: Could not open or read raster file at {path}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {path}: {e}\")\n",
    "            \n",
    "    return raster_values\n",
    "\n",
    "# ==================== 4. Extract Raster Data and Merge with Main Data ==================== #\n",
    "# Extract raster data for both training and testing sets\n",
    "train_raster_data = sample_rasters_with_buffer(train_combined, raster_paths, BUFFER_METERS)\n",
    "test_raster_data = sample_rasters_with_buffer(test_orig, raster_paths, BUFFER_METERS)\n",
    "\n",
    "# Now, we combine the original numeric features with the new raster features\n",
    "# Note: We must handle NaNs, as they can occur if a point is outside a raster's bounds.\n",
    "# A simple fillna(0) is used here, but a more sophisticated imputation might be needed.\n",
    "train_combined_with_rasters = pd.concat([train_combined, train_raster_data], axis=1).fillna(0)\n",
    "test_orig_with_rasters = pd.concat([test_orig, test_raster_data], axis=1).fillna(0)\n",
    "\n",
    "# Update the list of numeric columns to include the new raster features\n",
    "raster_cols = train_raster_data.columns.tolist()\n",
    "all_numeric_cols = numeric_cols + raster_cols\n",
    "\n",
    "# ==================== 5. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 6. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined_with_rasters[['Long','Lat']].values\n",
    "coords_test = test_orig_with_rasters[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# The scaler now fits on the combined original + raster data\n",
    "mlp_train = scaler.fit_transform(train_combined_with_rasters[all_numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig_with_rasters[all_numeric_cols])\n",
    "y_train = train_combined_with_rasters['RI'].values\n",
    "y_test = test_orig_with_rasters['RI'].values\n",
    "\n",
    "# ==================== 7. Define GNN-MLP Fusion Model ==================== #\n",
    "def build_gnn_mlp_model(mlp_dim, gnn_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Concatenate Embeddings ---\n",
    "    combined = Concatenate()([mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, mlp_test, gnn_test_matrix, y_test, return_preds=False):\n",
    "    \"\"\"\n",
    "    Evaluates the model on given data and returns R\u00b2, RMSE, MAE, SMAPE, and predictions.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict((mlp_test, gnn_test_matrix)).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # Calculate R-squared and RMSE\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        # Calculate Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # Calculate Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "        # Add a small epsilon to the denominator to avoid division by zero\n",
    "        denominator = np.abs(y_test) + np.abs(y_pred)\n",
    "        smape = np.mean(2 * np.abs(y_pred - y_test) / (denominator + 1e-8)) * 100\n",
    "        \n",
    "        return r2, rmse, mae, smape\n",
    "\n",
    "def calculate_permutation_importance(model, mlp_data, gnn_data, y_true, feature_names):\n",
    "    \"\"\"\n",
    "    Calculates permutation feature importance for the MLP and GNN branches.\n",
    "    Now also includes importance for individual features.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Permutation Feature Importance Analysis...\")\n",
    "    # Get baseline R\u00b2 on the unshuffled data\n",
    "    baseline_r2, _, _, _ = evaluate_model(model, mlp_data, gnn_data, y_true)\n",
    "    print(f\"Baseline R\u00b2 on test set: {baseline_r2:.4f}\")\n",
    "\n",
    "    importance = {}\n",
    "    \n",
    "    # Permute MLP input as a whole\n",
    "    shuffled_mlp_data = mlp_data.copy()\n",
    "    np.random.shuffle(shuffled_mlp_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, shuffled_mlp_data, gnn_data, y_true)\n",
    "    importance['MLP'] = baseline_r2 - shuffled_r2\n",
    "    \n",
    "    # Permute GNN input\n",
    "    shuffled_gnn_data = gnn_data.copy()\n",
    "    np.random.shuffle(shuffled_gnn_data)\n",
    "    shuffled_r2, _, _, _ = evaluate_model(model, mlp_data, shuffled_gnn_data, y_true)\n",
    "    importance['GNN'] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    # Permute each individual feature in MLP input\n",
    "    print(\"\\nCalculating individual feature importance...\")\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        shuffled_data_mlp = mlp_data.copy()\n",
    "        np.random.shuffle(shuffled_data_mlp[:, i])\n",
    "        shuffled_r2, _, _, _ = evaluate_model(model, shuffled_data_mlp, gnn_data, y_true)\n",
    "        importance[feature] = baseline_r2 - shuffled_r2\n",
    "\n",
    "    return importance\n",
    "\n",
    "def calculate_intrinsic_importance(mlp_data, y_true, feature_names):\n",
    "    \"\"\"\n",
    "    Calculates intrinsic feature importance using a tree-based model.\n",
    "    \"\"\"\n",
    "    print(\"\\nTraining a Gradient Boosting Regressor on the MLP features...\")\n",
    "    gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gbr.fit(mlp_data, y_true)\n",
    "    \n",
    "    importance = {}\n",
    "    for i, name in enumerate(feature_names):\n",
    "        importance[name] = gbr.feature_importances_[i]\n",
    "    return importance\n",
    "\n",
    "def get_lime_explanation(model, mlp_test, gnn_test, train_df_unscaled, sample_index):\n",
    "    \"\"\"\n",
    "    Generates a LIME explanation for a single data point.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating LIME explanation for a single data point...\")\n",
    "    \n",
    "    # Create a wrapper prediction function for LIME\n",
    "    def predict_fn(x):\n",
    "        # We need to reshape x to be a 2D array if it's not already\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        # Create the full input for the GNN-MLP model\n",
    "        gnn_input_for_lime = np.tile(gnn_test[sample_index:sample_index+1, :], (x.shape[0], 1))\n",
    "        # Predict using the full model\n",
    "        return model.predict([x, gnn_input_for_lime])\n",
    "    \n",
    "    # Initialize the LIME explainer with the training data\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        # Use the unscaled training data and its columns for a robust feature name link\n",
    "        training_data=train_df_unscaled.values,\n",
    "        feature_names=train_df_unscaled.columns.tolist(),\n",
    "        mode='regression',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Explain the selected instance from the SCALED test data\n",
    "    explanation = explainer.explain_instance(\n",
    "        data_row=mlp_test[sample_index],\n",
    "        predict_fn=predict_fn,\n",
    "        num_features=len(train_df_unscaled.columns),\n",
    "        num_samples=5000 # Increase samples for better stability\n",
    "    )\n",
    "    \n",
    "    # Extract the feature weights\n",
    "    lime_weights = explanation.as_list()\n",
    "    return lime_weights\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP Fusion Model with Raster Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_gnn_mlp_model(mlp_input_dim, gnn_input_dim)\n",
    "\n",
    "# ==================== 8. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 9. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 10. Evaluate & Perform Feature Importance ==================== #\n",
    "# Evaluate on the training data using the updated function\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "mae_train = mean_absolute_error(y_train[:len(y_pred_train)], y_pred_train)\n",
    "denominator_train = np.abs(y_train[:len(y_pred_train)]) + np.abs(y_pred_train)\n",
    "smape_train = np.mean(2 * np.abs(y_pred_train - y_train[:len(y_pred_train)]) / (denominator_train + 1e-8)) * 100\n",
    "\n",
    "# Evaluate on the test data using the updated function\n",
    "r2_test, rmse_test, mae_test, smape_test = evaluate_model(model, mlp_test, gnn_test, y_test)\n",
    "y_pred_test = evaluate_model(model, mlp_test, gnn_test, y_test, return_preds=True)\n",
    "\n",
    "print(f\"\\n GNN-MLP Fusion Model Performance:\")\n",
    "print(f\"R\u00b2 Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f} | MAE Train: {mae_train:.4f} | SMAPE Train: {smape_train:.4f}\")\n",
    "print(f\"R\u00b2 Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f} | MAE Test: {mae_test:.4f} | SMAPE Test: {smape_test:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate and print feature importance\n",
    "print(\"\\n--- Permutation-based Feature Importance ---\")\n",
    "feature_importance_perm = calculate_permutation_importance(\n",
    "    model, \n",
    "    mlp_test, \n",
    "    gnn_test, \n",
    "    y_test,\n",
    "    all_numeric_cols\n",
    ")\n",
    "sorted_importance_perm = sorted(\n",
    "    feature_importance_perm.items(), \n",
    "    key=lambda item: item[1], \n",
    "    reverse=True\n",
    ")\n",
    "for feature, score in sorted_importance_perm:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53c70f7a-c869-41e0-9749-514babc07837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP: 2.111869773783312\n",
      "FeR: 0.079347831991002\n",
      "num_industry: 0.045576858048925\n",
      "awei: 0.044838264154239\n",
      "MR: 0.018977220566508\n",
      "num_brick_field: 0.014194593213590\n",
      "bui: 0.007192163417536\n",
      "ndwi: 0.006094875653798\n",
      "ndsi: 0.005192015143415\n",
      "GNN: 0.000331639310161\n",
      "\n",
      "Training a Gradient Boosting Regressor on the MLP features...\n",
      "FeR: 0.8536\n",
      "MR: 0.0093\n",
      "ndsi: 0.0012\n",
      "hydro_dist_ind: 0.0012\n",
      "ndbsi: 0.0006\n",
      "awei: 0.0005\n",
      "bui: 0.0004\n",
      "ndwi: 0.0001\n",
      "hydro_dist_brick: 0.0001\n",
      "num_industry: 0.0000\n",
      "Feature: FeR <= 28222.33 | Weight: -207221.8520\n",
      "Feature: hydro_dist_ind <= 509.29 | Weight: -27457.3500\n",
      "Feature: CuR > -4240.00 | Weight: -26989.6129\n",
      "Feature: SandR > -4266.97 | Weight: -26989.6129\n",
      "Feature: SiltR > -4262.00 | Weight: -26989.6129\n",
      "Feature: AsR > -4276.67 | Weight: -26989.6129\n",
      "Feature: ClayR > -4266.17 | Weight: -26989.6129\n",
      "Feature: ClayR > -4266.17 | Weight: -26989.6129\n",
      "Feature: CrR > -4255.07 | Weight: -26989.6129\n",
      "Feature: CrR > -4255.07 | Weight: -26989.6129\n",
      "Feature: NiR > -4265.75 | Weight: -26989.6129\n",
      "Feature: NiR > -4265.75 | Weight: -26989.6129\n",
      "Feature: CdR > -4281.84 | Weight: -26989.6129\n",
      "Feature: AsR > -4276.67 | Weight: -26989.6129\n",
      "Feature: CuR > -4240.00 | Weight: -26989.6129\n",
      "Feature: CdR > -4281.84 | Weight: -26989.6129\n",
      "Feature: SandR > -4266.97 | Weight: -26989.6129\n",
      "Feature: Pb_R > -4240.09 | Weight: -26989.6129\n",
      "Feature: SiltR > -4262.00 | Weight: -26989.6129\n",
      "Feature: num_brick_field > 1.00 | Weight: -8961.6487\n",
      "Feature: PbR <= 42.89 | Weight: -6318.3149\n",
      "Feature: CrR <= 20.83 | Weight: 5623.5127\n",
      "Feature: AsR <= 9.87 | Weight: 5530.1949\n",
      "Feature: SandR <= 17.05 | Weight: -4925.6250\n",
      "Feature: SiltR <= 29.11 | Weight: -4384.2576\n",
      "Feature: SiltR <= 29.11 | Weight: 4005.9582\n",
      "Feature: NiR <= 22.54 | Weight: 3650.2304\n",
      "Feature: CrR <= 20.83 | Weight: 3328.9024\n",
      "Feature: CuR <= 56.87 | Weight: 3159.2517\n",
      "Feature: ClayR <= 23.23 | Weight: -3081.2742\n",
      "Feature: SandR <= 17.05 | Weight: -2984.5843\n",
      "Feature: CdR <= 2.10 | Weight: -2637.4072\n",
      "Feature: AsR <= 9.87 | Weight: 2274.4871\n",
      "Feature: MR <= 31.75 | Weight: -2221.9662\n",
      "Feature: CuR <= 56.87 | Weight: 2088.6623\n",
      "Feature: ClayR <= 23.23 | Weight: -1467.9317\n",
      "Feature: CdR <= 2.10 | Weight: 955.9326\n",
      "Feature: hydro_dist_brick <= 887.50 | Weight: -792.1255\n",
      "Feature: NiR <= 22.54 | Weight: -244.1754\n",
      "Feature: num_industry > 1.00 | Weight: -186.7530\n",
      "Feature: bui <= 0.00 | Weight: 0.0000\n",
      "Feature: ndsi <= 0.00 | Weight: 0.0000\n",
      "Feature: savi <= 0.00 | Weight: 0.0000\n",
      "Feature: ndbsi <= 0.00 | Weight: 0.0000\n",
      "Feature: ui <= 0.00 | Weight: 0.0000\n",
      "Feature: ndwi <= 0.00 | Weight: 0.0000\n",
      "Feature: ndbi <= 0.00 | Weight: 0.0000\n",
      "Feature: awei <= 0.00 | Weight: 0.0000\n",
      "Feature: evi <= 0.00 | Weight: 0.0000\n",
      "Feature: mndwi <= 0.00 | Weight: 0.0000\n",
      "Feature: ndvi <= 0.00 | Weight: 0.0000\n",
      "Feature: LULC2020 <= 0.00 | Weight: 0.0000\n",
      "Feature: LULC2021 <= 0.00 | Weight: 0.0000\n",
      "Feature: LULC2022 <= 0.00 | Weight: 0.0000\n",
      "Feature: LULC2019 <= 0.00 | Weight: 0.0000\n",
      "Feature: LULC2018 <= 0.00 | Weight: 0.0000\n",
      "Feature: LULC2017 <= 0.00 | Weight: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for feature, score in sorted_importance_perm[:10]:\n",
    "    print(f\"{feature}: {score:.15f}\")\n",
    "\n",
    "feature_importance_intrinsic = calculate_intrinsic_importance(mlp_train, y_train, all_numeric_cols)\n",
    "sorted_importance_intrinsic = sorted(feature_importance_intrinsic.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, score in sorted_importance_intrinsic[:10]:\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "    \n",
    "for feature, weight in lime_explanation:\n",
    "    print(f\"Feature: {feature} | Weight: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e13c968-3953-4be3-b7d1-74925d1a642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stations', 'River', 'Lat', 'Long', 'geometry', 'hydro_dist_brick',\n",
       "       'num_brick_field', 'hydro_dist_ind', 'num_industry', 'CrW', 'NiW',\n",
       "       'CuW', 'AsW', 'CdW', 'PbW', 'MW', 'SandW', 'SiltW', 'ClayW', 'FeW',\n",
       "       'RI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../../data/WinterSeason1.csv\").columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38448f-f873-465f-ac40-802006409357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "alphaearth_integrated": true,
  "season": "rainy"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}