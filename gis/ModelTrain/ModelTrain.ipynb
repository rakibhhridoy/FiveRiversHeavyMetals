{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57290214-9698-4ea7-863d-d77c2883d2c9",
   "metadata": {},
   "source": [
    "# PMF-GWR-Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a56466-dadd-46df-8295-da66836a94e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "[I 2025-08-13 10:28:34,932] A new study created in memory with name: no-name-62bce442-dc4f-494b-adf0-ccf8604170a2\n",
      "[I 2025-08-13 10:28:35,012] Trial 0 finished with value: -0.9967391959627846 and parameters: {'n_estimators': 218, 'learning_rate': 0.23551844558416718, 'max_depth': 4, 'subsample': 0.6038282701514118, 'colsample_bytree': 0.6234677141105672, 'reg_lambda': 8.842460784787573, 'reg_alpha': 3.279816030134387}. Best is trial 0 with value: -0.9967391959627846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PMF Source Profiles (F):\n",
      "          CrR        NiR        CuR       AsR       CdR        PbR         MR  \\\n",
      "0   1.011394   0.736558   1.692247  0.281341  0.081750   1.820546   0.744546   \n",
      "1   6.361288   2.934156   7.088633  1.445853  0.265187   5.471062   3.794235   \n",
      "2  21.198226  13.542373  26.909206  5.147733  1.449371  21.855110  14.985165   \n",
      "\n",
      "       SandR      SiltR      ClayR           FeR  \n",
      "0   0.626923   0.857056   0.708029    811.577541  \n",
      "1   4.450678   3.851341   2.797802   3334.739331  \n",
      "2  16.238105  14.757198  12.760148  12485.904320  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 10:28:35,319] Trial 1 finished with value: -0.9823389068373719 and parameters: {'n_estimators': 556, 'learning_rate': 0.013046325083998419, 'max_depth': 8, 'subsample': 0.6637392288713959, 'colsample_bytree': 0.7121223044306655, 'reg_lambda': 8.460893825769205, 'reg_alpha': 1.7825025381101034}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:35,470] Trial 2 finished with value: -0.9907162934229792 and parameters: {'n_estimators': 399, 'learning_rate': 0.05737775528992611, 'max_depth': 5, 'subsample': 0.6536796933625474, 'colsample_bytree': 0.6210437085040117, 'reg_lambda': 7.016064341751523, 'reg_alpha': 2.21928797349986}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:35,663] Trial 3 finished with value: -0.983688982946571 and parameters: {'n_estimators': 532, 'learning_rate': 0.09293909767272973, 'max_depth': 4, 'subsample': 0.9073537269936782, 'colsample_bytree': 0.9901734009825052, 'reg_lambda': 6.459902021812296, 'reg_alpha': 3.6808296734987684}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:35,787] Trial 4 finished with value: -0.9882689066953247 and parameters: {'n_estimators': 321, 'learning_rate': 0.07664423545355949, 'max_depth': 4, 'subsample': 0.8457299855248318, 'colsample_bytree': 0.8936968704813928, 'reg_lambda': 4.589512275481224, 'reg_alpha': 1.6902262832087374}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:35,861] Trial 5 finished with value: -0.9856641779100619 and parameters: {'n_estimators': 266, 'learning_rate': 0.2135867485383191, 'max_depth': 3, 'subsample': 0.6018441217923367, 'colsample_bytree': 0.8675624660452533, 'reg_lambda': 8.144406311588712, 'reg_alpha': 1.2369211525524864}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,033] Trial 6 finished with value: -0.9840629433725122 and parameters: {'n_estimators': 452, 'learning_rate': 0.21627954030820776, 'max_depth': 6, 'subsample': 0.8318904478296252, 'colsample_bytree': 0.8643928239755116, 'reg_lambda': 7.847052840759015, 'reg_alpha': 3.8500583442908605}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,142] Trial 7 finished with value: -0.9904141477152358 and parameters: {'n_estimators': 393, 'learning_rate': 0.07022575741715327, 'max_depth': 3, 'subsample': 0.8304368198961014, 'colsample_bytree': 0.8286833953085211, 'reg_lambda': 1.3831664997282846, 'reg_alpha': 3.2394559205383535}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,363] Trial 8 finished with value: -0.9871215060841819 and parameters: {'n_estimators': 589, 'learning_rate': 0.2327438228867787, 'max_depth': 8, 'subsample': 0.6199425547300755, 'colsample_bytree': 0.6661411066545674, 'reg_lambda': 8.771681492161743, 'reg_alpha': 1.8828104316762917}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,464] Trial 9 finished with value: -0.9895814411300552 and parameters: {'n_estimators': 542, 'learning_rate': 0.29509154092814793, 'max_depth': 4, 'subsample': 0.9837065073482648, 'colsample_bytree': 0.7729258846323095, 'reg_lambda': 4.527676333745621, 'reg_alpha': 4.472476793415318}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,606] Trial 10 finished with value: -0.9824687462432505 and parameters: {'n_estimators': 247, 'learning_rate': 0.15926254969219916, 'max_depth': 6, 'subsample': 0.727499306387305, 'colsample_bytree': 0.7327717089207091, 'reg_lambda': 9.835258310093227, 'reg_alpha': 0.26128386369421186}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,703] Trial 11 finished with value: -0.9898960901811401 and parameters: {'n_estimators': 212, 'learning_rate': 0.16261663191970147, 'max_depth': 5, 'subsample': 0.718336112712615, 'colsample_bytree': 0.6021282964353014, 'reg_lambda': 6.519634733323841, 'reg_alpha': 2.7147210213738497}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,815] Trial 12 finished with value: -0.9951542160602671 and parameters: {'n_estimators': 356, 'learning_rate': 0.28644183558682484, 'max_depth': 5, 'subsample': 0.7024267910474717, 'colsample_bytree': 0.6124504223456737, 'reg_lambda': 6.080562697661245, 'reg_alpha': 2.6097425590816687}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:36,915] Trial 13 finished with value: -0.9888102392096195 and parameters: {'n_estimators': 330, 'learning_rate': 0.29716906853583924, 'max_depth': 6, 'subsample': 0.7400999085202653, 'colsample_bytree': 0.6676661382627553, 'reg_lambda': 2.8430332541491308, 'reg_alpha': 2.967863814598027}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:37,050] Trial 14 finished with value: -0.9956078376097957 and parameters: {'n_estimators': 333, 'learning_rate': 0.25645190441220217, 'max_depth': 7, 'subsample': 0.6794304775502624, 'colsample_bytree': 0.6599521169161058, 'reg_lambda': 5.170933363495043, 'reg_alpha': 4.5459293341945015}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:37,167] Trial 15 finished with value: -0.9940322767507963 and parameters: {'n_estimators': 275, 'learning_rate': 0.24882274378742236, 'max_depth': 7, 'subsample': 0.6621089644977926, 'colsample_bytree': 0.6916674573789865, 'reg_lambda': 4.617045546893679, 'reg_alpha': 4.766029930278418}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:37,333] Trial 16 finished with value: -0.9945412427466456 and parameters: {'n_estimators': 472, 'learning_rate': 0.18701600471661114, 'max_depth': 7, 'subsample': 0.777011289032663, 'colsample_bytree': 0.7689431891361438, 'reg_lambda': 3.37019047053193, 'reg_alpha': 4.194310667360301}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:37,442] Trial 17 finished with value: -0.9889150737711591 and parameters: {'n_estimators': 224, 'learning_rate': 0.2653969616917681, 'max_depth': 7, 'subsample': 0.6057841982489435, 'colsample_bytree': 0.6472397422772042, 'reg_lambda': 9.912314784833324, 'reg_alpha': 4.912506680943051}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:37,560] Trial 18 finished with value: -0.9945592101098049 and parameters: {'n_estimators': 310, 'learning_rate': 0.11985487130618358, 'max_depth': 4, 'subsample': 0.7766110519726708, 'colsample_bytree': 0.7378077890865535, 'reg_lambda': 5.437546723947513, 'reg_alpha': 3.3997603629272666}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:37,735] Trial 19 finished with value: -0.9897454188567983 and parameters: {'n_estimators': 448, 'learning_rate': 0.19210549848711367, 'max_depth': 7, 'subsample': 0.672729637995439, 'colsample_bytree': 0.9570380030279597, 'reg_lambda': 3.347758547890865, 'reg_alpha': 4.107287493123746}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:37,890] Trial 20 finished with value: -0.978102155282907 and parameters: {'n_estimators': 366, 'learning_rate': 0.25503747915810693, 'max_depth': 8, 'subsample': 0.6888662982469986, 'colsample_bytree': 0.6524003688212707, 'reg_lambda': 7.476040376182297, 'reg_alpha': 3.464773893019546}. Best is trial 0 with value: -0.9967391959627846.\n",
      "[I 2025-08-13 10:28:38,009] Trial 21 finished with value: -0.9975309087966693 and parameters: {'n_estimators': 345, 'learning_rate': 0.27244316722103273, 'max_depth': 5, 'subsample': 0.7073691983835306, 'colsample_bytree': 0.600315134637067, 'reg_lambda': 5.919090088283211, 'reg_alpha': 2.496532666825796}. Best is trial 21 with value: -0.9975309087966693.\n",
      "[I 2025-08-13 10:28:38,113] Trial 22 finished with value: -0.9925510588006589 and parameters: {'n_estimators': 293, 'learning_rate': 0.26086986018268726, 'max_depth': 5, 'subsample': 0.6390216581440589, 'colsample_bytree': 0.6361673430998471, 'reg_lambda': 5.457478390535195, 'reg_alpha': 2.2559968729487037}. Best is trial 21 with value: -0.9975309087966693.\n",
      "[I 2025-08-13 10:28:38,220] Trial 23 finished with value: -0.9859385837082314 and parameters: {'n_estimators': 353, 'learning_rate': 0.22952829097029362, 'max_depth': 3, 'subsample': 0.7515765040141279, 'colsample_bytree': 0.686706725854358, 'reg_lambda': 9.068713465586812, 'reg_alpha': 0.9040838998418621}. Best is trial 21 with value: -0.9975309087966693.\n",
      "[I 2025-08-13 10:28:38,330] Trial 24 finished with value: -0.9941483194355288 and parameters: {'n_estimators': 245, 'learning_rate': 0.19046765691005793, 'max_depth': 6, 'subsample': 0.6366788095307685, 'colsample_bytree': 0.6032954541230968, 'reg_lambda': 2.2014539728318416, 'reg_alpha': 2.941686548535629}. Best is trial 21 with value: -0.9975309087966693.\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:218: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best Parameters from Optuna: {'n_estimators': 345, 'learning_rate': 0.27244316722103273, 'max_depth': 5, 'subsample': 0.7073691983835306, 'colsample_bytree': 0.600315134637067, 'reg_lambda': 5.919090088283211, 'reg_alpha': 2.496532666825796}\n",
      "\n",
      "✅ Final Model Performance:\n",
      "R² Train: 1.0000 | RMSE Train: 0.2822\n",
      "R² Test: 0.9975 | RMSE Test: 3.9290\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_2591/668805563.py:219: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])], plot_type=\"bar\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SHAP analysis complete. Check plots for feature importance.\n",
      "\n",
      "✅ Top Features (XGBoost Gain):\n",
      "                              Feature  Importance\n",
      "49                    Pb_R_500m_mean    0.471621\n",
      "9                                PbR    0.365919\n",
      "5                                NiR    0.097189\n",
      "6                                CuR    0.019139\n",
      "8                                CdR    0.014421\n",
      "45                     CuR_500m_mean    0.010197\n",
      "47                     NiR_500m_mean    0.007011\n",
      "4                                CrR    0.002467\n",
      "12                             SiltR    0.002136\n",
      "7                                AsR    0.001532\n",
      "11                             SandR    0.001201\n",
      "43                     CrR_500m_mean    0.001020\n",
      "13                             ClayR    0.001016\n",
      "38                      AsR_500m_std    0.000806\n",
      "0    hydrological_dist_to_nearest_BF    0.000709\n",
      "52                    SandR_500m_std    0.000696\n",
      "37                     AsR_500m_mean    0.000638\n",
      "10                                MR    0.000265\n",
      "39                     CdR_500m_mean    0.000243\n",
      "54                    SiltR_500m_std    0.000219\n",
      "2   hydrological_dist_to_nearest_IND    0.000194\n",
      "14                               FeR    0.000172\n",
      "51                   SandR_500m_mean    0.000172\n",
      "69                       PMF_Factor2    0.000152\n",
      "71                          PMF0_GWR    0.000106\n",
      "44                      CrR_500m_std    0.000099\n",
      "1                    num_upstream_BF    0.000095\n",
      "48                      NiR_500m_std    0.000081\n",
      "41                   ClayR_500m_mean    0.000064\n",
      "50                     Pb_R_500m_std    0.000054\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "import rasterstats\n",
    "from rasterstats import zonal_stats\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import shap\n",
    "from scipy.spatial import cKDTree\n",
    "import os\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# Load the main dataset and the river sampling data.\n",
    "original = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "# Identify columns for feature engineering and prediction\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = original.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Split original data into train and test sets for the ensemble model.\n",
    "# This ensures a fair evaluation on unseen data points.\n",
    "np.random.seed(42)\n",
    "train_idx = np.random.choice(len(original), 10, replace=False)\n",
    "test_idx = [i for i in range(len(original)) if i not in train_idx]\n",
    "train_orig = original.iloc[train_idx]\n",
    "test_orig = original.iloc[test_idx]\n",
    "\n",
    "# Combine the river samples and the original training data to form the full training set.\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Extract Multi-Scale Raster Features ==================== #\n",
    "# Define the raster files and buffer sizes for zonal statistics.\n",
    "raster_files = [\n",
    "    \"../CalIndices/ndwi.tif\", \"../CalIndices/ndvi.tif\", \"../CalIndices/ndbi.tif\",\n",
    "    \"../CalIndices/awei.tif\", \"../CalIndices/bui.tif\", \"../CalIndices/evi.tif\",\n",
    "    \"../CalIndices/mndwi.tif\", \"../CalIndices/ndbsi.tif\", \"../CalIndices/ndsi.tif\",\n",
    "    \"../CalIndices/savi.tif\", \"../CalIndices/ui.tif\", \n",
    "    \"../IDW/AsR.tif\", \"../IDW/CdR.tif\", \"../IDW/ClayR.tif\", \"../IDW/CrR.tif\", \"../IDW/CuR.tif\",\n",
    "    \"../IDW/NiR.tif\", \"../IDW/Pb_R.tif\", \"../IDW/SandR.tif\", \"../IDW/SiltR.tif\",\n",
    "    \"../LULCMerged/LULC2017.tif\", \"../LULCMerged/LULC2018.tif\", \"../LULCMerged/LULC2019.tif\",\n",
    "    \"../LULCMerged/LULC2020.tif\", \"../LULCMerged/LULC2021.tif\", \"../LULCMerged/LULC2022.tif\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "buffers = [500]\n",
    "\n",
    "def extract_raster_stats(points_df, rasters, buffers):\n",
    "    \"\"\"\n",
    "    Extracts zonal statistics (mean, std) from raster files for points\n",
    "    within specified buffer distances.\n",
    "    \"\"\"\n",
    "    # Create a GeoDataFrame from the points for spatial operations\n",
    "    gdf = gpd.GeoDataFrame(points_df, geometry=gpd.points_from_xy(points_df.Long, points_df.Lat), crs=\"EPSG:4326\")\n",
    "    features = pd.DataFrame(index=gdf.index)\n",
    "\n",
    "    for raster_path in rasters:\n",
    "        for buf in buffers:\n",
    "            col_mean = f\"{os.path.basename(raster_path).split('.')[0]}_{buf}m_mean\"\n",
    "            col_std = f\"{os.path.basename(raster_path).split('.')[0]}_{buf}m_std\"\n",
    "\n",
    "            # Create a buffer around each point (converted from meters to degrees)\n",
    "            # The value 111320 is a rough conversion factor from degrees to meters at the equator.\n",
    "            buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
    "            \n",
    "            # Use rasterstats to get zonal statistics for the buffered areas\n",
    "            zs_results = zonal_stats(buffered_geometries, raster_path, stats=['mean', 'std'], nodata=np.nan)\n",
    "\n",
    "            features[col_mean] = [res['mean'] for res in zs_results]\n",
    "            features[col_std] = [res['std'] for res in zs_results]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract raster features for both the training and testing data\n",
    "train_raster_feats = extract_raster_stats(train_combined, raster_files, buffers)\n",
    "test_raster_feats = extract_raster_stats(test_orig, raster_files, buffers)\n",
    "\n",
    "# ==================== 3. PMF (NMF) for Source Apportionment ==================== #\n",
    "# Use Non-Negative Matrix Factorization to identify latent source factors.\n",
    "pmf_features = ['CrR', 'NiR', 'CuR', 'AsR', 'CdR', 'PbR', 'MR', 'SandR', 'SiltR', 'ClayR', 'FeR']\n",
    "nmf = NMF(n_components=3, init='random', random_state=42, max_iter=100)\n",
    "G_train = nmf.fit_transform(train_combined[pmf_features].values)\n",
    "F = nmf.components_\n",
    "print(\"\\nPMF Source Profiles (F):\\n\", pd.DataFrame(F, columns=pmf_features))\n",
    "\n",
    "# ==================== 4. Fixed Geographically Weighted Regression (GWR) ==================== #\n",
    "# Implement a custom GWR function to model spatial non-stationarity.\n",
    "def gaussian_kernel(d, bw):\n",
    "    return np.exp(-(d**2) / (2 * bw**2))\n",
    "\n",
    "def fixed_gwr(coords, factors, y, bw=0.5):\n",
    "    \"\"\"\n",
    "    Performs a fixed bandwidth GWR using a Gaussian kernel.\n",
    "    \"\"\"\n",
    "    n = len(coords)\n",
    "    preds = np.zeros(n)\n",
    "    X = np.hstack([np.ones((n, 1)), factors])\n",
    "    for i in range(n):\n",
    "        dist = np.linalg.norm(coords - coords[i], axis=1)\n",
    "        W = np.diag(gaussian_kernel(dist, bw))\n",
    "        # Use pseudo-inverse for stability\n",
    "        beta = np.linalg.pinv(X.T @ W @ X) @ (X.T @ W @ y.reshape(-1, 1))\n",
    "        preds[i] = (np.array([1] + list(factors[i])) @ beta).item()\n",
    "    return preds.reshape(-1, 1)\n",
    "\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "y_train = train_combined['RI'].values\n",
    "GWR_train = fixed_gwr(coords_train, G_train, y_train, bw=0.5)\n",
    "\n",
    "# Interpolate PMF factors for the test set using Inverse Distance Weighting (IDW)\n",
    "def idw_interpolation(known_coords, known_values, query_coords, power=2):\n",
    "    \"\"\"\n",
    "    Performs IDW to interpolate values from known points to query points.\n",
    "    \"\"\"\n",
    "    tree = cKDTree(known_coords)\n",
    "    dists, idxs = tree.query(query_coords, k=4)\n",
    "    dists[dists == 0] = 1e-10  # Avoid division by zero\n",
    "    weights = 1 / (dists ** power)\n",
    "    weights /= weights.sum(axis=1)[:, None]\n",
    "    return np.sum(weights * known_values[idxs], axis=1)\n",
    "\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "y_test = test_orig['RI'].values\n",
    "# Interpolate PMF factors for the test set\n",
    "G_test = np.column_stack([idw_interpolation(coords_train, G_train[:, i], coords_test) for i in range(G_train.shape[1])])\n",
    "# Apply GWR to the interpolated PMF factors for the test set\n",
    "GWR_test = fixed_gwr(coords_test, G_test, y_test, bw=0.5)\n",
    "\n",
    "# ==================== 5. Interaction Features ==================== #\n",
    "# Create new features by interacting PMF and GWR results.\n",
    "def create_interactions(pmf, gwr):\n",
    "    \"\"\"\n",
    "    Creates interaction features between PMF factors and GWR predictions.\n",
    "    \"\"\"\n",
    "    interactions = pd.DataFrame()\n",
    "    for i in range(pmf.shape[1]):\n",
    "        interactions[f\"PMF{i}_GWR\"] = pmf[:, i] * gwr.flatten()\n",
    "    return interactions\n",
    "\n",
    "train_interact = create_interactions(G_train, GWR_train)\n",
    "test_interact = create_interactions(G_test, GWR_test)\n",
    "\n",
    "# ==================== 6. Final Feature Matrix ==================== #\n",
    "# Combine all engineered features into a single matrix for the XGBoost model.\n",
    "X_train = np.hstack([\n",
    "    train_combined[numeric_cols].values,\n",
    "    train_raster_feats.values,\n",
    "    G_train,\n",
    "    GWR_train,\n",
    "    train_interact.values\n",
    "])\n",
    "\n",
    "X_test = np.hstack([\n",
    "    test_orig[numeric_cols].values,\n",
    "    test_raster_feats.values,\n",
    "    G_test,\n",
    "    GWR_test,\n",
    "    test_interact.values\n",
    "])\n",
    "\n",
    "# ==================== 7. Optuna Hyperparameter Optimization ==================== #\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Defines the Optuna objective function to minimize negative R².\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 600),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5)\n",
    "    }\n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return -r2_score(y_test, y_pred)\n",
    "\n",
    "# Run the Optuna study to find the best parameters\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "best_params = study.best_params\n",
    "print(\"\\n✅ Best Parameters from Optuna:\", best_params)\n",
    "\n",
    "# ==================== 8. Train Final XGBoost ==================== #\n",
    "# Train the final model with the optimized hyperparameters.\n",
    "xgb = XGBRegressor(**best_params, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# ==================== 9. Evaluation ==================== #\n",
    "# Evaluate the final model's performance on both training and test data.\n",
    "y_pred_train = xgb.predict(X_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"\\n✅ Final Model Performance:\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 10. SHAP Interpretation ==================== #\n",
    "# Use SHAP to explain the model's predictions and feature importance.\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Generate SHAP summary plots\n",
    "shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])])\n",
    "shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])], plot_type=\"bar\")\n",
    "\n",
    "print(\"✅ SHAP analysis complete. Check plots for feature importance.\")\n",
    "\n",
    "feature_names = list(numeric_cols) \\\n",
    "                + list(train_raster_feats.columns) \\\n",
    "                + [f\"PMF_Factor{i}\" for i in range(G_train.shape[1])] \\\n",
    "                + [\"GWR_Adjusted\"] \\\n",
    "                + list(train_interact.columns)\n",
    "\n",
    "# Create DataFrame of importance\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": xgb.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Save & print\n",
    "importance_df.to_csv(\"SHAP-PMF-GLWR-Xgboost.csv\", index=False)\n",
    "print(\"\\n✅ Top Features (XGBoost Gain):\\n\", importance_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9835a3bf-45a8-4959-b476-d6bc19efc8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "[I 2025-08-11 11:05:33,095] A new study created in memory with name: no-name-e293079d-61c0-4df8-bc14-5a5bf8be4003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PMF Source Profiles (F):\n",
      "          CrR        NiR        CuR       AsR       CdR        PbR         MR  \\\n",
      "0   0.961540   0.704058   1.636377  0.265718  0.077563   1.753823   0.722294   \n",
      "1   4.964149   2.597048   5.703547  0.942491  0.311027   5.706320   2.725115   \n",
      "2  25.542785  12.377293  26.751550  5.311479  1.574210  23.217031  14.845736   \n",
      "\n",
      "       SandR      SiltR      ClayR           FeR  \n",
      "0   0.604440   0.835901   0.670266    781.195881  \n",
      "1   2.422355   3.007888   2.625702   2638.577939  \n",
      "2  15.054804  16.081543  12.821678  13124.520030  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:05:33,315] Trial 0 finished with value: -0.9605959585291662 and parameters: {'n_estimators': 237, 'learning_rate': 0.1379685312479051, 'max_depth': 3, 'subsample': 0.9074108210310408, 'colsample_bytree': 0.983808962495021, 'reg_lambda': 9.232833099736629, 'reg_alpha': 0.5120741550692554}. Best is trial 0 with value: -0.9605959585291662.\n",
      "[I 2025-08-11 11:05:33,514] Trial 1 finished with value: -0.9280868468967756 and parameters: {'n_estimators': 552, 'learning_rate': 0.2501295487510085, 'max_depth': 8, 'subsample': 0.966487001030288, 'colsample_bytree': 0.6417250209142515, 'reg_lambda': 2.709373475007811, 'reg_alpha': 3.974822157354539}. Best is trial 0 with value: -0.9605959585291662.\n",
      "[I 2025-08-11 11:05:33,668] Trial 2 finished with value: -0.9555335829000006 and parameters: {'n_estimators': 289, 'learning_rate': 0.18903586201859868, 'max_depth': 3, 'subsample': 0.984861351331838, 'colsample_bytree': 0.7415772555406844, 'reg_lambda': 9.101114811656347, 'reg_alpha': 1.078915967003603}. Best is trial 0 with value: -0.9605959585291662.\n",
      "[I 2025-08-11 11:05:33,999] Trial 3 finished with value: -0.9771860445872139 and parameters: {'n_estimators': 330, 'learning_rate': 0.18923131117929118, 'max_depth': 6, 'subsample': 0.9689425613986087, 'colsample_bytree': 0.8908234851518515, 'reg_lambda': 3.8350751644341354, 'reg_alpha': 0.2689733296147617}. Best is trial 3 with value: -0.9771860445872139.\n",
      "[I 2025-08-11 11:05:34,290] Trial 4 finished with value: -0.9643096865913288 and parameters: {'n_estimators': 340, 'learning_rate': 0.22662896630128396, 'max_depth': 8, 'subsample': 0.960564531231999, 'colsample_bytree': 0.8425494422891389, 'reg_lambda': 7.16860406499379, 'reg_alpha': 1.0186278451747377}. Best is trial 3 with value: -0.9771860445872139.\n",
      "[I 2025-08-11 11:05:34,540] Trial 5 finished with value: -0.9213620931133892 and parameters: {'n_estimators': 366, 'learning_rate': 0.10408740065085298, 'max_depth': 6, 'subsample': 0.8868738162342151, 'colsample_bytree': 0.6526390121916846, 'reg_lambda': 1.0929223672683577, 'reg_alpha': 4.152905507822075}. Best is trial 3 with value: -0.9771860445872139.\n",
      "[I 2025-08-11 11:05:34,669] Trial 6 finished with value: -0.9592118473361331 and parameters: {'n_estimators': 363, 'learning_rate': 0.2827483187353255, 'max_depth': 4, 'subsample': 0.9907620495208286, 'colsample_bytree': 0.6898817365606119, 'reg_lambda': 2.1954783828491977, 'reg_alpha': 1.51391408711529}. Best is trial 3 with value: -0.9771860445872139.\n",
      "[I 2025-08-11 11:05:34,933] Trial 7 finished with value: -0.9447893945217184 and parameters: {'n_estimators': 253, 'learning_rate': 0.2505336073414373, 'max_depth': 5, 'subsample': 0.6818451710589329, 'colsample_bytree': 0.8757060172885089, 'reg_lambda': 3.2962943495848367, 'reg_alpha': 0.49852408201525533}. Best is trial 3 with value: -0.9771860445872139.\n",
      "[I 2025-08-11 11:05:35,463] Trial 8 finished with value: -0.9706940223731061 and parameters: {'n_estimators': 599, 'learning_rate': 0.09988574154167239, 'max_depth': 5, 'subsample': 0.9416091982762576, 'colsample_bytree': 0.8883706062326631, 'reg_lambda': 5.172719878893194, 'reg_alpha': 0.8524551259860486}. Best is trial 3 with value: -0.9771860445872139.\n",
      "[I 2025-08-11 11:05:36,074] Trial 9 finished with value: -0.9829119180026699 and parameters: {'n_estimators': 379, 'learning_rate': 0.16380099160251577, 'max_depth': 8, 'subsample': 0.9603806291673622, 'colsample_bytree': 0.9442574591734834, 'reg_lambda': 5.334029102594409, 'reg_alpha': 0.059915258303753216}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:36,972] Trial 10 finished with value: -0.932227891058915 and parameters: {'n_estimators': 465, 'learning_rate': 0.02202200548270286, 'max_depth': 7, 'subsample': 0.8119984429208894, 'colsample_bytree': 0.9965776580029185, 'reg_lambda': 6.735908328940314, 'reg_alpha': 2.6579453012702037}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:37,314] Trial 11 finished with value: -0.932574500988104 and parameters: {'n_estimators': 454, 'learning_rate': 0.17706209097623893, 'max_depth': 7, 'subsample': 0.8330923980252434, 'colsample_bytree': 0.9158044798692164, 'reg_lambda': 4.662358186259398, 'reg_alpha': 2.2021878342767085}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:38,002] Trial 12 finished with value: -0.9751385988855085 and parameters: {'n_estimators': 428, 'learning_rate': 0.13846907803035188, 'max_depth': 6, 'subsample': 0.6738571717470381, 'colsample_bytree': 0.7916054896197267, 'reg_lambda': 4.277319522554754, 'reg_alpha': 0.013139538064997236}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:38,371] Trial 13 finished with value: -0.9366934384624217 and parameters: {'n_estimators': 291, 'learning_rate': 0.2084461987852212, 'max_depth': 7, 'subsample': 0.7464533450124539, 'colsample_bytree': 0.9371405030572929, 'reg_lambda': 6.490159158446844, 'reg_alpha': 2.086985615841106}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:39,525] Trial 14 finished with value: -0.9816516760283448 and parameters: {'n_estimators': 510, 'learning_rate': 0.07340298009859926, 'max_depth': 8, 'subsample': 0.867767483432119, 'colsample_bytree': 0.8252366510593231, 'reg_lambda': 5.902257127556139, 'reg_alpha': 0.07201640040151189}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:40,079] Trial 15 finished with value: -0.9075474902438748 and parameters: {'n_estimators': 513, 'learning_rate': 0.08040235677644725, 'max_depth': 8, 'subsample': 0.874078596145846, 'colsample_bytree': 0.7889150452957606, 'reg_lambda': 7.784419035709657, 'reg_alpha': 3.346093516730217}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:41,026] Trial 16 finished with value: -0.9436072250732799 and parameters: {'n_estimators': 501, 'learning_rate': 0.0392665858785944, 'max_depth': 8, 'subsample': 0.7530075883847998, 'colsample_bytree': 0.8328879999256948, 'reg_lambda': 5.98710964822975, 'reg_alpha': 1.6194359683310693}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:41,591] Trial 17 finished with value: -0.9121101777874322 and parameters: {'n_estimators': 401, 'learning_rate': 0.047602459490764235, 'max_depth': 7, 'subsample': 0.8497280046416541, 'colsample_bytree': 0.7497282563969234, 'reg_lambda': 8.092669354673495, 'reg_alpha': 4.946134138043067}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:42,409] Trial 18 finished with value: -0.9583486958763799 and parameters: {'n_estimators': 560, 'learning_rate': 0.07017977058243967, 'max_depth': 8, 'subsample': 0.9222125121039598, 'colsample_bytree': 0.9626073700154438, 'reg_lambda': 5.535737863787309, 'reg_alpha': 1.3889566175560635}. Best is trial 9 with value: -0.9829119180026699.\n",
      "[I 2025-08-11 11:05:42,806] Trial 19 finished with value: -0.9829597591681599 and parameters: {'n_estimators': 201, 'learning_rate': 0.15321339168849915, 'max_depth': 7, 'subsample': 0.7612466279640389, 'colsample_bytree': 0.7311296487169077, 'reg_lambda': 5.252919059599164, 'reg_alpha': 0.08672522652949056}. Best is trial 19 with value: -0.9829597591681599.\n",
      "[I 2025-08-11 11:05:43,035] Trial 20 finished with value: -0.9321460417213867 and parameters: {'n_estimators': 202, 'learning_rate': 0.1554704744663551, 'max_depth': 7, 'subsample': 0.7388572778916163, 'colsample_bytree': 0.7101002703988212, 'reg_lambda': 4.463574193074176, 'reg_alpha': 2.7137501766459473}. Best is trial 19 with value: -0.9829597591681599.\n",
      "[I 2025-08-11 11:05:43,724] Trial 21 finished with value: -0.9754399212683048 and parameters: {'n_estimators': 498, 'learning_rate': 0.12145344656635677, 'max_depth': 8, 'subsample': 0.7901645662294025, 'colsample_bytree': 0.6047018256922296, 'reg_lambda': 5.75903887484959, 'reg_alpha': 0.17783983149490462}. Best is trial 19 with value: -0.9829597591681599.\n",
      "[I 2025-08-11 11:05:44,212] Trial 22 finished with value: -0.9455715079614011 and parameters: {'n_estimators': 405, 'learning_rate': 0.1536968292218318, 'max_depth': 7, 'subsample': 0.6110369252591227, 'colsample_bytree': 0.7546690061021872, 'reg_lambda': 5.418961138705954, 'reg_alpha': 0.750032491732327}. Best is trial 19 with value: -0.9829597591681599.\n",
      "[I 2025-08-11 11:05:45,018] Trial 23 finished with value: -0.970917828913938 and parameters: {'n_estimators': 298, 'learning_rate': 0.07738647337013417, 'max_depth': 8, 'subsample': 0.7943033981014685, 'colsample_bytree': 0.8326287051921407, 'reg_lambda': 7.363446790678562, 'reg_alpha': 0.113914763877033}. Best is trial 19 with value: -0.9829597591681599.\n",
      "[I 2025-08-11 11:05:45,567] Trial 24 finished with value: -0.9718623281320217 and parameters: {'n_estimators': 451, 'learning_rate': 0.16612028516296043, 'max_depth': 7, 'subsample': 0.8624825331583275, 'colsample_bytree': 0.691703486255922, 'reg_lambda': 6.422837742820712, 'reg_alpha': 0.5184460846995661}. Best is trial 19 with value: -0.9829597591681599.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters from Optuna: {'n_estimators': 201, 'learning_rate': 0.15321339168849915, 'max_depth': 7, 'subsample': 0.7612466279640389, 'colsample_bytree': 0.7311296487169077, 'reg_lambda': 5.252919059599164, 'reg_alpha': 0.08672522652949056}\n",
      "\n",
      "Final Model Performance:\n",
      "R² Train: 1.0000 | RMSE Train: 0.0122\n",
      "R² Test: 0.9830 | RMSE Test: 0.6669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:218: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/942225979.py:219: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])], plot_type=\"bar\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAOsCAYAAADX7yC0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6mklEQVR4nOzdeVyU5f7/8ffIgCiLC2CoLGoumGFZGiWpmSCGZmGZp6wMl0It2+y0HL9lZlJqi8eyJhes1ArbXEpNj1YnraOIppkcO6loHQsoQTFRgfv3hz/mOM6AyA0zEK/n4+FDuO7rvudz33Nzw3uue7EYhmEIAAAAAExo4OkCAAAAANR9BAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAafU+WLzxxhs6deqUp8sAAAAA6rR6HywAAAAAmEewAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGCaxTAMw9NFeJJlZrGnSwAAAACcGBOtni7hvDBiAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCtxp+6kZGRoZSUlHKnp6WlKTo6WoZhaM2aNUpPT1d2drZOnTql0NBQxcfH69Zbb5W/v7/DfLm5uZo9e7Y2bdqk48ePq127dhoxYoTi4uJqepUAAAAAnMVtj/NLSEhQbGysU3t4eLgkac6cOUpLS1OPHj00ZswYWa1Wbd26VTabTRs3blRaWposFoskqaCgQKNHj9bvv/+u4cOHq0WLFlq9erUee+wxPfnkkxo8eLC7VgsAAACA3BgsoqKilJiY6HJacXGx3nnnHUVFRenVV19Vgwanz9C6+eabZbVatWrVKu3Zs0edOnWSJC1cuFA///yzXnzxRfXu3VuSdMMNNyg5OVmzZs1SXFycGjdu7J4VAwAAAFA7rrEoLi7WiRMnFBQUZA8VZYKDgyVJjRo1sretWbNGYWFh9lAhSV5eXho2bJgKCgq0ceNG9xQOAAAAQJIbg0VRUZHy8/Md/h07dkyS5Ovrq27duunrr7/WwoULdfDgQf33v//VihUr9P777+u6665TRESEJCkvL085OTmKjo52eo2ytu+//95dqwUAAABAbjwVymazyWazObTFx8crNTVVkjR16lRNnjxZr7zyil555RVJksVi0ciRIx0u/s7NzZUkhYSEOL1GixYtJEk5OTk1sg4AAAAAXHNbsEhKSnK6Y1NQUJD9ax8fH7Vu3VoDBw5Uz549JUnr16/X/Pnz5ePjo1GjRkk6PfJR1v9sZW1lfQAAAAC4h9uCRUREhGJiYlxOKyoq0siRI9WpUyf7CIZ0+k5Sjz/+uGw2m/r166c2bdrI19dXknTy5Emn5ZS1lfUBAAAA4B614uLtdevW6cCBAy6fQREXF6fS0lJt375d0v9OgSo7JepMZadAlZ0SBQAAAMA9akWwKAsJpaWlTtNKSkoc/g8ODlaLFi20c+dOp75lbZ07d66pUgEAAAC4UCuCRdu2bSVJK1eudJpW1talSxd7W0JCgn766Sd9+eWX9raSkhK99957CggIcPkgPgAAAAA1x23XWFSkV69e6tKlizZu3KgxY8aob9++kqQNGzZo27ZtiouLU1RUlL3/iBEjtG7dOk2aNEnDhw9XSEiI1qxZo++//16TJk2Sn5+fp1YFAAAAqJdqRbDw8vLSnDlztHDhQq1fv16zZ8+WxWJReHi47rvvPg0fPtyhf9OmTTV//nzNnj1b6enpOn78uNq2batp06apf//+HloLAAAAoP6yGIZheLoIT7LMLPZ0CQAAAIATY2KtGAOotFpxjQUAAACAuo1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwLS6dQ+rGmALXKDk5GR5e3t7uhQAAACgzmLEAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYZjEMw/B0EZ5kmVns6RKAamdMtHq6BAAAUM8wYgEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwrUafopWRkaGUlJRyp6elpSk6OlqGYWjNmjVKT09Xdna2Tp06pdDQUMXHx+vWW2+Vv79/ucvYuHGj7r//fknSW2+9pYsuuqja1wMAAABAxdzyeN6EhATFxsY6tYeHh0uS5syZo7S0NPXo0UNjxoyR1WrV1q1bZbPZtHHjRqWlpclisTjNf/z4cT333HNq3Lix/vjjjxpfDwAAAACuuSVYREVFKTEx0eW04uJivfPOO4qKitKrr76qBg1On5118803y2q1atWqVdqzZ486derkNO+cOXNUUlKipKQkLV68uEbXAQAAAED5PH6NRXFxsU6cOKGgoCB7qCgTHBwsSWrUqJHTfN9//73S09P10EMPqXHjxm6pFQAAAIBrbhmxKCoqUn5+vkObt7e3/Pz85Ovrq27duunrr7/WwoUL1a9fP3l5eWnr1q16//33dd111ykiIsJh3uLiYk2dOlUxMTGKi4vTjz/+6I7VAAAAAFAOtwQLm80mm83m0BYfH6/U1FRJ0tSpUzV58mS98soreuWVVyRJFotFI0eOdHnx96JFi5Sdna0ZM2bUfPEAAAAAzsktwSIpKUlxcXEObUFBQfavfXx81Lp1aw0cOFA9e/aUJK1fv17z58+Xj4+PRo0aZe/7008/ae7cuRo9erRat27tjvIBAAAAnINbgkVERIRiYmJcTisqKtLIkSPVqVMn+wiGdPpOUo8//rhsNpv69eunNm3aSJKmTZum1q1b64477nBH6QAAAAAqweMXb69bt04HDhxwGtGQpLi4OJWWlmr79u2SpA0bNmjz5s26/fbbdejQIR08eFAHDx7UkSNHJEk5OTk6ePCgSktL3bkKAAAAQL3nlhGLiuTm5kqSyzBQUlLi8P+hQ4ckSVOmTHG5rIkTJ0o6HVaaNm1a3aUCAAAAKIfHg0Xbtm0lSStXrlR8fLzDtJUrV0qSunTpIknq1auXWrRo4bSMdevWad26dbrvvvvUunVr+fn51XDVAAAAAM7k8WDRq1cvdenSRRs3btSYMWPUt29fSadPe9q2bZvi4uIUFRUl6fSTusue1n2mstvN9ujRQxdddJH7igcAAAAgqRYECy8vL82ZM0cLFy7U+vXrNXv2bFksFoWHh+u+++7T8OHDPV0iAAAAgHOwGIZheLoIT7LMLPZ0CUC1MyZ6/DMDAABQz3j8rlAAAAAA6j6CBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMq/c3u7cFLlBycrK8vb09XQoAAABQZzFiAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMsxiGYXi6CE+yzCz2dAmoo4yJVk+XAAAAUGswYgEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwrUaf8JWRkaGUlJRyp6elpSk6OlqGYWjNmjVKT09Xdna2Tp06pdDQUMXHx+vWW2+Vv7+/fZ4vvvhCn3/+uXbs2KFff/1V/v7+ateunW6//Xb17NmzJlcHAAAAQDnc8ujghIQExcbGOrWHh4dLkubMmaO0tDT16NFDY8aMkdVq1datW2Wz2bRx40alpaXJYrFIkqZNmyY/Pz/16dNHkZGRKigo0IoVKzRhwgSNHTtWo0aNcscqAQAAADiDW4JFVFSUEhMTXU4rLi7WO++8o6ioKL366qtq0OD02Vk333yzrFarVq1apT179qhTp06SpKlTp6pHjx4Oyxg2bJhuu+02zZ07V0OHDlVgYGDNrhAAAAAABx6/xqK4uFgnTpxQUFCQPVSUCQ4OliQ1atTI3nZ2qJAkX19f9erVS8XFxcrOzq7ZggEAAAA4ccuIRVFRkfLz8x3avL295efnJ19fX3Xr1k1ff/21Fi5cqH79+snLy0tbt27V+++/r+uuu04RERHnfI2cnBxJUvPmzWtiFQAAAABUwGIYhlFTC6/o4u34+HilpqZKOh0KJk+erM2bN/+vMItFI0eOVEpKiv36ivLs2bNHd9xxh7p27aq5c+eeV42WmcXn1R8oY0x0Sy4HAACoE9zyl1FSUpLi4uIc2oKCguxf+/j4qHXr1ho4cKD9zk7r16/X/Pnz5ePjU+EF2YcPH9YjjzwiX19fTZo0qWZWAAAAAECF3BIsIiIiFBMT43JaUVGRRo4cqU6dOtlHMKTTd5J6/PHHZbPZ1K9fP7Vp08Zp3oKCAo0fP155eXl6+eWXFRkZWVOrAAAAAKACHr94e926dTpw4IDTiIYkxcXFqbS0VNu3b3eaVlBQoHHjxmn//v2aOXOmy4u6AQAAALiHx4NFbm6uJKm0tNRpWklJicP/ZcpCxb59+zRjxgxdddVVNV8oAAAAgHJ5PFi0bdtWkrRy5UqnaWVtXbp0sbcdOXJE48eP1969ezV9+nSXD94DAAAA4F4ev61Nr1691KVLF23cuFFjxoxR3759JUkbNmzQtm3bFBcXp6ioKHv/8ePHKysrSwkJCTpy5Ig+/fRTh+V17dpVYWFhbl0HAAAAoL7zeLDw8vLSnDlztHDhQq1fv16zZ8+WxWJReHi47rvvPg0fPtyh/+7duyVJa9as0Zo1a5yW99RTTxEsAAAAADer0edY1AU8xwJVxXMsAAAA/sfj11gAAAAAqPsIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEyr9/fLtAUuUHJysry9vT1dCgAAAFBnMWIBAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwzWIYhuHpIjzJMrPY0yU4MCZaPV0CAAAAcN4YsQAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKbV6EMTMjIylJKSUu70tLQ0RUdHa+3atdq0aZOysrK0d+9elZSUaPny5WrVqpXTPF988YU+//xz7dixQ7/++qv8/f3Vrl073X777erZs2dNrg4AAACAcrjlaWwJCQmKjY11ag8PD5ckLV26VLt27VKHDh0UFham7Ozscpc1bdo0+fn5qU+fPoqMjFRBQYFWrFihCRMmaOzYsRo1alSNrQcAAAAA19wSLKKiopSYmFju9ClTpig4OFhWq1XPP/98hcFi6tSp6tGjh0PbsGHDdNttt2nu3LkaOnSoAgMDq612AAAAAOdWK66xCA0NldVauYxzdqiQJF9fX/Xq1UvFxcUVhhIAAAAANcMtIxZFRUXKz893aPP29pafn1+1vUZOTo4kqXnz5tW2TAAAAACV45ZgYbPZZLPZHNri4+OVmppaLcvfs2eP1q9fr27duql169bVskwAAAAAleeWYJGUlKS4uDiHtqCgoGpZ9uHDh/XII4/I19dXkyZNqpZlAgAAADg/bgkWERERiomJqfblFhQUaPz48crLy9PLL7+syMjIan8NAAAAAOfmlmBREwoKCjRu3Djt379fL7zwgsuLugEAAAC4R624K9T5KgsV+/bt04wZM3TVVVd5uiQAAACgXqtzIxZHjhzR+PHjtXfvXs2YMcPlg/cAAAAAuFetCBaZmZnKzMyUJO3evVuSlJ6eLn9/f0nS6NGj7X3Hjx+vrKwsJSQk6MiRI/r0008dltW1a1eFhYW5qXIAAAAAUi0JFlu2bNHcuXMd2hYtWmT/+sxgURY81qxZozVr1jgt66mnniJYAAAAAG5mMQzD8HQRnmSZWezpEhwYE2tF1gMAAADOS528eBsAAABA7UKwAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBp9f6hCbbABUpOTpa3t7enSwEAAADqLEYsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpFsMwDE8X4UmWmcU1tmxjorXGlg0AAADUJoxYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEyrVU9wy8jIUEpKSrnT09LSFB0dLUkqLi7W+++/rxUrVig7O1teXl4KCwvTkCFDdNNNN7mrZAAAAACqZcGiTEJCgmJjY53aw8PDJUmnTp3SQw89pIyMDA0YMEA33XSTSkpKdODAAf3yyy/uLhcAAACo92plsIiKilJiYmK50+fNm6fNmzfr1VdfVffu3d1YGQAAAABX6tw1FsePH9e7776r3r17q3v37jIMQ8eOHfN0WQAAAEC9VitHLIqKipSfn+/Q5u3tLT8/P23btk3Hjh1T586dNXPmTC1fvlx//PGHmjZtqqSkJN1zzz2yWmvlagEAAAB/WrXyL3CbzSabzebQFh8fr9TUVGVnZ0uS3nnnHXl7e2vChAlq0qSJVq1apbS0NOXk5Ojpp5/2RNkAAABAvVUrg0VSUpLi4uIc2oKCgiTJftrTkSNH9N5776lNmzaSTgePe+65R5988onuuusutW3b1q01AwAAAPVZrQwWERERiomJcTnN19dXknTxxRfbQ0WZgQMHauvWrdq6dSvBAgAAAHCjOnfxdosWLST9bwTjTMHBwZJOj2YAAAAAcJ86Fyy6dOkiScrJyXGaVtbWvHlzt9YEAAAA1Hd1Lli0bt1al1xyiXbt2qWsrCx7e0lJiT766CN5eXnpyiuv9GCFAAAAQP1TK6+xOJdHHnlEY8aM0bhx4zRs2DA1adJEa9eu1a5duzRmzBiFhoZ6ukQAAACgXqmTwSIqKkoLFizQnDlz9M477+jkyZNq06aNnnrqKV1//fWeLg8AAACodyyGYRieLsKTLDOLa2zZxsQ6mdsAAACA81bnrrEAAAAAUPsQLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhW7++HagtcoOTkZHl7e3u6FAAAAKDOYsQCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgmsUwDMPTRXiSZWZxlec1JlqrsRIAAACg7mLEAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmFarHsSQkZGhlJSUcqenpaXpxIkTFfaRpHnz5unSSy+t5uoAAAAAlKdWBYsyCQkJio2NdWoPDw9XSUmJpkyZ4jTt5MmTmjZtmpo2baqLL77YHWUCAAAA+P9qZbCIiopSYmJiudNdTVu9erVKS0s1cOBAWa21crUAAACAP60/zTUWy5YtkyTdcMMNHq4EAAAAqH9q5Uf7RUVFys/Pd2jz9vaWn5+fy/4///yzMjIydOmll6pNmzY1XyAAAAAAB7UyWNhsNtlsNoe2+Ph4paamuuy/fPlyGYahG2+80Q3VAQAAADhbrQwWSUlJiouLc2gLCgpy2bekpEQrV66Un5+f0zwAAAAA3KNWBouIiAjFxMRUqu/XX3+tX3/9VUOGDJGvr28NVwYAAADAlTp/8XbZRducBgUAAAB4Tp0OFr///rv++c9/qmPHjrrooos8XQ4AAABQb9XpYPHJJ5+ouLhYgwcP9nQpAAAAQL1Wp4PFsmXL1LBhwwofpgcAAACg5tXZYPHtt99q//796tu3rwIDAz1dDgAAAFCvWQzDMDxdhCdZZhZXeV5jYq28qRYAAADgdnV2xAIAAABA7UGwAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBp9f5BDLbABUpOTpa3t7enSwEAAADqLEYsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpFsMwDE8X4UmWmcVVms+YaK3mSgAAAIC6ixELAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGk1+pS3jIwMpaSklDs9LS1N0dHRWrt2rTZt2qSsrCzt3btXJSUlWr58uVq1auU0z8qVK7V69Wrt3btX+fn5aty4scLDwzVkyBAlJibKy8urJlcJAAAAgAtueXx0QkKCYmNjndrDw8MlSUuXLtWuXbvUoUMHhYWFKTs7u9xlZWVlKSAgQEOHDlWzZs10/PhxffXVV3r66ae1bds2PfnkkzW2HgAAAABcc0uwiIqKUmJiYrnTp0yZouDgYFmtVj3//PMVBouJEyc6td166626//77tWLFCo0bN07BwcHVUjcAAACAyqkV11iEhobKajWXcVq2bCnDMFRYWFhNVQEAAACoLLeMWBQVFSk/P9+hzdvbW35+flVeZmFhoYqLi3XkyBF9/fXXWr58uSIiIuynVwEAAABwH7cEC5vNJpvN5tAWHx+v1NTUKi9z7Nix2r17tyTJYrHoiiuu0OOPP87F2wAAAIAHuCVYJCUlKS4uzqEtKCjI1DIfffRRHTt2THl5efrqq6/0+++/6+jRo6aWCQAAAKBq3BIsIiIiFBMTU63LvPjii+1fDxw4UK+88orGjBmjd999V2FhYdX6WgAAAAAqVisu3q4OgwYNUlFRkVasWOHpUgAAAIB6508TLIqKiiRJR44c8XAlAAAAQP1Tp4JFcXGx092lyrz33nuSHE+RAgAAAOAebrnG4lwyMzOVmZkpSfY7PaWnp8vf31+SNHr0aEnS8ePHNXDgQF1zzTW68MIL1bx5c/3222/64osv9P333+uKK67QgAEDPLMSAAAAQD1WK4LFli1bNHfuXIe2RYsW2b8uCxa+vr4aOnSoMjMz9c0336iwsFCNGzdWu3bt9Ne//lVDhgzhdrMAAACAB1gMwzA8XYQnWWYWV2k+Y2KtyGQAAABArVCnrrEAAAAAUDsRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhW7++ZagtcoOTkZHl7e3u6FAAAAKDOYsQCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgmsUwDMPTRXiSZWbxefU3JlprqBIAAACg7mLEAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmFarHsqQkZGhlJSUcqenpaUpOjpad999tzIzM132eeutt3TRRRfVVIkAAAAAXKhVwaJMQkKCYmNjndrDw8PtXzdt2lQPPfSQU5/WrVvXaG0AAAAAnNXKYBEVFaXExMQK+zRq1OicfQAAAAC4R52+xqK0tFSFhYUyDMPTpQAAAAD1Wq0csSgqKlJ+fr5Dm7e3t/z8/Ozf5+TkqFevXjpx4oR8fX111VVXafz48WrTpo17iwUAAABQO4OFzWaTzWZzaIuPj1dqaqqk09dRXHLJJerQoYMaNGigXbt2KT09XZs3b9b8+fPVvn17T5QNAAAA1Fu1MlgkJSUpLi7OoS0oKMj+9VNPPeUwLS4uTr1799Y999yjF198UXPmzHFLnQAAAABOq5XBIiIiQjExMec1T7du3dStWzdt3bpVRUVF8vX1raHqAAAAAJytTl+8fbZWrVqppKRER48e9XQpAAAAQL3ypwoWBw4ckJeXlwIDAz1dCgAAAFCv1LlgUVhYqJKSEqf2r776St9++61iYmLUsGFDD1QGAAAA1F+18hqLimRkZOill15Sr1691Lp1a3l5eWnXrl1atWqVmjZtqocfftjTJQIAAAD1Tp0LFpGRkercubP++c9/6vfff1dxcbFatGihm266ScnJyWrRooWnSwQAAADqHYtRzx9bbZlZfF79jYl1LosBAAAANa7OXWMBAAAAoPYhWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADAtHr/UAZb4AIlJyfL29vb06UAAAAAdRYjFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIthGIani/Aky8ziSvc1JlprsBIAAACg7mLEAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGBajT/xLSMjQykpKeVOT0tLU3R0tNauXatNmzYpKytLe/fuVUlJiZYvX65WrVq5nC83N1ezZ8/Wpk2bdPz4cbVr104jRoxQXFxcTa0KAAAAgHK47VHSCQkJio2NdWoPDw+XJC1dulS7du1Shw4dFBYWpuzs7HKXVVBQoNGjR+v333/X8OHD1aJFC61evVqPPfaYnnzySQ0ePLjG1gMAAACAM7cFi6ioKCUmJpY7fcqUKQoODpbVatXzzz9fYbBYuHChfv75Z7344ovq3bu3JOmGG25QcnKyZs2apbi4ODVu3Lja1wEAAACAa7XmGovQ0FBZrZXLOWvWrFFYWJg9VEiSl5eXhg0bpoKCAm3cuLGmygQAAADggtuCRVFRkfLz8x3+HTt27LyXk5eXp5ycHEVHRztNK2v7/vvvTdcLAAAAoPLcdiqUzWaTzWZzaIuPj1dqaup5LSc3N1eSFBIS4jStRYsWkqScnJwqVgkAAACgKtwWLJKSkpzu2BQUFHTeyykqKpIk+fj4OE0rayvrAwAAAMA93BYsIiIiFBMTY3o5vr6+kqSTJ086TStrK+sDAAAAwD1qzcXblVV2ClTZKVFnKjsFquyUKAAAAADuUeeCRXBwsFq0aKGdO3c6TStr69y5s7vLAgAAAOq1OhcspNMP2/vpp5/05Zdf2ttKSkr03nvvKSAgwOWD+AAAAADUHLddY3EumZmZyszMlCTt3r1bkpSeni5/f39J0ujRo+19R4wYoXXr1mnSpEkaPny4QkJCtGbNGn3//feaNGmS/Pz83L8CAAAAQD1Wa4LFli1bNHfuXIe2RYsW2b8+M1g0bdpU8+fP1+zZs5Wenq7jx4+rbdu2mjZtmvr37++2mgEAAACcZjEMw/B0EZ5kmVlc6b7GxFqTwwAAAIBapU5eYwEAAACgdiFYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMK3e3z/VFrhAycnJ8vb29nQpAAAAQJ3FiAUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0i2EYhqeL8CTLzOJK9zUmWmuwEgAAAKDuYsQCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYVqsezJCRkaGUlJRyp6elpSk6Otqp/fHHH9fatWvVrl07paen12SJAAAAAFyoVcGiTEJCgmJjY53aw8PDndr++c9/6h//+IcaNmzojtIAAAAAuFArg0VUVJQSExPP2e+PP/7Qc889p6FDh+rLL790Q2UAAAAAXKnT11jMmTNHpaWlGjt2rKdLAQAAAOq1WjliUVRUpPz8fIc2b29v+fn52b//7rvvlJ6ermeffVb+/v5urhAAAADAmWplsLDZbLLZbA5t8fHxSk1NlSQVFxdr6tSpuvLKKxUfH++JEgEAAACcoVYGi6SkJMXFxTm0BQUF2b9+++23dfDgQc2cOdPdpQEAAABwoVYGi4iICMXExLicdvDgQc2bN08jR45UWFiYmysDAAAA4EqtDBYVeemllxQYGKi+ffvq4MGD9vaSkhIVFxfr4MGDatSokYKDgz1YJQAAAFC/1Llg8csvvyg3N1e33HKLy+lJSUm6+uqr9fLLL7u3MAAAAKAeq3PB4v7779fRo0ed2p9//nn5+PjowQcfZLQCAAAAcLM6FyzKu/Zi1qxZatSokdNF3wAAAABqXp1+QB4AAACA2sFiGIbh6SI8yTKzuNJ9jYl1boAHAAAAcAtGLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGn1/sEMtsAFSk5Olre3t6dLAQAAAOosRiwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkWwzAMTxfhSZaZxZXqZ0y01nAlAAAAQN3FiAUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADAtFr11LeMjAylpKSUOz0tLU3R0dEqLi7WW2+9pU8//VQ///yzGjdurMsuu0zjx49XmzZt3FcwAAAAAEm1LFiUSUhIUGxsrFN7eHi4DMPQQw89pE2bNumaa67RsGHDdPjwYb3//vtKTk7W/Pnz1a5dOw9UDQAAANRftTJYREVFKTEx0eW0zz//XJs2bVJSUpL+9re/2dsTExM1bNgwzZw5U3PmzHFXqQAAAABUB6+xyMjIkCQNHjzYoT0sLEzdunXT5s2b9csvv3iiNAAAAKDeqpUjFkVFRcrPz3do8/b2lp+fn06ePClJ8vX1dZqvrO27775TaGhojdcJAAAA4LRaGSxsNptsNptDW3x8vFJTU+3XT2zZskUdOnSwTy8qKtJ3330nSYxYAAAAAG5WK4NFUlKS4uLiHNqCgoIknb6WYsGCBbLZbGrUqJGuuOIK5efny2az2Uc5ioqK3F0yAAAAUK/VymARERGhmJgYl9MCAwM1Z84cPfnkk3r22Wft7ZdddplGjBih+fPny9/f312lAgAAAFAtDRbn0r59ey1ZskQHDx5Ubm6uQkJCFB4erlmzZkkSz7IAAAAA3KxOBosy4eHhCg8Pt3+/adMm+fn56ZJLLvFgVQAAAED9U+duN1ued999Vz/++KNuu+02NWrUyNPlAAAAAPVKnRyxmDBhglq3bq127drJYrHom2++0eeff66rr75ao0aN8nR5AAAAQL1TJ4NF165d9dlnn2nlypWSpLZt2+rRRx/VkCFD5OXl5eHqAAAAgPrHYhiG4ekiPMkys7hS/YyJdTKDAQAAAG7xp7nGAgAAAIDnECwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYVu/voWoLXKDk5GR5e3t7uhQAAACgzmLEAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYJrFMAzD00V4kmVm8Tn7GBOtbqgEAAAAqLsYsQAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKad9wMaMjIylJKSUu70tLQ0RUdHa+3atdq0aZOysrK0d+9elZSUaPny5WrVqpXTPF988YU+//xz7dixQ7/++qv8/f3Vrl073X777erZs6dT/z/++ENz587V+vXrlZOTo8DAQPXs2VNjx45VixYtzneVAAAAAJhU5Se/JSQkKDY21qk9PDxckrR06VLt2rVLHTp0UFhYmLKzs8td1rRp0+Tn56c+ffooMjJSBQUFWrFihSZMmKCxY8dq1KhR9r5FRUW6++679e9//1sDBw5UdHS0/vvf/2rp0qXavHmz3nzzTQUHB1d1tQAAAABUQZWDRVRUlBITE8udPmXKFAUHB8tqter555+vMFhMnTpVPXr0cGgbNmyYbrvtNs2dO1dDhw5VYGCgJOnDDz9UVlaWxo8fr+TkZHv/3r17a/To0Xrttdf0f//3f1VdLQAAAABVUGPXWISGhspqrVxuOTtUSJKvr6969eql4uJih1CSkZEhSbr++usd+l9yySUKDw/XZ599phMnTpioHAAAAMD5qnKwKCoqUn5+vsO/Y8eOVWdtysnJkSQ1b97c3nbq1ClJp4PH2Xx9fXX8+HH95z//qdY6AAAAAFSsysHCZrMpLi7O4d/UqVOrrbA9e/Zo/fr16tatm1q3bm1vb9eunaT/jVyUycvLs49s/Prrr9VWBwAAAIBzq/I1FklJSYqLi3NoCwoKMl2QJB0+fFiPPPKIfH19NWnSJIdpN998sz744AOlpqbq5MmTio6O1qFDhzRr1iyVlJRIOj2aAgAAAMB9qhwsIiIiFBMTU521SJIKCgo0fvx45eXl6eWXX1ZkZKTD9PDwcL388suaOnWqnnjiCXt737591blzZ73//vvy8/Or9roAAAAAlK/KwaImFBQUaNy4cdq/f79eeOEFlxd1S1L37t310Ucfad++fcrPz1erVq0UGhqqxx57TJLUpk0bN1YNAAAAoNYEi7JQsW/fPs2YMUNXXXVVhf0tFov9egtJOnnypLZs2aLw8HCnUQ4AAAAANavGbjd7Po4cOaLx48dr7969mj59ussH753Lq6++qoKCAo0cObIGKgQAAABQkRobscjMzFRmZqYkaffu3ZKk9PR0+fv7S5JGjx5t7zt+/HhlZWUpISFBR44c0aeffuqwrK5duyosLMz+/e23367u3bsrPDxcp06d0ueff66MjAwlJSU5Pd8CAAAAQM2rsWCxZcsWzZ0716Ft0aJF9q/PDBZlwWPNmjVas2aN07Keeuoph2ARHR2tL7/8Ur/++qusVqs6duyoqVOnasCAAdW9GgAAAAAqwWIYhuHpIjzJMrP4nH2MibXmUhQAAACgVqoV11gAAAAAqNsIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwrd4/oMEWuEDJycny9vb2dCkAAABAncWIBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwzWIYhuHpIjzJMrO4wunGRKubKgEAAADqLkYsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKad99PfMjIylJKSUu70tLQ0RUdHa+3atdq0aZOysrK0d+9elZSUaPny5WrVqpXTPNdff70OHTpU7jJvvPFGTZo0yaFt5cqVWrJkibKzs+Xn56devXrp3nvvVbNmzc53lQAAAACYVOXHSickJCg2NtapPTw8XJK0dOlS7dq1Sx06dFBYWJiys7PLXdbDDz+sP/74w6l96dKl2rlzp3r16uXQvnjxYr300ku67LLL9PDDDysnJ0eLFy/Wzp079eabb6pRo0ZVXS0AAAAAVVDlYBEVFaXExMRyp0+ZMkXBwcGyWq16/vnnKwwW11xzjVNbUVGRpk+fruDgYIcAk5+fr9dee00XXXSRXnvtNXl5eUmSLrroIj300EN65513NHLkyKquFgAAAIAqqLFrLEJDQ2W1Vjm36B//+IcKCws1aNAgh+V8/vnnKioq0rBhw+yhQpJ69+6t1q1ba9WqVabqBgAAAHD+qhwsioqKlJ+f7/Dv2LFj1VbYsmXLZLFYdMMNNzi079q1S5LUtWtXp3mio6O1f/9+l6dVAQAAAKg5VR5SsNlsstlsDm3x8fFKTU01XdTBgwe1bds2XXbZZfZrNsrk5eVJkkJCQpzmCwkJkWEYys3NVWRkpOk6AAAAAFROlYNFUlKS4uLiHNqCgoJMFySdHq0wDMNptEI6PVIiST4+Pk7TGjZs6NAHAAAAgHtUOVhEREQoJiamOmuRJJWUlGjlypUKCAhQv379nKb7+vpKkk6ePGn/usyJEycc+gAAAABwj1r3gLyNGzcqLy9PAwYMsI9AnCk4OFiSlJub6zQtNzdXFovF5WlSAAAAAGpOrQsWH3/8saTTD8VzpUuXLpKkHTt2OE3buXOnIiMj1bhx45oqDwAAAIALtSpY5OXlaePGjYqKilKnTp1c9unTp48aNmyo9PR0lZSU2Nu//PJL/fzzzxowYIC7ygUAAADw/1X9QRPnkJmZqczMTEnS7t27JUnp6eny9/eXJI0ePdppnpUrV6qkpKTc0QpJatasmcaOHauXX35Z48aNU0JCgnJzc7Vo0SK1adNGt912W/WvDAAAAIAK1Viw2LJli+bOnevQtmjRIvvXroLF8uXL1bBhw3OOOtx+++1q0qSJlixZopkzZ8rPz09xcXG67777OA0KAAAA8ACLYRiGp4vwJMvM4gqnGxNrLHsBAAAAfxq16hoLAAAAAHUTwQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBp9f5eqrbABUpOTpa3t7enSwEAAADqLEYsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAplkMwzA8XYQnWWYWVzjdmGh1UyUAAABA3cWIBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMK1GH9KQkZGhlJSUcqenpaUpOjpaa9eu1aZNm5SVlaW9e/eqpKREy5cvV6tWrZzm2b9/vz7++GNlZWUpKytLhYWFGjNmjO65556aXBUAAAAAFXDL098SEhIUGxvr1B4eHi5JWrp0qXbt2qUOHTooLCxM2dnZ5S5r586dWrx4scLCwtS5c2dt2bKlxuoGAAAAUDluCRZRUVFKTEwsd/qUKVMUHBwsq9Wq559/vsJg0bt3b61fv14BAQH6/vvvdeedd9ZEyQAAAADOg1uCxbmEhoZWum+TJk1qsBIAAAAAVeGWYFFUVKT8/HyHNm9vb/n5+bnj5QEAAADUMLcEC5vNJpvN5tAWHx+v1NRUd7w8AAAAgBrmlmCRlJSkuLg4h7agoCB3vDQAAAAAN3BLsIiIiFBMTIw7XgoAAACAB/CAPAAAAACmESwAAAAAmEawAAAAAGBarXiORWZmpjIzMyVJu3fvliSlp6fL399fkjR69Gh738LCQr377ruSpLy8PEnStm3bNG/ePElSnz591KFDB7fVDgAAAKCWBIstW7Zo7ty5Dm2LFi2yf31msDhy5Ihef/11h74ZGRnKyMiQJF1wwQUECwAAAMDNLIZhGJ4uwpMsM4srnG5MrBXZCwAAAKjVuMYCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYVu8f0mALXKDk5GR5e3t7uhQAAACgzmLEAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYZjEMw/B0EZ5kmVnsst2YaHVzJQAAAEDdxYgFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwLTzfgpcRkaGUlJSyp2elpam6OhorV27Vps2bVJWVpb27t2rkpISLV++XK1atXKaZ//+/fr444+VlZWlrKwsFRYWasyYMbrnnnvKfY2yvj///LNatmypFStWnO+qAAAAAKgmVX68dEJCgmJjY53aw8PDJUlLly7Vrl271KFDB4WFhSk7O7vcZe3cuVOLFy9WWFiYOnfurC1btlT42q+++qqaNGmiTp066ejRo1VdBQAAAADVpMrBIioqSomJieVOnzJlioKDg2W1WvX8889XGCx69+6t9evXKyAgQN9//73uvPPOCl/7448/VlhYmCTplltu0fHjx6u2EgAAAACqRZWDxbmEhoZWum+TJk3Oa9lloQIAAABA7VDlYFFUVKT8/HyHNm9vb/n5+ZmtCQAAAEAdU+VgYbPZZLPZHNri4+OVmppquigAAAAAdUuVg0VSUpLi4uIc2oKCgkwXBAAAAKDuqXKwiIiIUExMTHXWAgAAAKCO4gF5AAAAAEwjWAAAAAAwjWABAAAAwLQae45FZmamMjMzJUm7d++WJKWnp8vf31+SNHr0aHvfwsJCvfvuu5KkvLw8SdK2bds0b948SVKfPn3UoUMHe/9PPvlEhw4dkiTl5+fr1KlT9r4tW7bUwIEDa2q1AAAAALhQY8Fiy5Ytmjt3rkPbokWL7F+fGSyOHDmi119/3aFvRkaGMjIyJEkXXHCBQ7BYtmyZPbSUKZv/sssuI1gAAAAAbmYxDMPwdBGeZJlZ7LLdmFhjmQsAAAD40+EaCwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYVu/vqWoLXKDk5GR5e3t7uhQAAACgzmLEAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYJrFMAzD00V4kmVmsct2Y6LVzZUAAAAAdRcjFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwLTzflhDRkaGUlJSyp2elpam6OhorV27Vps2bVJWVpb27t2rkpISLV++XK1atXKa54svvtDnn3+uHTt26Ndff5W/v7/atWun22+/XT179nTq/8EHH2jbtm3avXu3Dh48qNLSUmVkZJzvqgAAAACoJlV+ClxCQoJiY2Od2sPDwyVJS5cu1a5du9ShQweFhYUpOzu73GVNmzZNfn5+6tOnjyIjI1VQUKAVK1ZowoQJGjt2rEaNGuXQf+HChSooKFCnTp1UVFSkX3/9taqrAQAAAKAaVDlYREVFKTExsdzpU6ZMUXBwsKxWq55//vkKg8XUqVPVo0cPh7Zhw4bptttu09y5czV06FAFBgbap9lsNoWGhqpBgwZ64IEHCBYAAACAh9XYNRahoaGyWiuXW84OFZLk6+urXr16qbi42CmUtGrVSg0acHkIAAAAUFtUecSiqKhI+fn5Dm3e3t7y8/MzW5NdTk6OJKl58+bVtkwAAAAA1a/KwcJms8lmszm0xcfHKzU11XRRkrRnzx6tX79e3bp1U+vWratlmQAAAABqRpWDRVJSkuLi4hzagoKCTBckSYcPH9YjjzwiX19fTZo0qVqWCQAAAKDmVDlYREREKCYmpjprkSQVFBRo/PjxysvL08svv6zIyMhqfw0AAAAA1avKwaImFBQUaNy4cdq/f79eeOEFlxd1AwAAAKh9as2tlcpCxb59+zRjxgxdddVVni4JAAAAQCXVihGLI0eOaPz48dq7d69mzJjh8sF7AAAAAGqvGgsWmZmZyszMlCTt3r1bkpSeni5/f39J0ujRo+19x48fr6ysLCUkJOjIkSP69NNPHZbVtWtXhYWF2b//8ssvtWfPHknSwYMHJUnz5s2TJAUEBGjYsGE1tFYAAAAAXKmxYLFlyxbNnTvXoW3RokX2r88MFmXBY82aNVqzZo3Tsp566imHYLF+/XqtXLnSoc/rr78uSWrZsiXBAgAAAHAzi2EYhqeL8CTLzGKX7cbEWnGWGAAAAFAn1JqLtwEAAADUXQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhW7x/WYAtcoOTkZHl7e3u6FAAAAKDOYsQCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhmMQzD8HQRnmSZWeyy3ZhodXMlAAAAQN3FiAUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADAtBp9ClxGRoZSUlLKnZ6Wlqbo6GgZhqE1a9YoPT1d2dnZOnXqlEJDQxUfH69bb71V/v7+9nlWrFihp59+2uXyhg4dqkcffbTa1wMAAABAxdzyeOmEhATFxsY6tYeHh0uS5syZo7S0NPXo0UNjxoyR1WrV1q1bZbPZtHHjRqWlpclisTjMm5ycrLZt2zq0RUZG1txKAAAAACiXW4JFVFSUEhMTXU4rLi7WO++8o6ioKL366qtq0OD02Vk333yzrFarVq1apT179qhTp04O88XExKh79+41XjsAAACAc/P4NRbFxcU6ceKEgoKC7KGiTHBwsCSpUaNGLuc9duyYTp06VeM1AgAAAKiYW0YsioqKlJ+f79Dm7e0tPz8/+fr6qlu3bvr666+1cOFC9evXT15eXtq6davef/99XXfddYqIiHBa5sMPP6xjx47JYrGoffv2uuOOO8odFQEAAABQsyyGYRg1tfCKLt6Oj49XamqqJCknJ0eTJ0/W5s2b/1eYxaKRI0cqJSXF4fqKtWvX6osvvlD37t3VvHlz/fe//1V6eroOHDigu+++W3ffffd51WiZWeyy3ZjolswFAAAA/Cm45a/npKQkxcXFObQFBQXZv/bx8VHr1q01cOBA9ezZU5K0fv16zZ8/Xz4+Pho1apS9b3x8vOLj4x2WNWTIEN1xxx2aP3++Bg0apFatWtXg2gAAAAA4m1uCRUREhGJiYlxOKyoq0siRI9WpUyf7CIZ0+k5Sjz/+uGw2m/r166c2bdqUu3wfHx/dcccdmjx5sr755hsNGTKkulcBAAAAQAU8fvH2unXrdODAAacRDUmKi4tTaWmptm/ffs7ltGzZUpKcruUAAAAAUPM8Hixyc3MlSaWlpU7TSkpKHP6vyMGDByVJzZs3r8bqAAAAAFSGx4NF2UPuVq5c6TStrK1Lly72NlcjEoWFhXrzzTfl7e2tq666qmYKBQAAAFAuj9/6qFevXurSpYs2btyoMWPGqG/fvpKkDRs2aNu2bYqLi1NUVJS9/1/+8hdddtllat++vf2uUMuXL1deXp4eeOABXXDBBZ5aFQAAAKDe8niw8PLy0pw5c7Rw4UKtX79es2fPlsViUXh4uO677z4NHz7coX9CQoK2bt2qf/3rXyosLJS/v7+6dOmip556itEKAAAAwENq9DkWdQHPsQAAAADM8/g1FgAAAADqPoIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0+r9PVVtgQuUnJwsb29vT5cCAAAA1FmMWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEyzGIZheLoIT7LMLHZqMyZaPVAJAAAAUHcxYgEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEw77wc2ZGRkKCUlpdzpaWlpio6O1tq1a7Vp0yZlZWVp7969Kikp0fLly9WqVSunea6//nodOnSo3GXeeOONmjRpkstppaWlGjVqlHbu3Kmrr75aL7/88vmuEgAAAACTqvwkuISEBMXGxjq1h4eHS5KWLl2qXbt2qUOHDgoLC1N2dna5y3r44Yf1xx9/OLUvXbpUO3fuVK9evcqdd+nSpfrxxx+rsAYAAAAAqkuVg0VUVJQSExPLnT5lyhQFBwfLarXq+eefrzBYXHPNNU5tRUVFmj59uoKDg10GGEn69ddfNWfOHN19992MVAAAAAAeVGPXWISGhspqrXJu0T/+8Q8VFhZq0KBB5S7n+eefV+vWrXXrrbdW+XUAAAAAmFflv/yLioqUn5/v0Obt7S0/Pz+zNUmSli1bJovFohtuuMHl9HXr1umf//ynFixYIC8vr2p5TQAAAABVU+VgYbPZZLPZHNri4+OVmppquqiDBw9q27Ztuuyyy+zXbJypsLBQM2fO1JAhQxQdHW369QAAAACYU+VgkZSUpLi4OIe2oKAg0wVJp0crDMMod7Ri1qxZMgxD9957b7W8HgAAAABzqhwsIiIiFBMTU521SJJKSkq0cuVKBQQEqF+/fk7Tt23bpo8//lhTpkxRQEBAtb8+AAAAgPNX9aura8jGjRuVl5enoUOHqmHDhk7Tp0+frg4dOujiiy/WwYMHHaYVFRXp4MGDCggIUNOmTd1UMQAAAIBaFyw+/vhjSacfiufKoUOHVFhYqKSkJKdpGRkZSkpK0tChQ/Xoo4/WYJUAAAAAzlSrgkVeXp42btyoqKgoderUyWWfp59+WqdOnXJqf+yxx9S5c2eNGDHC5QXfAAAAAGpOjQWLzMxMZWZmSpJ2794tSUpPT5e/v78kafTo0U7zrFy5UiUlJeWOVkhSnz59yp0WFBTkdEE5AAAAgJpXY8Fiy5Ytmjt3rkPbokWL7F+7ChbLly9Xw4YNNWDAgJoqCwAAAEANsBiGYXi6CE+yzCx2ajMm1qozxAAAAIBar4GnCwAAAABQ9xEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGBavX9ggy1wgZKTk+Xt7e3pUgAAAIA6ixELAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGCaxTAMw9NFeJJlZrFTmzHR6oFKAAAAgLqLEQsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaTX6JLiMjAylpKSUOz0tLU3R0dEyDENr1qxRenq6srOzderUKYWGhio+Pl633nqr/P39nebdsWOHFi5cqG+//VbHjx9XcHCwLr74Yj399NPy9vauydUCAAAAcBa3PGI6ISFBsbGxTu3h4eGSpDlz5igtLU09evTQmDFjZLVatXXrVtlsNm3cuFFpaWmyWCz2+ZYvX66pU6fq4osvVnJysvz9/ZWXl6dt27appKSEYAEAAAC4mVuCRVRUlBITE11OKy4u1jvvvKOoqCi9+uqratDg9NlZN998s6xWq1atWqU9e/aoU6dOkqS9e/cqNTVV119/vSZNmuQQOAAAAAB4hsevsSguLtaJEycUFBRkDxVlgoODJUmNGjWyt7399tsyDEMTJkyQxWLR8ePHVVxc7NaaAQAAADhyy4hFUVGR8vPzHdq8vb3l5+cnX19fdevWTV9//bUWLlyofv36ycvLS1u3btX777+v6667ThEREfb5Nm3apDZt2igzM1OzZs3STz/9JKvVqiuuuEITJ0506AsAAADAPSyGYRg1tfCKLt6Oj49XamqqJCknJ0eTJ0/W5s2b/1eYxaKRI0cqJSXFfrpTYWGhrrnmGjVp0kSFhYW65ZZbdNlll+mHH37QwoUL5e/vryVLlthHOirDMtN5tMOY6Ja8BQAAAPxpuOUv6KSkJMXFxTm0BQUF2b/28fFR69atNXDgQPXs2VOStH79es2fP18+Pj4aNWqUJOnYsWOSpIKCAo0cOVLjxo2TJPXt21ctW7bU008/rSVLlmjChAnuWC0AAAAA/59bgkVERIRiYmJcTisqKtLIkSPVqVMn+wiGdPpOUo8//rhsNpv69eunNm3aqGHDhvbp119/vcNyrrvuOk2dOlVbt26tmZUAAAAAUC6PX7y9bt06HThwwGlEQ5Li4uJUWlqq7du3S5KaNGkiX19fSY4jHpJktVrVtGlTHT16tMZrBgAAAODI48EiNzdXklRaWuo0raSkxOF/i8Wiiy66SNLp6zLOdPLkSR0+fFjNmjWryXIBAAAAuODxYNG2bVtJ0sqVK52mlbV16dLF3lb2PIz333/foe+HH36o0tJSlw/iAwAAAFCzPH77o169eqlLly7auHGjxowZo759+0qSNmzYoG3btikuLk5RUVH2/tdff70++eQTvfvuu8rPz9ell16qH3/8UR9++KHatWunv/zlL55aFQAAAKDe8niw8PLy0pw5c7Rw4UKtX79es2fPlsViUXh4uO677z4NHz7cqf/f//53zZs3T5999pnWrVunZs2aaciQIRo7dqwaN27soTUBAAAA6q8afY5FXcBzLAAAAADzPH6NBQAAAIC6j2ABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADAtHp/X1Vb4AIlJyfL29vb06UAAAAAdRYjFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMshmEYni7Ckywzi53ajIlWD1QCAAAA1F2MWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANPO+4ENGRkZSklJKXd6WlqaoqOjtXbtWm3atElZWVnau3evSkpKtHz5crVq1crlfLm5uZo9e7Y2bdqk48ePq127dhoxYoTi4uIc+v33v//V4MGDXS6jXbt2Sk9PP99VAgAAAGBSlZ8El5CQoNjYWKf28PBwSdLSpUu1a9cudejQQWFhYcrOzi53WQUFBRo9erR+//13DR8+XC1atNDq1av12GOP6cknn3QZJPr27au+ffs6tAUEBFR1dQAAAACYUOVgERUVpcTExHKnT5kyRcHBwbJarXr++ecrDBYLFy7Uzz//rBdffFG9e/eWJN1www1KTk7WrFmzFBcXp8aNGzvM0759+wpfHwAAAID71Ng1FqGhobJaK5db1qxZo7CwMHuokCQvLy8NGzZMBQUF2rhxo8v5Tpw4oaKiomqpFwAAAEDVVTlYFBUVKT8/3+HfsWPHzns5eXl5ysnJUXR0tNO0srbvv//eadrixYt19dVX6+qrr9bAgQP1+uuv6+TJk+e/IgAAAABMq/KpUDabTTabzaEtPj5eqamp57Wc3NxcSVJISIjTtBYtWkiScnJy7G0NGjRQjx491KdPH7Vs2VKHDx/WunXrNG/ePO3YsUOzZ8+Wl5fX+a4OAAAAABOqHCySkpKc7tgUFBR03sspO5XJx8fHaVpZ25mnO4WGhuq1115z6HfjjTfq2Wef1UcffaTPPvtM11133XnXAQAAAKDqqhwsIiIiFBMTY7oAX19fSXJ5GlNZW1mfiowcOVIfffSRvvrqK4IFAAAA4GYef0Be2SlQZadEnansFKiyU6IqcsEFF8jLy0v5+fnVWh8AAACAc/N4sAgODlaLFi20c+dOp2llbZ07dz7ncn7++WeVlJSoefPm1V4jAAAAgIp5PFhIpx+299NPP+nLL7+0t5WUlOi9995TQECAw4P4XI1IlJaWas6cOZLkcMtaAAAAAO5R5WssziUzM1OZmZmSpN27d0uS0tPT5e/vL0kaPXq0ve+IESO0bt06TZo0ScOHD1dISIjWrFmj77//XpMmTZKfn5+977PPPqtjx46pa9euuuCCC5Sfn6/169dr9+7d6tOnj/r161dTqwQAAACgHDUWLLZs2aK5c+c6tC1atMj+9ZnBomnTppo/f75mz56t9PR0HT9+XG3bttW0adPUv39/h2XExsbq008/1UcffaSCggL5+PioXbt2evTRR3XTTTepQYNaMQgDAAAA1CsWwzAMTxfhSZaZxU5txsQay1sAAADAnxIf7wMAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANPq/QMbbIELlJycLG9vb0+XAgAAANRZjFgAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMM3q6QI8yTAMHT9+XEeOHJG3t7enywEAAABqpYCAAFkslgr7WAzDMNxUT62Tl5enkJAQT5cBAAAA1GoFBQUKDAyssE+9HrFo2LChLr30Un3yySfy9/f3dDl/eoWFhRo4cCDb203Y3u7DtnYvtrd7sb3dh23tXmzv8xMQEHDOPvU6WFgsFnl5eSkwMJAdyg0aNGjA9nYjtrf7sK3di+3tXmxv92Fbuxfbu/px8TYAAAAA0wgWAAAAAEyr18HCx8dHY8aMkY+Pj6dLqRfY3u7F9nYftrV7sb3di+3tPmxr92J7V796fVcoAAAAANWjXo9YAAAAAKgeBAsAAAAApv0pbje7f/9+TZ8+XTt27JCfn58SExM1bty4cz5N2zAMvfnmm1q6dKny8/PVsWNHPfTQQ4qOjnbol5ubq+nTp+tf//qXrFar+vbtqwcffLDe3pqsKts7Ly9Pixcv1r/+9S/99NNP8vf3V7du3XTvvfeqZcuW9n4ZGRlKSUlxmj8+Pl6pqak1sj61XVX37+uvv16HDh1yat+4caMaNmxo/57921FVtnd5+60kRUZG6oMPPqiwX33dvw8ePKi3335b3333nX788UdFRkYqPT39nPNx7K6aqmxvjt1VU9V9m+N21VRle3Pcrhl1PlgcOXJEKSkpioiI0IwZM5STk6OXXnpJRUVFevTRRyuc980335TNZtO9996rDh06aOnSpbr33nu1ePFihYWFSZKKi4t17733SpKmTp2qoqIizZo1S5MmTdLLL79c06tX61R1e+/evVsbNmzQ4MGDFR0drfz8fM2bN08jRozQe++9p2bNmjn0f+qpp9SmTRv7902bNq2hNardzOzfktSvXz/dfvvtDm1nXqTG/u2oqts7KipKaWlpDm3Hjh3ThAkT1LNnT6f+7N+n/fjjj9q4caO6dOmi0tJSlZaWVmo+jt1VU5XtzbG7aqq6b0sct6uiKtub43YNMeq4BQsWGFdffbWRn59vb/vggw+MK664wsjJySl3vqKiIqN3797GK6+8Ym87efKkMWjQICM1NdXetmrVKqN79+7Gvn377G1ff/21cfnllxs7d+6s3pWpA6q6vY8cOWKcOnXKoe2XX34xunfvbrz99tv2ti1bthiXX365sWvXruovvg6q6vY2DMMYNGiQ8dxzz1XYh/3bkZntfbbly5cbl19+ufHdd9/Z29i/HZWUlNi/fuqpp4yhQ4eecx6O3VVXle3NsbtqqrKtDYPjdlVVdXufjeO2eXX+GotNmzbpiiuuUJMmText8fHxKi0t1TfffFPufDt27NCxY8cUFxdnb/P29lbfvn21ceNGh+V36NDBIaXGxMSoSZMmDv3qi6pu74CAAFmtjgNkF1xwgZo1a6bc3Nwaq7euq+r2Pp/ls3//T3Vu79WrVysiIkJdunSp7jL/NBo0OP9fQRy7q64q25tjd9VUZVtXFvu2s+ra3hy3zavzwWL//v0OP1zS6QNhcHCw9u/fX+F8kpzmbdu2rX755RcVFRXZ+0VGRjr0sVgsioyMrHD5f1ZV3d6uZGdn6/fff1fbtm2dpt1///264oorlJiYqFmzZtnfj/rG7PZevXq1rrrqKvXq1UsTJkzQf/7zH6fls3//T3Xt37/99psyMjKUkJDgcjr7d9Vx7PY8jt01i+O2Z3Dcrh5/imssAgICnNoDAgJ05MiRCufz8fFxuBiqbD7DMHT06FH5+vrq6NGjLpcfGBhY4fL/rKq6vc9mGIZmzpypkJAQhx9if39/3XnnnbrsssvUsGFDbdmyRYsWLdK+ffvq5bmjZrZ37969dfHFFys0NFQ///yzFixYoFGjRjmch87+7ai69u+1a9eqpKREAwYMcGhn/zaPY7dnceyuWRy3PYfjdvWo88ECddMbb7yhzZs3a/bs2WrUqJG9PSoqSlFRUfbve/TooeDgYE2fPl3fffedLr74Yk+UWyc98sgj9q+7deumK6+8UjfddJMWLVqkxx57zIOV/fmtWrVKnTt3dvpUkf0bdR3H7prFcdtzOG5Xjzp/KlRgYKAKCwud2o8eParAwMAK5zt58qROnDjhNJ/FYrF/GhAQEOBy+UeOHKlw+X9WVd3eZ/roo480d+5cPfHEE7riiivO2T8+Pl6SlJWVdX7F/glUx/YuExwcrEsvvVS7d++2t7F/O6qO7f3TTz9p165dTp96lac+799VwbHbczh2ux/HbffguF196nywaNOmjdM5hYWFhcrLy3M6B/fs+aTT54qeaf/+/QoNDZWvr2+5yzcMQ9nZ2RUu/8+qqtu7zIYNG/Tcc88pJSVFN9xwQ80U+SdidntXZfns3/sd2s53e69evVoNGjQo9zxdmMOx2zM4dtce7NvVj+N29anzwaJnz57avHmzjh49am9bt26dGjRooCuvvLLc+bp27So/Pz+tW7fO3lZcXKwNGzYoNjbWYfk//PCDDhw4YG/bvHmzCgoKHPrVF1Xd3tLph8z87W9/04033qjRo0dX+jXXrFkjSbrooouqVnQdZmZ7ny03N1fbt2932I7s346qY3uvWbNGl19+uYKDgyvdX6qf+3dVcOx2P47dnsNx2z04blefOn+NxU033aT33ntPDz/8sEaOHKmcnBzNmjVLQ4YMUUhIiL3f2LFjdejQIX388ceSpIYNGyo5OVlvvPGGmjVrpvbt22vp0qUqKChweDBNXFyc0tLS9Ne//lXjx49XUVGRXn75ZV199dX18ry6qm7vffv2aeLEiQoPD1diYqJ27txp79usWTP7RWn/93//p7CwMEVFRdkvklqyZImuueaaevkDXNXtvXr1an311VeKjY1VSEiIfvrpJy1cuFBeXl7s3xWo6vYuk5WVpX379mn48OEul8/+7aioqEhfffWVJOnQoUM6duyYPTBcfvnlatasGcfualSV7c2xu2qqsq05blddVbZ3GY7b1avOB4vAwEC99tprmjFjhh5++GH5+fnpxhtv1Lhx4xz6lZSUqKSkxKFtxIgRMgxDixYt0uHDh9WxY0fNnj3bfqCUJKvVqtmzZ2vGjBn629/+Ji8vL/Xt21cPPfSQW9avtqnq9v7uu+9UWFiowsJCjRo1yqHvoEGDNHnyZElSu3bttGrVKi1evFgnT55Uq1atlJycrOTk5Bpft9qoqtu7devWys3N1QsvvGC/g0iPHj10zz33qHXr1vZ+7N+OzBxPpNOfYvn4+Khfv34ul8/+7ej33393uiC17PvXX39d3bt359hdjaqyvTl2V01VtjXH7aqr6rFE4rhd3SyGYRieLgIAAABA3Vbnr7EAAAAA4HkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAnVaTk6OmjRporlz5zq033XXXWrTpo1nivqTmDx5siwWi/bv3++W11u4cKHT6x0/flytWrXS008/fd7LK2/fQNWVvUeff/65p0uBh5k9PrAv1V/79++XxWKxP7XdXT7//HNZLBYtXLiwSvNv375dDRo00BdffFG9hf3JECxQp02aNEkhISFKTk6uVP9ffvlFEydO1MUXX6yAgAAFBgaqQ4cO+stf/qIPP/zQoe8111wjf3//cpdV9os1IyPD5fTDhw+rUaNGslgsevvtt8tdTps2bWSxWOz/fHx81KZNG40ePVoHDx6s1Hr9WTVq1EiPPfaYZsyYoUOHDp3XvOe7b6B+2759uyZPnuy2IA3P279/vyZPnqzt27e79XXZ15zl5+dr8uTJtTpoXnrppbrxxhv18MMPyzAMT5dTaxEsUGf99NNPWrBgge677z5ZrdZz9s/OztYll1yiV199VVdeeaWee+45paamatCgQcrKylJaWlq11rd48WKdOHFCbdu21YIFCyrsGxYWprfffltvv/22Zs2apZiYGC1YsEAxMTHKy8ur1rrqmlGjRslisejFF1+s9Dznu2+gcu644w4dP35cvXv39nQp1W779u16+umn+WOvHtm/f7+efvppjwSL+ryvRUZG6vjx45o0aZK9LT8/X08//XStDhaS9MADD2jr1q369NNPPV1KrcVvXNRZNptNFotFt956a6X6z5w5Uzk5Ofr44491ww03OE3/5ZdfqrW++fPnq2/fvrrhhhv0wAMPaO/evWrXrp3Lvk2aNNHtt99u/37s2LFq0aKFXnnlFaWlpemRRx6p1trqEj8/Pw0ZMkQLFy7U1KlT1bBhw3POc777hqeVlJToxIkTaty4sadLqZCXl5e8vLw8XQaAOsxiscjX19fTZVRJr1691KZNG73++usaOHCgp8uplRixqEfKzmn9xz/+oSlTpigyMlKNGjVSTEyMvvnmG0nSF198oauvvlp+fn5q2bKlnnnmGZfLysjIUFJSkoKDg9WwYUN16tRJzz77rIqLix36bd68WXfddZc6duyoxo0bKyAgQLGxsfroo4+clnnXXXfJYrGooKDA/oe1r6+vYmNj9a9//cup/9KlS9W9e3e1aNGiUuv/ww8/SJL69evncnpoaGilllMZmZmZ2r59u0aMGKHbbrtNVqv1nKMWZ0tISJAk/ec//ym3z6pVq2SxWPT3v//d5fSrrrpKISEhOnXqlKTzez9cKXuPXLFYLLrrrruc2t977z1dffXVCggIUOPGjRUTE6P333+/Uq9X5rrrrlNeXp42bNhQqf7l7RulpaV69tln1bt3b4WGhsrHx0cREREaO3asfvvtN3u//Px8+fr6asiQIS6X//jjj8tisTh80llQUKBHH31U7du3V8OGDRUSEqJbb71Ve/fudZi37Odw3bp1euaZZ3ThhRfK19dX6enpkqTPPvtMw4YNU7t27dSoUSM1bdpU/fv3L/e83g8++ECXXHKJfH19FRERoaefflrr1q1zeS7xiRMnNG3aNHXp0kW+vr5q2rSprr/+em3btq1S29XVefHVdVxp06aNrrnmGmVmZuraa6+Vv7+/mjdvrhEjRignJ8eh79GjRzVp0iTFxMTYj0Ht27fXY489pj/++MNp2YZhaO7cuYqJiZG/v7/8/f0VHR2tJ598UtLp0xrLTpnr27ev/bREV/vz2Xbs2KGkpCQFBQXJ19dXF110kaZPn66SkhKHfud7fHOl7PTL77//Xg888IBatmypxo0bq1+/fvr3v/8tSfrwww912WWXqVGjRmrTpo3eeOMNl8uaN2+evV+TJk3Uv39/ffXVV079SktLlZqaqrZt28rX11cXX3yxFi9eXG6Nhw4d0tixYxURESEfHx+1atVKd999t9N7eL4qu52vueYal9fXnX1e/8KFC9W3b19JUnJysv09v+aaayQ5no8/e/ZsdezYUb6+vurYsaNmz57ttPyy/fdsZ5/XX9V9rWz/+e2333TXXXcpODhYAQEBuvHGG+0fir3xxhvq3LmzfH19FRUVpWXLljktZ86cOerfv79at24tHx8ftWzZUrfffrvL0ZOSkhI988wzioyMlK+vr7p27ar33nvP5fU157N/n/1efP7552rbtq0k6emnn7Zvk7L3saJrI8r7nbRs2TJ169ZNvr6+Cg8P1//93//Zfw+e7XyOixaLRQkJCVq9erUKCwtdLq++Y8SiHnrsscdUUlKi+++/XydPntQLL7yg/v3766233tKoUaN09913a/jw4UpPT9eTTz6ptm3bOnya/sknn2jIkCFq3769Hn74YTVv3lxff/21nnzySW3fvl1Lly619/3oo4+UlZWlW265RZGRkfrtt9/05ptvasiQIVq8eLFuu+02p/oSEhIUEhKiJ598Ur/99ptefPFFDRw4UPv27VNAQIAk6ddff9W///1vTZgwodLrfeGFF0qS5s6dqwceeKDcP5DPVt6pSK7+gCkzf/58+fv766abbpKfn58GDRqkN998U1OmTFGDBpXL82VBKDg4uNw+/fv3V2hoqN566y2nbfHDDz/om2++0YQJE+Tt7S2pau+HGZMmTdKzzz6rAQMG6JlnnlGDBg300UcfaejQoXrllVc0fvz4Si3nqquuknT6F8yAAQMq7FvRvnHy5EnNmDFDN910k2644Qb5+flpy5Ytmj9/vr766itt3bpVPj4+atq0qQYPHqxly5bp999/V/Pmze3LKC0t1eLFi9W1a1ddeumlkk6Hip49e+rAgQMaOXKkunTpokOHDmnOnDmKiYlRRkaGIiMjHWqZOHGiTp06pTFjxigwMFCdOnWSdPoPnt9//1133nmnwsLC9PPPP2vevHnq16+fNmzYoF69etmX8d577+nWW2/VhRdeqKeeekpWq1VvvvmmVqxY4bTup06d0oABA7Rp0ybdcccduvfee1VQUKC5c+cqNjZWX375pbp3716p98MVs8cV6fQpbP369dNNN92km2++WZmZmVqwYIEyMjK0ZcsW+4hO2Ta56aab7MH9iy++0PTp07Vt2zatWbPGYbl33HGHFi9erJiYGP3tb39T06ZNlZWVpffff19TpkzRkCFDdOjQIb3xxht64okn1LlzZ0n/O2aUJyMjQ3369JG3t7fGjx+v0NBQrVixQo8++qi+/fZbl3+AV+b4di4jRoyQv7+/nnjiCeXm5uqFF15QQkKCnnnmGf31r3/V2LFjNXLkSM2fP1/33HOPLrroIl199dX2+R999FFNnz5dV1xxhaZNm6ajR4/qjTfeUN++fbVs2TIlJiba+z700EOaNWuWevfurQcffFA5OTkaP368y9HXAwcO6KqrrtLJkyc1atQoXXjhhfrPf/6j1157TRs2bFBGRoaaNGlSqXU0u53PpXfv3nriiSc0bdo03X333fafqwsuuMCh3+zZs/XLL7/onnvuUUBAgN555x1NmDBBv//+u5566qnzft2q7mtlBgwYoLCwME2ZMkX/+c9/9Pe//11JSUkaMmSI3njjDY0aNUq+vr76+9//rptvvll79uyx/9EunR65v/LKKzVhwgQ1b95c3333nebNm6f169dr586dCgoKsve999579frrr6tv376aOHGicnNzNW7cOIflna0q+3fnzp310ksv6cEHH7Svi6QKr3GsyEcffaSbbrpJbdq00ZNPPimr1aq0tDR98sknTn2rcly86qqrZLPZ9NVXX53z91G9ZKDeSEtLMyQZ3bp1M06cOGFvX7ZsmSHJsFqtxpYtW+ztJ06cMEJDQ40rr7zS3nb8+HHjggsuMHr16mWcOnXKYfkvvviiIcnYsGGDva2wsNCpjmPHjhkdO3Y0Onfu7NA+YsQIQ5IxduxYh/b09HRDkvH666/b29avX29IMmbNmuVyXUeMGGFERkY6tP34449GYGCgIckIDw83brvtNuOll14yMjIyXC6jT58+hqRz/jtzm5Vto6ZNmxojRoywt3388ceGJOPTTz91ep3IyEgjKirKyM3NNXJzc429e/caCxYsMJo0aWJYrVZj586dLusrM3HiREOSsWvXLof2SZMmGZKMrVu32tvO5/146qmnDEnGvn377G1l75ErkhzWeevWrYYk4/HHH3fqe8MNNxgBAQHGkSNH7G1l++eZr3cmq9VqDBo0yOW0M1W0b5SWlhp//PGHU/u8efMMScZ7771nb1u5cqUhyXj11Vcd+q5bt86QZLzwwgv2tgkTJhi+vr7G9u3bHfru37/fCAgIcNguZevZsWNH49ixY061uHqPfvnlFyMoKMi47rrr7G2nTp0yWrVqZbRo0cL4/fff7e1Hjx412rZta0gy0tLS7O1lP5+rV692WHZBQYERHh5u9OnTx+l1z1ZW+5k/49VxXDGM0z8HkoyXXnrJob2s7tTUVIdlnDx50qm+sn3+X//6l73tvffeMyQZt99+u1FSUuLQ/8zvXa3bufTs2dPw8vIyvv32W3tbaWmpMXToUEOSsW7dOnv7+RzfylP2Mzlo0CCjtLTU3j5r1ixDkhEQEGAcOHDA3p6Tk2M0bNjQ+Mtf/mJvy8rKMiwWixEbG+vwfv38889GkyZNjMjISKO4uNih77XXXmtvM4zTP9sWi8Xp53Xw4MFGSEiIcfDgQYe6t2zZYnh5eRlPPfWUve18tvf5bOc+ffo4HfsNwzD27dtnSHKoYcOGDU4/J2dP8/f3d1ifEydOGD169DCsVqtDe2RkpMufIVevUZV9rWz/GTdunEP7gw8+aP+dVlBQYG//9ttvDUnGY4895tDf1fGl7Jj2/PPP29u+++47Q5KRkJDg8HOyY8cOo0GDBuX+bqjM/u3qvXDVVqai9+ns30nFxcVGeHi4ERQUZOTm5trb8/PzjYiIiGo5Lv7zn/80JBkzZ850mgbD4FSoemjs2LHy8fGxf1/2SU1MTIxDMvfx8dEVV1xh/+RcktauXatff/1VycnJys/PV15env1f2adcn332mb2/n5+f/es//vhDv/32m/744w9de+212r17t44cOeJU34MPPujw/bXXXitJDnXk5uZKksMnyefSrl07ffvtt/ZPyZcsWaIHH3xQ3bt3V9euXbV161aneXx9fbV27VqX/+644w6Xr/Phhx8qPz9fI0aMsLclJiYqJCSk3NOhsrKyFBISopCQELVr104jR45UcHCwli1bposvvrjC9Sp7nbfeesveZhiGFi1apIsvvliXXXaZvb0q70dVLV68WBaLRSNGjHDYT/Ly8jR48GAdPXpUX3/9daWX17x580qdTlHRvmGxWNSoUSNJp4f5y/bhsn3szCH7hIQEXXDBBQ7bVTq9na1Wq4YPHy7p9LZevHixevfurdatWzusp5+fn6688kqHn4kyY8eOdXlNxZnvUWFhoX777Td5eXkpJibGob6tW7fqv//9r+666y41a9bM3u7v76+UlBSn5S5atEhRUVG6/PLLHWo8efKk4uPj9dVXX+n48eMutmjlmDmulAkMDNS4ceMc2saNG6fAwECH0/V8fHzso3DFxcU6fPiw8vLyFBcXJ8nxfSz7NHvmzJlOo4WVHT10JScnR5s2bdLgwYPVtWtXe7vFYtHf/vY3SXJ5imFljm/nMmHCBIcR17JtPXjwYIWHh9vbQ0JC1KlTJ4dlL1u2TIZh6K9//avD+9WqVSslJycrOzvbfgpIWd+HHnrI4dqayy67TPHx8Q41FRQUaOXKlRo8eLB8fX0d9rE2bdqoffv2Ln8OzqWq27m6DB8+XGFhYfbvfXx89OCDD6q4uNjlyGBNe+CBBxy+L3vv77zzTgUGBtrbu3btqsDAQKf9quz4UlpaqoKCAuXl5emSSy5RkyZNHH5uVq5cKUm6//77HX5OoqOj7afpulId+7cZW7du1cGDB5WcnOww2t+kSZNqOy6WjeqYPb3vz4pToeqhs4ewy/4ocTW82axZM4dzz3fv3i1JGjlyZLnL//XXX+1f5+TkaNKkSVq2bJnLH8L8/HyHg6Gr+sp+iM+so+yXqnGet3xr06aNXnnlFb3yyis6dOiQvvrqK7399ttasWKFBg0apF27djn8Qerl5WX/Y+Vsrs5Hlk6fBhUSEqKwsDCH6yP69++vpUuXKi8vz+n0pjZt2tift1B2XnL79u0rtU5l4WHx4sWaNm2aGjRooC+//FL79+/X9OnTHfpW5f2oqt27d8swDEVFRZXb58x95VwMw6jU6Wvn2jfS09P1wgsvaNu2bU7n3B4+fNj+dVl4ePHFF7Vnzx517NhRx44d04cffqj+/fvbT5nIzc3Vb7/9ps8++0whISEuX9PVH7AdO3Z02ffHH3/U3/72N61Zs0b5+fku102S9u3bJ0n2U6jO5Kpt9+7dOn78eLk1SqdP+zvzD9PzYea4cuYyzvxjV5IaNmyodu3aOV2rMmfOHL3++uvatWuXSktLHaad+T7+8MMPatmypdMpLmaVbf8uXbo4TevcubMaNGjgVLNUuePbuZzvts7Ozq5U3WVte/fuVffu3e31u/oZvuiiixyCwr///W+VlpZq/vz5mj9/fqXqroyqbufqUnaq0pkuuugiSarR1y2P2Z+z9evXa8qUKfrXv/6loqIih2ln/tyc6/iyatWqStVXlf3bjHPts2erynGx7HdLZU+nrm8IFvVQeXd1qczdXsp+oGbMmGE/v/xsrVq1svft37+/du/erfvvv1/du3dXkyZN5OXlpbS0NC1ZssTpD4KK6jjzD8Wyg8Dvv/9+zprL07JlSw0dOlRDhw7V8OHDtWTJEn366adO532fj3379mnDhg0yDKPcPxwXLVrk9KmTn59fuQGmMu6880498MADWr9+veLi4vTWW2/Jy8vLYV2q+n6cqbwD6dkX7Ze9nsVi0apVq8p9T139sVCew4cPV3jwL1PRvvHhhx9q2LBhuuKKKzRr1iyFh4fL19dXJSUlGjBggNP633nnnXrxxRf11ltvaerUqfrwww9VWFjoMBpVtl/GxcXp0UcfrfT6uBqtKCwsVO/evXXs2DE98MADio6OVkBAgBo0aKDU1FStX7++0ss/m2EYio6OrvC2vZXZvuUxc1w5Xy+++KIefvhh9e/fXxMmTFCrVq3k4+Ojn3/+WXfdddc592NPqszxrarLqI5lV1XZa9x+++0OPx9nKhstrEnnc4yqi69r5r3fsmWL+vfvr/bt2+u5555T27Zt7c9a+stf/lItPzc1sQ9W9Ae82e1bleNi2e8WM8fLPzOCBc5Lhw4dJFXuD+EdO3bo22+/1ZNPPun05OR58+aZqqPsD9LqGl698sortWTJEv3888+mlpOWlma/A03Tpk2dpk+aNEkLFixwChZm3XbbbXrkkUf01ltvKTY2Vu+//77i4+PVsmVLe5/qeD/KRnPOvqDZ1Sd3HTp00OrVqxUREeHyU7/zsX//fhUXF5/ztDCp4n3j7bfflq+vrzZs2ODwh31WVpbLZV1yySW65JJLtGjRIj3zzDN666237Bd2lwkJCVHTpk115MgRU+FQkv7xj3/ov//9rxYsWOD0YL8z7/kuyX7HlLK7AZ3JVVuHDh2Um5ura6+91tQpQDVp7969OnnypMOoxYkTJ7R3716HTyDffvtttWnTRqtWrXJYl9WrVzsts2PHjlq2bJl+/fXXCkctzvfTx7JPiHft2uU0LSsrS6WlpVX6hL6mldW0a9cupwuGv//+e4c+Zf9nZWWV27dM+/btZbFYdPLkSdM/B2c63+3cvHlzl6e1ujpGVeY9LxulP9PZ26nsdV19mFHV160JS5YsUUlJiVatWuUwwnHs2DGH0QrJ8fhy9n7s6vhiVkXb5MzfO2c7e/ueuc+e7ex9VqracbHsTITK/D6qj2rnbxfUWgkJCWrRooWee+45lz/kx48f19GjRyX975OLsz+p+O6770yfExsSEqIuXbrYb2dZGZ9//rnLc8hLS0vt58q6GiqtrNLSUi1cuFDR0dEaPXq0br75Zqd/t956q3bu3KktW7ZU+XVcCQkJ0XXXXacPP/xQixcv1pEjR5w+NayO96NsFGbdunUO7S+88IJT37JrUJ544gmnW0JK53caVNn73KdPn3P2rWjf8PLyksVicfhkzjAMTZ06tdzljRgxQtnZ2VqyZInWr1+vYcOGOdyDvUGDBho+fLg2b95c7m10K3subnnv0WeffeZ0y8bu3burZcuWWrhwocMfBYWFhXr99dedln3nnXfql19+KfeTufN5P2rKkSNHNGfOHIe2OXPm6MiRI7rxxhvtbWXv45nbqbi4WM8995zTMsuuhfnrX//q9InsmfOX3YGmsqOgLVq0UM+ePbVixQp99913DstMTU2VJCUlJVVqWe40ePBgWSwWzZgxw+FUwEOHDiktLU2RkZHq1q2bQ98XX3zR4Wc4MzPT6RgQFBSkxMREffjhhy5/9gzDsF//dD7Odzt37NhRR48e1ebNm+1tpaWleumll5yWXZn3fPHixfrpp5/s3588eVIvvfSSvLy8NGjQIIfXzcrKcvhw6sSJE3r11Ver9Lo1obzjy7Rp05x+Nq6//npJ0qxZsxym7dy50+mua9Whom3Stm1bWa1Wp31u06ZNTvva5ZdfrrCwMKWlpTnc0fHIkSPVdlz85ptvZLVaFRsbe+4Vq4cYscB58fPz01tvvaUbb7xRnTp10siRI9W+fXvl5+crKytLH374oT766CNdc8016ty5s7p06aLp06frjz/+UKdOnbRnzx7ZbDZFR0e7/FTpfAwdOlTPPPOMDh065PDJfHlmzpypjRs36vrrr9dll12mJk2a6JdfftEHH3ygrVu3qm/fvqYeePPZZ5/p4MGDGjVqVLl9brrpJk2ePFnz589Xjx49qvxarowYMULLly/Xww8/rCZNmjj8ISapWt6PW2+9VU888YTuvvtuZWVlqXnz5lq9erXLW/L26NFDkydP1uTJk3XppZdq6NChatWqlQ4dOmR/cunJkycrtW6ffvqpgoOD7fedP5fy9o2bb75ZH3zwga699lrdeeedOnXqlD7++OMKbx08fPhw/fWvf9W4ceNUWlrq8jSPZ599Vhs3btQtt9yiW265RVdeeaV8fHyUnZ2tTz/9VJdffrnLe7Cf7eqrr1ZoaKgefvhh7d+/X2FhYdq+fbvefvttRUdHa+fOnfa+VqtVM2fO1PDhw3XFFVdo1KhRslqtWrhwoYKCgrRv3z6HTwHvv/9+rV27Vo888ojWr1+va6+9VoGBgTpw4ID+8Y9/2EdyPOnCCy/U008/re+++06XX365tm7dqgULFigqKsrh9sE333yzHn/8cV133XUaMmSIjhw5oiVLltgv6D7T0KFDNWzYML311lv64YcfNHjwYDVr1kx79uzRmjVr7H+s9ujRQw0aNNCzzz6rw4cPy8/PT23btlVMTEy59c6aNUt9+vRRr1697LdBXblypdasWaPbbrut3GfmeFKnTp30yCOPaPr06erdu7eGDRtmv91sYWGhFi9ebP8DNCoqSuPHj9crr7yia6+9VjfddJNycnL0yiuv6JJLLnG6z/9rr72mq6++Wr1799add96pbt26qbS0VHv37tWyZct055132p9dcD7OZzvffffdeuGFF5SUlKT7779fPj4+ev/9912eMnPRRRcpICBAc+bMUePGjdW0aVO1aNHCfsGxdDowxMTEKCUlRQEBAVqyZIm2bNmi//u//3M47/7ee+/Vu+++q7i4OKWkpOjkyZN6++23XZ7yWJV9rTokJSXppZdeUmJiou6++275+Pho7dq12rFjh9N1f126dNHdd9+tN954Q3FxcUpKSlJubq5effVVdevWTVu3bq3WkZegoCC1b99e7777ri688EJdcMEF8vPz0/XXXy9/f3/dddddmjdvnm699VZdc801+uGHH5SWlqauXbvq22+/tS/Hy8tLL730km655RZdccUVGjNmjP05UkFBQTpw4IDD657vcdEwDK1evVoDBgyo8u1w//Rq+K5TqEUqusWdzrpVaJnybi+6c+dOY/jw4UarVq0Mb29vo0WLFsZVV11lTJkyxfjtt9/s/fbv32/cfPPNRnBwsNGoUSOjR48exocffmj6VqaGcfr2iFar1eUt31zdbvbrr782HnroIaN79+5GixYtDKvVajRp0sS48sorjRdeeMEoKipy6N+nTx/Dz8/PZT2G8b9bP5bdSvPmm282JBk7duwodx7DMIyOHTsaTZo0sd/2NDIy0ujSpUuF81TGiRMnjObNmxuSjNGjR7vscz7vh6s2wzCMb775xujZs6fRsGFDIygoyBgzZoxx+PDhcvehlStXGv379zeaNWtm+Pj4GGFhYcaAAQOM1157zaFfebebLSwsNPz8/IyJEydWeltUtG+88cYbRufOnY2GDRsaoaGhxpgxY4zffvut3PoNwzAGDRpkSDI6dOhQ7mseO3bMmDJlinHxxRcbvr6+hr+/vxEVFWWMHj3a+Oabb5zWs7xbTX777bdGQkKC0bRpU8Pf39/o06eP8eWXX5b785Genm5ER0cbPj4+Rnh4+P9r725CYW3DOIBfb515pnkiMlGKaWSImHxkIdmYbCTJBsmCbKxsGBvKJMkspoxIzWaGWFggZZIpmpQkiSzEhmThK8pHKY3+Z/F2dOaYmcM7rzNH/r/1Pc313F3z1DV1/2/YbDbMzc29is8F/o2odTqdKCkpgaqqUFUVJpMJTU1NWF5eDvtskWr/v94rP+I6t7e3UVFRAVVVkZiYiObmZpyfnwetDQQCGBwcRGZmJhRFgcFggNVqxf7+fsjIyufnZ4yOjqKoqAg6nQ5xcXEwm82w2WxB6zweD3Jzc6HRaCL2w892d3dRW1v70t85OTmw2+1B8azhnvl3+/SrcL/JSFGd4eJXXS4XCgsLodVqER8fj8rKSqytrb1a9/z8jIGBARgMBiiKgry8PExNTYWt5erqCl1dXcjKyoJWq0VCQgLy8/PR0dERFIn93sjVt+4zAHi9XhQUFEBRFKSmpqK7uxsHBwch98jr9aKoqAharRYi8hIv+nPEqdPphMlkgqIoMJlMGB4eDlmjx+NBdnY2NBoNjEYj7HY7VlZWQkalvrfXwvVPpCjWUBG48/PzKC4uhqqq0Ov1aGhowMnJSci1gUAANpsN6enpUBQFZrMZMzMz6OzshIjg4uLit/UBr/s7XL9ubm6irKwMqqpCRIL69v7+Hm1tbUhKSoJOp0N5eTnW19fDfu/s7OxLD6SlpaG3txc+ny/kXr3nvej3+yEiWFxcDPmsBPwD/IFTXUQfpL29XXw+nxweHgb9W9nS0iJ+vz/kbaL0d/J4PNLa2irHx8dBN+c6nU7p6el5Sfd5q3C98RU4HA7p6uqSjY0NKS0tjXU5b2I0GsVoNAbd6k0UK36/XyoqKsTtdr/pBvavpKamRlZXV+Xu7u5Dwhn+ZnV1dXJ6eipbW1tMhQqDZyzoU+vv75fr62txu92xLoU+wOPjowwNDYnVan3XUCHyNXrj6enp1fmVh4cHGRsbE71eH3SHCRHRe4Q6k7i3tydLS0tisVi+3FCxs7MjCwsL4nA4OFREwDMW9KmlpKTI7e1trMugD6LT6eTs7Ow/ffYr9MbR0ZFUVVVJY2OjZGRkyNnZmUxMTMjx8bGMj4+/uhOCiOitJiYmZHJyUqqrqyU5OVkODg7E5XKJoijS398f6/L+uB9nhigyDhZERJ9UcnKylJaWyvT0tFxeXsq3b9/EbDbL0NCQ1NfXx7o8IvrEiouLZX5+XkZGRuTm5kbi4+PFYrFIX1/fS3IY0a94xoKIiIiIiKLGMxZERERERBQ1DhZERERERBQ1DhZERERERBQ1DhZERERERBQ1DhZERERERBQ1DhZERERERBQ1DhZERERERBQ1DhZERERERBQ1DhZERERERBS1708UBqKKxE9tAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP analysis complete. Check plots for feature importance.\n",
      "\n",
      "Top Features (XGBoost Gain):\n",
      "               Feature  Importance\n",
      "80      AsR_500m_mean    0.427384\n",
      "84     AsR_2000m_mean    0.356742\n",
      "82     AsR_1000m_mean    0.172078\n",
      "12              ClayR    0.006133\n",
      "7                 CdR    0.003826\n",
      "174          PMF0_GWR    0.002677\n",
      "10              SandR    0.002590\n",
      "9                  MR    0.002185\n",
      "13                FeR    0.001468\n",
      "129    SiltR_500m_std    0.001447\n",
      "6                 CuR    0.001367\n",
      "89      CdR_1000m_std    0.001042\n",
      "88     CdR_1000m_mean    0.000975\n",
      "85      AsR_2000m_std    0.000903\n",
      "124  SandR_1000m_mean    0.000882\n",
      "127   SandR_2000m_std    0.000825\n",
      "5                 NiR    0.000762\n",
      "175          PMF1_GWR    0.000738\n",
      "98      CrR_500m_mean    0.000734\n",
      "91      CdR_2000m_std    0.000673\n",
      "95    ClayR_1000m_std    0.000662\n",
      "4                 CrR    0.000622\n",
      "8                 PbR    0.000622\n",
      "170       PMF_Factor0    0.000606\n",
      "109     CuR_2000m_std    0.000589\n",
      "86      CdR_500m_mean    0.000578\n",
      "11              SiltR    0.000555\n",
      "116    Pb_R_500m_mean    0.000536\n",
      "92    ClayR_500m_mean    0.000532\n",
      "111      NiR_500m_std    0.000506\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "import rasterstats\n",
    "from rasterstats import zonal_stats\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import shap\n",
    "from scipy.spatial import cKDTree\n",
    "import os\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# Load the main dataset and the river sampling data.\n",
    "original = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_200.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "# Identify columns for feature engineering and prediction\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = original.drop(columns=drop_cols).columns.drop('AsR')\n",
    "\n",
    "# Split original data into train and test sets for the ensemble model.\n",
    "# This ensures a fair evaluation on unseen data points.\n",
    "np.random.seed(42)\n",
    "train_idx = np.random.choice(len(original), 10, replace=False)\n",
    "test_idx = [i for i in range(len(original)) if i not in train_idx]\n",
    "train_orig = original.iloc[train_idx]\n",
    "test_orig = original.iloc[test_idx]\n",
    "\n",
    "# Combine the river samples and the original training data to form the full training set.\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Extract Multi-Scale Raster Features ==================== #\n",
    "# Define the raster files and buffer sizes for zonal statistics.\n",
    "raster_files = [\n",
    "    \"../CalIndices/ndwi.tif\", \"../CalIndices/ndvi.tif\", \"../CalIndices/ndbi.tif\",\n",
    "    \"../CalIndices/awei.tif\", \"../CalIndices/bui.tif\", \"../CalIndices/evi.tif\",\n",
    "    \"../CalIndices/mndwi.tif\", \"../CalIndices/ndbsi.tif\", \"../CalIndices/ndsi.tif\",\n",
    "    \"../CalIndices/savi.tif\", \"../CalIndices/ui.tif\",\n",
    "    \"../IDW/AsR.tif\", \"../IDW/CdR.tif\", \"../IDW/ClayR.tif\", \"../IDW/CrR.tif\", \"../IDW/CuR.tif\",\n",
    "    \"../IDW/NiR.tif\", \"../IDW/Pb_R.tif\", \"../IDW/SandR.tif\", \"../IDW/SiltR.tif\",\n",
    "    \"../LULCMerged/LULC2017.tif\", \"../LULCMerged/LULC2018.tif\", \"../LULCMerged/LULC2019.tif\",\n",
    "    \"../LULCMerged/LULC2020.tif\", \"../LULCMerged/LULC2021.tif\", \"../LULCMerged/LULC2022.tif\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "buffers = [500, 1000, 2000]\n",
    "\n",
    "def extract_raster_stats(points_df, rasters, buffers):\n",
    "    \"\"\"\n",
    "    Extracts zonal statistics (mean, std) from raster files for points\n",
    "    within specified buffer distances.\n",
    "    \"\"\"\n",
    "    # Create a GeoDataFrame from the points for spatial operations\n",
    "    gdf = gpd.GeoDataFrame(points_df, geometry=gpd.points_from_xy(points_df.Long, points_df.Lat), crs=\"EPSG:4326\")\n",
    "    features = pd.DataFrame(index=gdf.index)\n",
    "\n",
    "    for raster_path in rasters:\n",
    "        for buf in buffers:\n",
    "            col_mean = f\"{os.path.basename(raster_path).split('.')[0]}_{buf}m_mean\"\n",
    "            col_std = f\"{os.path.basename(raster_path).split('.')[0]}_{buf}m_std\"\n",
    "\n",
    "            # Create a buffer around each point (converted from meters to degrees)\n",
    "            # The value 111320 is a rough conversion factor from degrees to meters at the equator.\n",
    "            buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
    "            \n",
    "            # Use rasterstats to get zonal statistics for the buffered areas\n",
    "            zs_results = zonal_stats(buffered_geometries, raster_path, stats=['mean', 'std'], nodata=np.nan)\n",
    "\n",
    "            features[col_mean] = [res['mean'] for res in zs_results]\n",
    "            features[col_std] = [res['std'] for res in zs_results]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract raster features for both the training and testing data\n",
    "train_raster_feats = extract_raster_stats(train_combined, raster_files, buffers)\n",
    "test_raster_feats = extract_raster_stats(test_orig, raster_files, buffers)\n",
    "\n",
    "# ==================== 3. PMF (NMF) for Source Apportionment ==================== #\n",
    "# Use Non-Negative Matrix Factorization to identify latent source factors.\n",
    "pmf_features = ['CrR', 'NiR', 'CuR', 'AsR', 'CdR', 'PbR', 'MR', 'SandR', 'SiltR', 'ClayR', 'FeR']\n",
    "nmf = NMF(n_components=3, init='random', random_state=42, max_iter=1000)\n",
    "G_train = nmf.fit_transform(train_combined[pmf_features].values)\n",
    "F = nmf.components_\n",
    "print(\"\\nPMF Source Profiles (F):\\n\", pd.DataFrame(F, columns=pmf_features))\n",
    "\n",
    "# ==================== 4. Fixed Geographically Weighted Regression (GWR) ==================== #\n",
    "# Implement a custom GWR function to model spatial non-stationarity.\n",
    "def gaussian_kernel(d, bw):\n",
    "    return np.exp(-(d**2) / (2 * bw**2))\n",
    "\n",
    "def fixed_gwr(coords, factors, y, bw=0.5):\n",
    "    \"\"\"\n",
    "    Performs a fixed bandwidth GWR using a Gaussian kernel.\n",
    "    \"\"\"\n",
    "    n = len(coords)\n",
    "    preds = np.zeros(n)\n",
    "    X = np.hstack([np.ones((n, 1)), factors])\n",
    "    for i in range(n):\n",
    "        dist = np.linalg.norm(coords - coords[i], axis=1)\n",
    "        W = np.diag(gaussian_kernel(dist, bw))\n",
    "        # Use pseudo-inverse for stability\n",
    "        beta = np.linalg.pinv(X.T @ W @ X) @ (X.T @ W @ y.reshape(-1, 1))\n",
    "        preds[i] = (np.array([1] + list(factors[i])) @ beta).item()\n",
    "    return preds.reshape(-1, 1)\n",
    "\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "y_train = train_combined['AsR'].values\n",
    "GWR_train = fixed_gwr(coords_train, G_train, y_train, bw=0.5)\n",
    "\n",
    "# Interpolate PMF factors for the test set using Inverse Distance Weighting (IDW)\n",
    "def idw_interpolation(known_coords, known_values, query_coords, power=2):\n",
    "    \"\"\"\n",
    "    Performs IDW to interpolate values from known points to query points.\n",
    "    \"\"\"\n",
    "    tree = cKDTree(known_coords)\n",
    "    dists, idxs = tree.query(query_coords, k=4)\n",
    "    dists[dists == 0] = 1e-10  # Avoid division by zero\n",
    "    weights = 1 / (dists ** power)\n",
    "    weights /= weights.sum(axis=1)[:, None]\n",
    "    return np.sum(weights * known_values[idxs], axis=1)\n",
    "\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "y_test = test_orig['AsR'].values\n",
    "# Interpolate PMF factors for the test set\n",
    "G_test = np.column_stack([idw_interpolation(coords_train, G_train[:, i], coords_test) for i in range(G_train.shape[1])])\n",
    "# Apply GWR to the interpolated PMF factors for the test set\n",
    "GWR_test = fixed_gwr(coords_test, G_test, y_test, bw=0.5)\n",
    "\n",
    "# ==================== 5. Interaction Features ==================== #\n",
    "# Create new features by interacting PMF and GWR results.\n",
    "def create_interactions(pmf, gwr):\n",
    "    \"\"\"\n",
    "    Creates interaction features between PMF factors and GWR predictions.\n",
    "    \"\"\"\n",
    "    interactions = pd.DataFrame()\n",
    "    for i in range(pmf.shape[1]):\n",
    "        interactions[f\"PMF{i}_GWR\"] = pmf[:, i] * gwr.flatten()\n",
    "    return interactions\n",
    "\n",
    "train_interact = create_interactions(G_train, GWR_train)\n",
    "test_interact = create_interactions(G_test, GWR_test)\n",
    "\n",
    "# ==================== 6. Final Feature Matrix ==================== #\n",
    "# Combine all engineered features into a single matrix for the XGBoost model.\n",
    "X_train = np.hstack([\n",
    "    train_combined[numeric_cols].values,\n",
    "    train_raster_feats.values,\n",
    "    G_train,\n",
    "    GWR_train,\n",
    "    train_interact.values\n",
    "])\n",
    "\n",
    "X_test = np.hstack([\n",
    "    test_orig[numeric_cols].values,\n",
    "    test_raster_feats.values,\n",
    "    G_test,\n",
    "    GWR_test,\n",
    "    test_interact.values\n",
    "])\n",
    "\n",
    "# ==================== 7. Optuna Hyperparameter Optimization ==================== #\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Defines the Optuna objective function to minimize negative R².\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 600),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5)\n",
    "    }\n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return -r2_score(y_test, y_pred)\n",
    "\n",
    "# Run the Optuna study to find the best parameters\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "best_params = study.best_params\n",
    "print(\"\\nBest Parameters from Optuna:\", best_params)\n",
    "\n",
    "# ==================== 8. Train Final XGBoost ==================== #\n",
    "# Train the final model with the optimized hyperparameters.\n",
    "xgb = XGBRegressor(**best_params, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# ==================== 9. Evaluation ==================== #\n",
    "# Evaluate the final model's performance on both training and test data.\n",
    "y_pred_train = xgb.predict(X_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 10. SHAP Interpretation ==================== #\n",
    "# Use SHAP to explain the model's predictions and feature importance.\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Generate SHAP summary plots\n",
    "shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])])\n",
    "shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])], plot_type=\"bar\")\n",
    "\n",
    "print(\"SHAP analysis complete. Check plots for feature importance.\")\n",
    "\n",
    "feature_names = list(numeric_cols) \\\n",
    "                + list(train_raster_feats.columns) \\\n",
    "                + [f\"PMF_Factor{i}\" for i in range(G_train.shape[1])] \\\n",
    "                + [\"GWR_Adjusted\"] \\\n",
    "                + list(train_interact.columns)\n",
    "\n",
    "# Create DataFrame of importance\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": xgb.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Save & print\n",
    "importance_df.to_csv(\"SHAP-PMF-GLWR-Xgboost.csv\", index=False)\n",
    "print(\"\\nTop Features (XGBoost Gain):\\n\", importance_df.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a058f3-90a9-488f-b484-0dd1a12873fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:71: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_mean] = [res['mean'] for res in zs_results]\n",
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[col_std] = [res['std'] for res in zs_results]\n",
      "[I 2025-08-11 11:16:40,417] A new study created in memory with name: no-name-de2f7bf3-91b2-4293-8553-98082f43d65a\n",
      "[I 2025-08-11 11:16:40,553] Trial 0 finished with value: -0.9490638704298393 and parameters: {'n_estimators': 536, 'learning_rate': 0.218101846505773, 'max_depth': 5, 'subsample': 0.7431240299023683, 'colsample_bytree': 0.7279593924528027, 'reg_lambda': 2.1326327009615147, 'reg_alpha': 2.158749203828223}. Best is trial 0 with value: -0.9490638704298393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PMF Source Profiles (F):\n",
      "          CrR        NiR        CuR       AsR       CdR        PbR         MR  \\\n",
      "0   1.011389   0.736567   1.692243  0.281334  0.081748   1.820547   0.744549   \n",
      "1   6.361217   2.933900   7.088545  1.445830  0.265560   5.471049   3.793943   \n",
      "2  21.197896  13.541837  26.909527  5.148483  1.449400  21.854976  14.985015   \n",
      "\n",
      "       SandR      SiltR      ClayR           FeR  \n",
      "0   0.626930   0.857063   0.708036    811.577481  \n",
      "1   4.450762   3.851295   2.797844   3334.740535  \n",
      "2  16.237624  14.758396  12.759443  12485.992078  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 11:16:40,680] Trial 1 finished with value: -0.9365270300802844 and parameters: {'n_estimators': 273, 'learning_rate': 0.22363279452254514, 'max_depth': 8, 'subsample': 0.8949234039430543, 'colsample_bytree': 0.739651082290796, 'reg_lambda': 3.092986525867082, 'reg_alpha': 0.9386161595367182}. Best is trial 0 with value: -0.9490638704298393.\n",
      "[I 2025-08-11 11:16:40,784] Trial 2 finished with value: -0.9382752426704232 and parameters: {'n_estimators': 398, 'learning_rate': 0.16081776570399078, 'max_depth': 3, 'subsample': 0.6718815580639304, 'colsample_bytree': 0.807413439220453, 'reg_lambda': 1.7789433712019718, 'reg_alpha': 3.5009107616753523}. Best is trial 0 with value: -0.9490638704298393.\n",
      "[I 2025-08-11 11:16:40,960] Trial 3 finished with value: -0.9504011471957837 and parameters: {'n_estimators': 516, 'learning_rate': 0.2539388012656014, 'max_depth': 4, 'subsample': 0.9511947296269092, 'colsample_bytree': 0.8213873904512122, 'reg_lambda': 4.603950471288655, 'reg_alpha': 0.23605898185241947}. Best is trial 3 with value: -0.9504011471957837.\n",
      "[I 2025-08-11 11:16:41,268] Trial 4 finished with value: -0.9765466150678968 and parameters: {'n_estimators': 471, 'learning_rate': 0.18196207984191928, 'max_depth': 8, 'subsample': 0.8016668152455694, 'colsample_bytree': 0.725513889196507, 'reg_lambda': 4.394467437850624, 'reg_alpha': 0.08652001792071928}. Best is trial 4 with value: -0.9765466150678968.\n",
      "[I 2025-08-11 11:16:41,495] Trial 5 finished with value: -0.9042526166794324 and parameters: {'n_estimators': 474, 'learning_rate': 0.13592109795998353, 'max_depth': 6, 'subsample': 0.6731400940696409, 'colsample_bytree': 0.915964944184068, 'reg_lambda': 6.683059280334925, 'reg_alpha': 3.268479610759276}. Best is trial 4 with value: -0.9765466150678968.\n",
      "[I 2025-08-11 11:16:41,587] Trial 6 finished with value: -0.9297375374451645 and parameters: {'n_estimators': 261, 'learning_rate': 0.1907104069413831, 'max_depth': 4, 'subsample': 0.9537213654652367, 'colsample_bytree': 0.6651399647932286, 'reg_lambda': 6.784347040699389, 'reg_alpha': 3.5597661954190922}. Best is trial 4 with value: -0.9765466150678968.\n",
      "[I 2025-08-11 11:16:41,806] Trial 7 finished with value: -0.9402909117323512 and parameters: {'n_estimators': 222, 'learning_rate': 0.02793331085857058, 'max_depth': 6, 'subsample': 0.8135695686620117, 'colsample_bytree': 0.8330631714473431, 'reg_lambda': 2.237051256832186, 'reg_alpha': 1.6711346694962326}. Best is trial 4 with value: -0.9765466150678968.\n",
      "[I 2025-08-11 11:16:42,238] Trial 8 finished with value: -0.9160830564125835 and parameters: {'n_estimators': 346, 'learning_rate': 0.025576775534238344, 'max_depth': 7, 'subsample': 0.8114686061505334, 'colsample_bytree': 0.6065723502539374, 'reg_lambda': 2.4163400295072357, 'reg_alpha': 4.920867461201208}. Best is trial 4 with value: -0.9765466150678968.\n",
      "[I 2025-08-11 11:16:42,632] Trial 9 finished with value: -0.970241406978732 and parameters: {'n_estimators': 538, 'learning_rate': 0.05917889258425952, 'max_depth': 4, 'subsample': 0.7644294141541115, 'colsample_bytree': 0.9949782398670645, 'reg_lambda': 8.25413348818779, 'reg_alpha': 0.46994087324426836}. Best is trial 4 with value: -0.9765466150678968.\n",
      "[I 2025-08-11 11:16:42,837] Trial 10 finished with value: -0.9225422877671966 and parameters: {'n_estimators': 433, 'learning_rate': 0.2897755306043134, 'max_depth': 8, 'subsample': 0.6091810654606457, 'colsample_bytree': 0.7099375004124006, 'reg_lambda': 9.929553539388106, 'reg_alpha': 1.3699293786368079}. Best is trial 4 with value: -0.9765466150678968.\n",
      "[I 2025-08-11 11:16:43,133] Trial 11 finished with value: -0.984850581507232 and parameters: {'n_estimators': 588, 'learning_rate': 0.10942475418884964, 'max_depth': 3, 'subsample': 0.7515417750820057, 'colsample_bytree': 0.9542844771032806, 'reg_lambda': 8.831408616903309, 'reg_alpha': 0.013888635866940918}. Best is trial 11 with value: -0.984850581507232.\n",
      "[I 2025-08-11 11:16:43,484] Trial 12 finished with value: -0.9836205562724198 and parameters: {'n_estimators': 595, 'learning_rate': 0.10154960885878843, 'max_depth': 3, 'subsample': 0.8648559183863823, 'colsample_bytree': 0.9047064078095224, 'reg_lambda': 4.82980807327135, 'reg_alpha': 0.0019140881067352573}. Best is trial 11 with value: -0.984850581507232.\n",
      "[I 2025-08-11 11:16:43,761] Trial 13 finished with value: -0.9671850858268412 and parameters: {'n_estimators': 590, 'learning_rate': 0.10419098066699714, 'max_depth': 3, 'subsample': 0.8640268374830783, 'colsample_bytree': 0.9190782562312894, 'reg_lambda': 9.994229715870066, 'reg_alpha': 0.9902074930933236}. Best is trial 11 with value: -0.984850581507232.\n",
      "[I 2025-08-11 11:16:44,096] Trial 14 finished with value: -0.9876616742855528 and parameters: {'n_estimators': 599, 'learning_rate': 0.09177741887684704, 'max_depth': 3, 'subsample': 0.8817470856833246, 'colsample_bytree': 0.9139406599980704, 'reg_lambda': 5.856421063179383, 'reg_alpha': 0.015550472957847599}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:44,352] Trial 15 finished with value: -0.9278906245276731 and parameters: {'n_estimators': 596, 'learning_rate': 0.0785910540563089, 'max_depth': 5, 'subsample': 0.9994747234495429, 'colsample_bytree': 0.9853919496479819, 'reg_lambda': 8.096250611957641, 'reg_alpha': 2.579239486232371}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:44,613] Trial 16 finished with value: -0.9658207934431983 and parameters: {'n_estimators': 368, 'learning_rate': 0.12859478838856336, 'max_depth': 4, 'subsample': 0.7246554170123118, 'colsample_bytree': 0.8685796502051292, 'reg_lambda': 6.438676092083938, 'reg_alpha': 0.8454870572924005}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:44,880] Trial 17 finished with value: -0.9547793404174674 and parameters: {'n_estimators': 507, 'learning_rate': 0.06487828595419622, 'max_depth': 3, 'subsample': 0.9007833723702667, 'colsample_bytree': 0.9557623949669546, 'reg_lambda': 8.361654939522133, 'reg_alpha': 1.6737386114996164}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:45,224] Trial 18 finished with value: -0.9750999883387317 and parameters: {'n_estimators': 561, 'learning_rate': 0.11083118804252079, 'max_depth': 5, 'subsample': 0.7075242862328426, 'colsample_bytree': 0.880508695038661, 'reg_lambda': 5.858032240132565, 'reg_alpha': 0.6324414184160346}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:45,374] Trial 19 finished with value: -0.9504112198742415 and parameters: {'n_estimators': 473, 'learning_rate': 0.14781806273992, 'max_depth': 3, 'subsample': 0.846759390367634, 'colsample_bytree': 0.952836228747921, 'reg_lambda': 3.584604791968747, 'reg_alpha': 2.701387701273584}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:45,532] Trial 20 finished with value: -0.9144797219151513 and parameters: {'n_estimators': 330, 'learning_rate': 0.08234792535742907, 'max_depth': 4, 'subsample': 0.7612086460668119, 'colsample_bytree': 0.8537768291320367, 'reg_lambda': 1.0648970059822567, 'reg_alpha': 4.684115088745287}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:45,812] Trial 21 finished with value: -0.9815617067658956 and parameters: {'n_estimators': 568, 'learning_rate': 0.10285252500459945, 'max_depth': 3, 'subsample': 0.8524052968805574, 'colsample_bytree': 0.9068335217637941, 'reg_lambda': 4.960472577283181, 'reg_alpha': 0.1571710347819046}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:46,079] Trial 22 finished with value: -0.9542928988439918 and parameters: {'n_estimators': 565, 'learning_rate': 0.043480764794670154, 'max_depth': 3, 'subsample': 0.9101529048391633, 'colsample_bytree': 0.9472343646099162, 'reg_lambda': 7.562101006310572, 'reg_alpha': 1.2704883409292822}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:46,472] Trial 23 finished with value: -0.9799278172081869 and parameters: {'n_estimators': 599, 'learning_rate': 0.09315618097001511, 'max_depth': 4, 'subsample': 0.8325959434016885, 'colsample_bytree': 0.914557197782708, 'reg_lambda': 5.406504844315018, 'reg_alpha': 0.03058174152543627}. Best is trial 14 with value: -0.9876616742855528.\n",
      "[I 2025-08-11 11:16:46,641] Trial 24 finished with value: -0.9773261594267219 and parameters: {'n_estimators': 503, 'learning_rate': 0.12802919930906387, 'max_depth': 3, 'subsample': 0.7816189483451811, 'colsample_bytree': 0.7898431529483314, 'reg_lambda': 3.8358358580102285, 'reg_alpha': 0.5778308522010692}. Best is trial 14 with value: -0.9876616742855528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters from Optuna: {'n_estimators': 599, 'learning_rate': 0.09177741887684704, 'max_depth': 3, 'subsample': 0.8817470856833246, 'colsample_bytree': 0.9139406599980704, 'reg_lambda': 5.856421063179383, 'reg_alpha': 0.015550472957847599}\n",
      "\n",
      "Final Model Performance:\n",
      "R² Train: 1.0000 | RMSE Train: 0.0028\n",
      "R² Test: 0.9877 | RMSE Test: 0.5675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:218: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/5ry1y2d128x8fgnl550m4c_h0000gp/T/ipykernel_4060/1849737970.py:219: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])], plot_type=\"bar\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP analysis complete. Check plots for feature importance.\n",
      "\n",
      "Top Features (XGBoost Gain):\n",
      "              Feature  Importance\n",
      "80     AsR_500m_mean    0.646021\n",
      "82    AsR_1000m_mean    0.219832\n",
      "84    AsR_2000m_mean    0.073752\n",
      "6                CuR    0.013091\n",
      "7                CdR    0.009580\n",
      "12             ClayR    0.003399\n",
      "10             SandR    0.002833\n",
      "104    CuR_500m_mean    0.002606\n",
      "4                CrR    0.002138\n",
      "1    num_upstream_BF    0.002136\n",
      "89     CdR_1000m_std    0.001983\n",
      "100   CrR_1000m_mean    0.001684\n",
      "5                NiR    0.001561\n",
      "125  SandR_1000m_std    0.001287\n",
      "171      PMF_Factor1    0.001256\n",
      "122  SandR_500m_mean    0.001253\n",
      "106   CuR_1000m_mean    0.001249\n",
      "9                 MR    0.001111\n",
      "118  Pb_R_1000m_mean    0.001042\n",
      "120  Pb_R_2000m_mean    0.000968\n",
      "115    NiR_2000m_std    0.000962\n",
      "133  SiltR_2000m_std    0.000814\n",
      "8                PbR    0.000601\n",
      "129   SiltR_500m_std    0.000590\n",
      "107    CuR_1000m_std    0.000583\n",
      "92   ClayR_500m_mean    0.000508\n",
      "11             SiltR    0.000437\n",
      "123   SandR_500m_std    0.000432\n",
      "97   ClayR_2000m_std    0.000416\n",
      "108   CuR_2000m_mean    0.000385\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "import rasterstats\n",
    "from rasterstats import zonal_stats\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import shap\n",
    "from scipy.spatial import cKDTree\n",
    "import os\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# Load the main dataset and the river sampling data.\n",
    "original = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "# Identify columns for feature engineering and prediction\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = original.drop(columns=drop_cols).columns.drop('AsR')\n",
    "\n",
    "# Split original data into train and test sets for the ensemble model.\n",
    "# This ensures a fair evaluation on unseen data points.\n",
    "np.random.seed(42)\n",
    "train_idx = np.random.choice(len(original), 10, replace=False)\n",
    "test_idx = [i for i in range(len(original)) if i not in train_idx]\n",
    "train_orig = original.iloc[train_idx]\n",
    "test_orig = original.iloc[test_idx]\n",
    "\n",
    "# Combine the river samples and the original training data to form the full training set.\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Extract Multi-Scale Raster Features ==================== #\n",
    "# Define the raster files and buffer sizes for zonal statistics.\n",
    "raster_files = [\n",
    "    \"../CalIndices/ndwi.tif\", \"../CalIndices/ndvi.tif\", \"../CalIndices/ndbi.tif\",\n",
    "    \"../CalIndices/awei.tif\", \"../CalIndices/bui.tif\", \"../CalIndices/evi.tif\",\n",
    "    \"../CalIndices/mndwi.tif\", \"../CalIndices/ndbsi.tif\", \"../CalIndices/ndsi.tif\",\n",
    "    \"../CalIndices/savi.tif\", \"../CalIndices/ui.tif\",\n",
    "    \"../IDW/AsR.tif\", \"../IDW/CdR.tif\", \"../IDW/ClayR.tif\", \"../IDW/CrR.tif\", \"../IDW/CuR.tif\",\n",
    "    \"../IDW/NiR.tif\", \"../IDW/Pb_R.tif\", \"../IDW/SandR.tif\", \"../IDW/SiltR.tif\",\n",
    "    \"../LULCMerged/LULC2017.tif\", \"../LULCMerged/LULC2018.tif\", \"../LULCMerged/LULC2019.tif\",\n",
    "    \"../LULCMerged/LULC2020.tif\", \"../LULCMerged/LULC2021.tif\", \"../LULCMerged/LULC2022.tif\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "buffers = [500, 1000, 2000]\n",
    "\n",
    "def extract_raster_stats(points_df, rasters, buffers):\n",
    "    \"\"\"\n",
    "    Extracts zonal statistics (mean, std) from raster files for points\n",
    "    within specified buffer distances.\n",
    "    \"\"\"\n",
    "    # Create a GeoDataFrame from the points for spatial operations\n",
    "    gdf = gpd.GeoDataFrame(points_df, geometry=gpd.points_from_xy(points_df.Long, points_df.Lat), crs=\"EPSG:4326\")\n",
    "    features = pd.DataFrame(index=gdf.index)\n",
    "\n",
    "    for raster_path in rasters:\n",
    "        for buf in buffers:\n",
    "            col_mean = f\"{os.path.basename(raster_path).split('.')[0]}_{buf}m_mean\"\n",
    "            col_std = f\"{os.path.basename(raster_path).split('.')[0]}_{buf}m_std\"\n",
    "\n",
    "            # Create a buffer around each point (converted from meters to degrees)\n",
    "            # The value 111320 is a rough conversion factor from degrees to meters at the equator.\n",
    "            buffered_geometries = gdf.geometry.buffer(buf / 111320)\n",
    "            \n",
    "            # Use rasterstats to get zonal statistics for the buffered areas\n",
    "            zs_results = zonal_stats(buffered_geometries, raster_path, stats=['mean', 'std'], nodata=np.nan)\n",
    "\n",
    "            features[col_mean] = [res['mean'] for res in zs_results]\n",
    "            features[col_std] = [res['std'] for res in zs_results]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract raster features for both the training and testing data\n",
    "train_raster_feats = extract_raster_stats(train_combined, raster_files, buffers)\n",
    "test_raster_feats = extract_raster_stats(test_orig, raster_files, buffers)\n",
    "\n",
    "# ==================== 3. PMF (NMF) for Source Apportionment ==================== #\n",
    "# Use Non-Negative Matrix Factorization to identify latent source factors.\n",
    "pmf_features = ['CrR', 'NiR', 'CuR', 'AsR', 'CdR', 'PbR', 'MR', 'SandR', 'SiltR', 'ClayR', 'FeR']\n",
    "nmf = NMF(n_components=3, init='random', random_state=42, max_iter=1000)\n",
    "G_train = nmf.fit_transform(train_combined[pmf_features].values)\n",
    "F = nmf.components_\n",
    "print(\"\\nPMF Source Profiles (F):\\n\", pd.DataFrame(F, columns=pmf_features))\n",
    "\n",
    "# ==================== 4. Fixed Geographically Weighted Regression (GWR) ==================== #\n",
    "# Implement a custom GWR function to model spatial non-stationarity.\n",
    "def gaussian_kernel(d, bw):\n",
    "    return np.exp(-(d**2) / (2 * bw**2))\n",
    "\n",
    "def fixed_gwr(coords, factors, y, bw=0.5):\n",
    "    \"\"\"\n",
    "    Performs a fixed bandwidth GWR using a Gaussian kernel.\n",
    "    \"\"\"\n",
    "    n = len(coords)\n",
    "    preds = np.zeros(n)\n",
    "    X = np.hstack([np.ones((n, 1)), factors])\n",
    "    for i in range(n):\n",
    "        dist = np.linalg.norm(coords - coords[i], axis=1)\n",
    "        W = np.diag(gaussian_kernel(dist, bw))\n",
    "        # Use pseudo-inverse for stability\n",
    "        beta = np.linalg.pinv(X.T @ W @ X) @ (X.T @ W @ y.reshape(-1, 1))\n",
    "        preds[i] = (np.array([1] + list(factors[i])) @ beta).item()\n",
    "    return preds.reshape(-1, 1)\n",
    "\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "y_train = train_combined['AsR'].values\n",
    "GWR_train = fixed_gwr(coords_train, G_train, y_train, bw=0.5)\n",
    "\n",
    "# Interpolate PMF factors for the test set using Inverse Distance Weighting (IDW)\n",
    "def idw_interpolation(known_coords, known_values, query_coords, power=2):\n",
    "    \"\"\"\n",
    "    Performs IDW to interpolate values from known points to query points.\n",
    "    \"\"\"\n",
    "    tree = cKDTree(known_coords)\n",
    "    dists, idxs = tree.query(query_coords, k=4)\n",
    "    dists[dists == 0] = 1e-10  # Avoid division by zero\n",
    "    weights = 1 / (dists ** power)\n",
    "    weights /= weights.sum(axis=1)[:, None]\n",
    "    return np.sum(weights * known_values[idxs], axis=1)\n",
    "\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "y_test = test_orig['AsR'].values\n",
    "# Interpolate PMF factors for the test set\n",
    "G_test = np.column_stack([idw_interpolation(coords_train, G_train[:, i], coords_test) for i in range(G_train.shape[1])])\n",
    "# Apply GWR to the interpolated PMF factors for the test set\n",
    "GWR_test = fixed_gwr(coords_test, G_test, y_test, bw=0.5)\n",
    "\n",
    "# ==================== 5. Interaction Features ==================== #\n",
    "# Create new features by interacting PMF and GWR results.\n",
    "def create_interactions(pmf, gwr):\n",
    "    \"\"\"\n",
    "    Creates interaction features between PMF factors and GWR predictions.\n",
    "    \"\"\"\n",
    "    interactions = pd.DataFrame()\n",
    "    for i in range(pmf.shape[1]):\n",
    "        interactions[f\"PMF{i}_GWR\"] = pmf[:, i] * gwr.flatten()\n",
    "    return interactions\n",
    "\n",
    "train_interact = create_interactions(G_train, GWR_train)\n",
    "test_interact = create_interactions(G_test, GWR_test)\n",
    "\n",
    "# ==================== 6. Final Feature Matrix ==================== #\n",
    "# Combine all engineered features into a single matrix for the XGBoost model.\n",
    "X_train = np.hstack([\n",
    "    train_combined[numeric_cols].values,\n",
    "    train_raster_feats.values,\n",
    "    G_train,\n",
    "    GWR_train,\n",
    "    train_interact.values\n",
    "])\n",
    "\n",
    "X_test = np.hstack([\n",
    "    test_orig[numeric_cols].values,\n",
    "    test_raster_feats.values,\n",
    "    G_test,\n",
    "    GWR_test,\n",
    "    test_interact.values\n",
    "])\n",
    "\n",
    "# ==================== 7. Optuna Hyperparameter Optimization ==================== #\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Defines the Optuna objective function to minimize negative R².\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 600),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5)\n",
    "    }\n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return -r2_score(y_test, y_pred)\n",
    "\n",
    "# Run the Optuna study to find the best parameters\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "best_params = study.best_params\n",
    "print(\"\\nBest Parameters from Optuna:\", best_params)\n",
    "\n",
    "# ==================== 8. Train Final XGBoost ==================== #\n",
    "# Train the final model with the optimized hyperparameters.\n",
    "xgb = XGBRegressor(**best_params, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# ==================== 9. Evaluation ==================== #\n",
    "# Evaluate the final model's performance on both training and test data.\n",
    "y_pred_train = xgb.predict(X_train)\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 10. SHAP Interpretation ==================== #\n",
    "# Use SHAP to explain the model's predictions and feature importance.\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Generate SHAP summary plots\n",
    "shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])])\n",
    "shap.summary_plot(shap_values, X_train, feature_names=[f\"F{i}\" for i in range(X_train.shape[1])], plot_type=\"bar\")\n",
    "\n",
    "print(\"SHAP analysis complete. Check plots for feature importance.\")\n",
    "\n",
    "feature_names = list(numeric_cols) \\\n",
    "                + list(train_raster_feats.columns) \\\n",
    "                + [f\"PMF_Factor{i}\" for i in range(G_train.shape[1])] \\\n",
    "                + [\"GWR_Adjusted\"] \\\n",
    "                + list(train_interact.columns)\n",
    "\n",
    "# Create DataFrame of importance\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": xgb.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Save & print\n",
    "importance_df.to_csv(\"SHAP-PMF-GLWR-Xgboost.csv\", index=False)\n",
    "print(\"\\nTop Features (XGBoost Gain):\\n\", importance_df.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd0b42-9574-4d38-a519-e51e3e508275",
   "metadata": {},
   "source": [
    "# PMF-GWR Based CNN-GNN-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85fb55d7-102c-44d7-8a8a-28a2778b5ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PMF Source Profiles (F):\n",
      "          CrR        NiR        CuR       AsR       CdR        PbR         MR  \\\n",
      "0   1.011394   0.736558   1.692247  0.281341  0.081750   1.820546   0.744546   \n",
      "1   6.361288   2.934156   7.088633  1.445853  0.265187   5.471062   3.794235   \n",
      "2  21.198226  13.542373  26.909206  5.147733  1.449371  21.855110  14.985165   \n",
      "\n",
      "       SandR      SiltR      ClayR           FeR  \n",
      "0   0.626923   0.857056   0.708029    811.577541  \n",
      "1   4.450678   3.851341   2.797802   3334.739331  \n",
      "2  16.238105  14.757198  12.760148  12485.904320  \n",
      "\n",
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing with Enhanced CNN–GNN–MLP Model (500m)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,832</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,800</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_41    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_43    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_45    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_41… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │ max_pooling2d_43… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">100,416</span> │ max_pooling2d_45… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_42    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_44    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_46    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_42… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_44… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_46… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_combined        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120000</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ flatten_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15,360,128</span> │ cnn_combined[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_25      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ gnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">691,840</span> │ concatenate_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ transformer_bloc… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m20,832\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m40,800\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_41    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_43    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_45    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_41… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m51,264\u001b[0m │ max_pooling2d_43… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_51 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m100,416\u001b[0m │ max_pooling2d_45… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_42    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_44    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_46    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_42… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_44… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_46… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_combined        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120000\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ flatten_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ flatten_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,472\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_126 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │ \u001b[38;5;34m15,360,128\u001b[0m │ cnn_combined[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_25      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ cnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ gnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │    \u001b[38;5;34m691,840\u001b[0m │ concatenate_25[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_129 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ transformer_bloc… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_130 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,337,057</span> (62.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,337,057\u001b[0m (62.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,337,057</span> (62.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,337,057\u001b[0m (62.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 294ms/step - loss: 34723.8008 - val_loss: 23331.9414\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 280ms/step - loss: 22914.8848 - val_loss: 10303.9258\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - loss: 9632.6924 - val_loss: 4718.3516\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - loss: 6271.0171 - val_loss: 5185.2856\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 280ms/step - loss: 6240.5991 - val_loss: 4652.2095\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - loss: 5114.9873 - val_loss: 4708.8525\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - loss: 4945.1816 - val_loss: 4530.8457\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - loss: 5727.6230 - val_loss: 3625.7747\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - loss: 2996.6450 - val_loss: 2689.4751\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - loss: 3152.1204 - val_loss: 1318.2704\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - loss: 1478.1138 - val_loss: 824.2883\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - loss: 1203.4611 - val_loss: 892.1137\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 289ms/step - loss: 838.8353 - val_loss: 1155.0319\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - loss: 983.5536 - val_loss: 584.0251\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 285ms/step - loss: 778.6987 - val_loss: 562.7603\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 305ms/step - loss: 817.7516 - val_loss: 327.6863\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - loss: 744.0341 - val_loss: 399.9274\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - loss: 994.4224 - val_loss: 589.5069\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 289ms/step - loss: 680.7864 - val_loss: 368.8808\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - loss: 840.3652 - val_loss: 408.6573\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 286ms/step - loss: 710.5457 - val_loss: 339.5006\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - loss: 1212.3990 - val_loss: 519.6331\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 289ms/step - loss: 1137.7543 - val_loss: 589.1194\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 285ms/step - loss: 810.2007 - val_loss: 327.2043\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - loss: 679.5660 - val_loss: 301.2451\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - loss: 481.8894 - val_loss: 374.2705\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - loss: 656.6066 - val_loss: 443.4462\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - loss: 905.3644 - val_loss: 249.7935\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - loss: 475.8770 - val_loss: 177.6548\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - loss: 468.1436 - val_loss: 107.3018\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - loss: 267.5375 - val_loss: 193.5201\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - loss: 364.9856 - val_loss: 213.4180\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 285ms/step - loss: 608.8947 - val_loss: 172.6354\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 293ms/step - loss: 462.0377 - val_loss: 124.4818\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 291ms/step - loss: 361.2413 - val_loss: 259.8395\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 303ms/step - loss: 641.2083 - val_loss: 142.1660\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - loss: 573.2639 - val_loss: 244.7065\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 289ms/step - loss: 427.8917 - val_loss: 228.0634\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 293ms/step - loss: 591.1084 - val_loss: 649.3901\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 291ms/step - loss: 823.0609 - val_loss: 341.9646\n",
      "\n",
      "✅ Enhanced CNN–GNN–MLP Model Performance (500m):\n",
      "R² Train: -0.9433 | RMSE Train: 95.1857\n",
      "R² Test: 0.9168 | RMSE Test: 22.8137\n",
      "\n",
      "--------------------------------------------------\n",
      "Feature Importance Analysis for 500m\n",
      "--------------------------------------------------\n",
      "\n",
      "Baseline Performance on Test Set: R² = 0.9168\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R² drop): 0.4542\n",
      "MLP Branch Importance (R² drop): 0.2628\n",
      "GNN Branch Importance (R² drop): -0.0179\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "PMF0_GWR            : 0.0254\n",
      "RI                  : 0.0215\n",
      "GWR_Adjusted        : 0.0194\n",
      "NiR                 : 0.0116\n",
      "num_industry        : 0.0101\n",
      "ClayR               : 0.0098\n",
      "PMF_Factor0         : 0.0094\n",
      "FeR                 : 0.0056\n",
      "CuR                 : 0.0034\n",
      "CdR                 : 0.0031\n",
      "PMF_Factor2         : 0.0028\n",
      "SandR               : 0.0015\n",
      "PbR                 : 0.0008\n",
      "MR                  : 0.0005\n",
      "hydro_dist_brick    : 0.0000\n",
      "hydro_dist_ind      : 0.0000\n",
      "PMF_Factor1         : -0.0001\n",
      "PMF2_GWR            : -0.0007\n",
      "CrR                 : -0.0008\n",
      "SiltR               : -0.0015\n",
      "PMF1_GWR            : -0.0029\n",
      "num_brick_field     : -0.0131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11364"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Define the single buffer size to use for CNN patches\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data & Preprocessing ==================== #\n",
    "# Load the main dataset and the river sampling data.\n",
    "original = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "# Identify columns for feature engineering and prediction\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = original.drop(columns=drop_cols).columns.drop('AsR')\n",
    "pmf_features = ['CrR', 'NiR', 'CuR', 'AsR', 'CdR', 'PbR', 'MR', 'SandR', 'SiltR', 'ClayR', 'FeR']\n",
    "\n",
    "# --- IMPUTATION FIX: Fill NaN values with 0 before further processing ---\n",
    "original.fillna(0, inplace=True)\n",
    "river_100.fillna(0, inplace=True)\n",
    "\n",
    "# Split original data into train and test sets for the ensemble model.\n",
    "np.random.seed(42)\n",
    "train_orig = original.sample(10, random_state=42)\n",
    "test_orig = original.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# Define the coordinates and target variables\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 2. Feature Engineering from Model 1 ==================== #\n",
    "\n",
    "# --- 2.1 PMF (NMF) for Source Apportionment ---\n",
    "nmf = NMF(n_components=3, init='random', random_state=42, max_iter=1000)\n",
    "# Ensure data for NMF does not contain NaN or negative values\n",
    "G_train = nmf.fit_transform(np.maximum(train_combined[pmf_features].values, 0))\n",
    "F = nmf.components_\n",
    "print(\"\\nPMF Source Profiles (F):\\n\", pd.DataFrame(F, columns=pmf_features))\n",
    "\n",
    "# --- 2.2 Fixed Geographically Weighted Regression (GWR) ---\n",
    "def gaussian_kernel(d, bw):\n",
    "    return np.exp(-(d**2) / (2 * bw**2))\n",
    "\n",
    "def fixed_gwr(coords, factors, y, bw=0.5):\n",
    "    \"\"\"Performs a fixed bandwidth GWR using a Gaussian kernel.\"\"\"\n",
    "    n = len(coords)\n",
    "    preds = np.zeros(n)\n",
    "    X = np.hstack([np.ones((n, 1)), factors])\n",
    "    for i in range(n):\n",
    "        dist = np.linalg.norm(coords - coords[i], axis=1)\n",
    "        W = np.diag(gaussian_kernel(dist, bw))\n",
    "        try:\n",
    "            beta = np.linalg.pinv(X.T @ W @ X) @ (X.T @ W @ y.reshape(-1, 1))\n",
    "            preds[i] = (np.array([1] + list(factors[i])) @ beta).item()\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Handle singular matrix by using a simpler model\n",
    "            preds[i] = y.mean()\n",
    "    return preds.reshape(-1, 1)\n",
    "\n",
    "GWR_train = fixed_gwr(coords_train, G_train, y_train, bw=0.5)\n",
    "\n",
    "# --- 2.3 Interpolate PMF factors for the test set ---\n",
    "def idw_interpolation(known_coords, known_values, query_coords, power=2):\n",
    "    \"\"\"Performs IDW to interpolate values from known points to query points.\"\"\"\n",
    "    tree = cKDTree(known_coords)\n",
    "    dists, idxs = tree.query(query_coords, k=4)\n",
    "    dists[dists == 0] = 1e-10  # Avoid division by zero\n",
    "    weights = 1 / (dists ** power)\n",
    "    weights /= weights.sum(axis=1)[:, None]\n",
    "    return np.sum(weights * known_values[idxs], axis=1)\n",
    "\n",
    "G_test = np.column_stack([idw_interpolation(coords_train, G_train[:, i], coords_test) for i in range(G_train.shape[1])])\n",
    "\n",
    "# --- 2.4 Apply GWR to the interpolated PMF factors for the test set ---\n",
    "GWR_test = fixed_gwr(coords_test, G_test, y_test, bw=0.5)\n",
    "\n",
    "# --- 2.5 Interaction Features ---\n",
    "def create_interactions(pmf, gwr):\n",
    "    \"\"\"Creates interaction features between PMF factors and GWR predictions.\"\"\"\n",
    "    interactions = pd.DataFrame()\n",
    "    for i in range(pmf.shape[1]):\n",
    "        interactions[f\"PMF{i}_GWR\"] = pmf[:, i] * gwr.flatten()\n",
    "    return interactions\n",
    "\n",
    "train_interact = create_interactions(G_train, GWR_train)\n",
    "test_interact = create_interactions(G_test, GWR_test)\n",
    "\n",
    "# ==================== 3. Prepare GNN & MLP Input ==================== #\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "mlp_data_train_raw = pd.DataFrame(\n",
    "    np.hstack([\n",
    "        train_combined[numeric_cols].values,\n",
    "        G_train,\n",
    "        GWR_train,\n",
    "        train_interact.values\n",
    "    ]),\n",
    "    columns=list(numeric_cols) + [f\"PMF_Factor{i}\" for i in range(G_train.shape[1])] + [\"GWR_Adjusted\"] + list(train_interact.columns)\n",
    ")\n",
    "\n",
    "mlp_data_test_raw = pd.DataFrame(\n",
    "    np.hstack([\n",
    "        test_orig[numeric_cols].values,\n",
    "        G_test,\n",
    "        GWR_test,\n",
    "        test_interact.values\n",
    "    ]),\n",
    "    columns=list(numeric_cols) + [f\"PMF_Factor{i}\" for i in range(G_test.shape[1])] + [\"GWR_Adjusted\"] + list(test_interact.columns)\n",
    ")\n",
    "\n",
    "# --- IMPUTATION FIX: Fill NaN in raw MLP data before scaling ---\n",
    "mlp_data_train_raw.fillna(0, inplace=True)\n",
    "mlp_data_test_raw.fillna(0, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(mlp_data_train_raw)\n",
    "mlp_test = scaler.transform(mlp_data_test_raw)\n",
    "\n",
    "# ==================== 4. Collect ALL Rasters for CNN ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"\\nUsing {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 5. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # --- NORMALIZATION FIX: Add a small epsilon to avoid division by zero ---\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if max_val != 0:\n",
    "                        arr /= max_val + 1e-8 # Add epsilon for stability\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 6. Define Custom Transformer Layer ==================== #\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.expand_dims(inputs, axis=1)\n",
    "        attn_output = self.att(x, x)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return tf.squeeze(out2, axis=1)\n",
    "\n",
    "# ==================== 7. Define the New Fusion Model ==================== #\n",
    "def build_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # CNN input\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    cnn_3x3 = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_3x3 = MaxPooling2D((2,2))(cnn_3x3)\n",
    "    cnn_3x3 = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_3x3)\n",
    "    cnn_3x3 = MaxPooling2D((2,2))(cnn_3x3)\n",
    "    cnn_3x3 = Flatten()(cnn_3x3)\n",
    "\n",
    "    cnn_5x5 = Conv2D(32, (5,5), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_5x5 = MaxPooling2D((2,2))(cnn_5x5)\n",
    "    cnn_5x5 = Conv2D(64, (5,5), activation=\"relu\", padding=\"same\")(cnn_5x5)\n",
    "    cnn_5x5 = MaxPooling2D((2,2))(cnn_5x5)\n",
    "    cnn_5x5 = Flatten()(cnn_5x5)\n",
    "\n",
    "    cnn_7x7 = Conv2D(32, (7,7), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_7x7 = MaxPooling2D((2,2))(cnn_7x7)\n",
    "    cnn_7x7 = Conv2D(64, (7,7), activation=\"relu\", padding=\"same\")(cnn_7x7)\n",
    "    cnn_7x7 = MaxPooling2D((2,2))(cnn_7x7)\n",
    "    cnn_7x7 = Flatten()(cnn_7x7)\n",
    "\n",
    "    cnn_combined = Concatenate(name=\"cnn_combined\")([cnn_3x3, cnn_5x5, cnn_7x7])\n",
    "    cnn_out = Dense(128, activation=\"relu\", name=\"cnn_out\")(cnn_combined)\n",
    "\n",
    "    # MLP branch (for numerical site features)\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    m = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_out = Dense(32, activation=\"relu\", name=\"mlp_out\")(m)\n",
    "\n",
    "    # GNN branch (for spatial connectivity)\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    g = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_out = Dense(32, activation=\"relu\", name=\"gnn_out\")(g)\n",
    "\n",
    "    # Meta-learner (Transformer Block)\n",
    "    pre_transformer_features = Concatenate()([cnn_out, mlp_out, gnn_out])\n",
    "    \n",
    "    # Calculate the new embedding dimension\n",
    "    embed_dim = pre_transformer_features.shape[1]\n",
    "    \n",
    "    transformer_out = TransformerBlock(\n",
    "        embed_dim=embed_dim,\n",
    "        num_heads=4,\n",
    "        ff_dim=256\n",
    "    )(pre_transformer_features)\n",
    "    \n",
    "    # Final Fusion Layer\n",
    "    f = Dense(128, activation=\"relu\")(transformer_out)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn), verbose=0).flatten())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "        y_pred[np.isnan(y_pred)] = 0 # Replace NaNs with 0\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "# ==================== 8. Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing with Enhanced CNN–GNN–MLP Model ({BUFFER_METERS}m)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# Create data generators\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = model.predict(train_generator, verbose=0).flatten()\n",
    "# --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "y_pred_train[np.isnan(y_pred_train)] = 0\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n✅ Enhanced CNN–GNN–MLP Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "y_pred_baseline[np.isnan(y_pred_baseline)] = 0\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "print(f\"\\nBaseline Performance on Test Set: R² = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test), verbose=0).flatten()\n",
    "y_pred_cnn_ablated[np.isnan(y_pred_cnn_ablated)] = 0\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test), verbose=0).flatten()\n",
    "y_pred_mlp_ablated[np.isnan(y_pred_mlp_ablated)] = 0\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated), verbose=0).flatten()\n",
    "y_pred_gnn_ablated[np.isnan(y_pred_gnn_ablated)] = 0\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R² drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R² drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R² drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(mlp_data_train_raw.columns):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test), verbose=0).flatten()\n",
    "    y_pred_shuffled[np.isnan(y_pred_shuffled)] = 0\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac9f54e-9cca-4278-a228-ce7304dc2578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PMF Source Profiles (F):\n",
      "          CrR        NiR        CuR       AsR       CdR        PbR         MR  \\\n",
      "0   1.011394   0.736558   1.692247  0.281341  0.081750   1.820546   0.744546   \n",
      "1   6.361288   2.934156   7.088633  1.445853  0.265187   5.471062   3.794235   \n",
      "2  21.198226  13.542373  26.909206  5.147733  1.449371  21.855110  14.985165   \n",
      "\n",
      "       SandR      SiltR      ClayR           FeR  \n",
      "0   0.626923   0.857056   0.708029    811.577541  \n",
      "1   4.450678   3.851341   2.797802   3334.739331  \n",
      "2  16.238105  14.757198  12.760148  12485.904320  \n",
      "\n",
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing with Enhanced CNN–GNN–MLP Model (500m)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,832</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,800</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">100,416</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_combined        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120000</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15,360,128</span> │ cnn_combined[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ gnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">691,840</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ transformer_bloc… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m20,832\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m40,800\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m51,264\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m100,416\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_5[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_combined        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120000\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,472\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │ \u001b[38;5;34m15,360,128\u001b[0m │ cnn_combined[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ cnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ gnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │    \u001b[38;5;34m691,840\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ transformer_bloc… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,337,057</span> (62.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,337,057\u001b[0m (62.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,337,057</span> (62.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,337,057\u001b[0m (62.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 295ms/step - loss: 36898.0430 - val_loss: 25647.1270\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 286ms/step - loss: 27972.0000 - val_loss: 15256.8486\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - loss: 14307.1924 - val_loss: 5278.6963\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - loss: 4629.7686 - val_loss: 4703.5566\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 291ms/step - loss: 3890.4363 - val_loss: 4728.3101\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - loss: 4392.8589 - val_loss: 4547.0303\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - loss: 4326.8970 - val_loss: 4250.5645\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - loss: 5601.9863 - val_loss: 2418.5154\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 283ms/step - loss: 2955.4570 - val_loss: 1172.5132\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - loss: 1786.7261 - val_loss: 1051.9607\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - loss: 1034.6396 - val_loss: 738.2487\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - loss: 1058.5410 - val_loss: 433.2673\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 286ms/step - loss: 625.4643 - val_loss: 349.8346\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - loss: 548.4119 - val_loss: 327.3129\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - loss: 720.7579 - val_loss: 601.2037\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 275ms/step - loss: 1041.7461 - val_loss: 414.5102\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - loss: 881.8064 - val_loss: 345.1212\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 334ms/step - loss: 637.0455 - val_loss: 686.6856\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - loss: 820.4858 - val_loss: 487.8225\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - loss: 542.7325 - val_loss: 132.3797\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 293ms/step - loss: 547.9084 - val_loss: 230.1070\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 301ms/step - loss: 738.7037 - val_loss: 345.0883\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 322ms/step - loss: 443.8466 - val_loss: 188.9005\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - loss: 687.4448 - val_loss: 172.9704\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - loss: 582.8444 - val_loss: 686.1722\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - loss: 930.8214 - val_loss: 266.5090\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 294ms/step - loss: 645.0862 - val_loss: 229.8827\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 356ms/step - loss: 636.9471 - val_loss: 156.6479\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 325ms/step - loss: 444.5184 - val_loss: 421.7116\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 347ms/step - loss: 676.3129 - val_loss: 186.4513\n",
      "\n",
      "✅ Enhanced CNN–GNN–MLP Model Performance (500m):\n",
      "R² Train: -1.1585 | RMSE Train: 100.3172\n",
      "R² Test: 0.9468 | RMSE Test: 18.2461\n",
      "\n",
      "--------------------------------------------------\n",
      "Feature Importance Analysis for 500m\n",
      "--------------------------------------------------\n",
      "\n",
      "Baseline Performance on Test Set: R² = 0.9468\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R² drop): 0.6332\n",
      "MLP Branch Importance (R² drop): 0.1038\n",
      "GNN Branch Importance (R² drop): -0.0087\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "num_brick_field     : 0.0194\n",
      "num_industry        : 0.0131\n",
      "RI                  : 0.0111\n",
      "SandR               : 0.0093\n",
      "PMF0_GWR            : 0.0069\n",
      "CuR                 : 0.0040\n",
      "PMF_Factor1         : 0.0007\n",
      "GWR_Adjusted        : 0.0005\n",
      "SiltR               : 0.0003\n",
      "hydro_dist_brick    : -0.0000\n",
      "PMF_Factor2         : -0.0000\n",
      "hydro_dist_ind      : -0.0000\n",
      "CdR                 : -0.0002\n",
      "PMF2_GWR            : -0.0004\n",
      "FeR                 : -0.0006\n",
      "ClayR               : -0.0006\n",
      "CrR                 : -0.0006\n",
      "PMF_Factor0         : -0.0009\n",
      "NiR                 : -0.0011\n",
      "PMF1_GWR            : -0.0016\n",
      "PbR                 : -0.0027\n",
      "MR                  : -0.0053\n",
      "\n",
      "================================================================================\n",
      "Saving Model and Processed Data\n",
      "================================================================================\n",
      "✅ Model saved to 'models/fusion_model_500m.keras'\n",
      "✅ Processed data arrays saved to 'data_exports'\n",
      "✅ Raw dataframes saved to 'data_exports'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5543"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Define the single buffer size to use for CNN patches\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data & Preprocessing ==================== #\n",
    "# Load the main dataset and the river sampling data.\n",
    "original = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "# Identify columns for feature engineering and prediction\n",
    "drop_cols = ['Stations', 'River', 'Lat', 'Long', 'geometry']\n",
    "numeric_cols = original.drop(columns=drop_cols).columns.drop('AsR')\n",
    "pmf_features = ['CrR', 'NiR', 'CuR', 'AsR', 'CdR', 'PbR', 'MR', 'SandR', 'SiltR', 'ClayR', 'FeR']\n",
    "\n",
    "# --- IMPUTATION FIX: Fill NaN values with 0 before further processing ---\n",
    "original.fillna(0, inplace=True)\n",
    "river_100.fillna(0, inplace=True)\n",
    "\n",
    "# Split original data into train and test sets for the ensemble model.\n",
    "np.random.seed(42)\n",
    "train_orig = original.sample(10, random_state=42)\n",
    "test_orig = original.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# Define the coordinates and target variables\n",
    "coords_train = train_combined[['Long', 'Lat']].values\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 2. Feature Engineering from Model 1 ==================== #\n",
    "\n",
    "# --- 2.1 PMF (NMF) for Source Apportionment ---\n",
    "nmf = NMF(n_components=3, init='random', random_state=42, max_iter=1000)\n",
    "# Ensure data for NMF does not contain NaN or negative values\n",
    "G_train = nmf.fit_transform(np.maximum(train_combined[pmf_features].values, 0))\n",
    "F = nmf.components_\n",
    "print(\"\\nPMF Source Profiles (F):\\n\", pd.DataFrame(F, columns=pmf_features))\n",
    "\n",
    "# --- 2.2 Fixed Geographically Weighted Regression (GWR) ---\n",
    "def gaussian_kernel(d, bw):\n",
    "    return np.exp(-(d**2) / (2 * bw**2))\n",
    "\n",
    "def fixed_gwr(coords, factors, y, bw=0.5):\n",
    "    \"\"\"Performs a fixed bandwidth GWR using a Gaussian kernel.\"\"\"\n",
    "    n = len(coords)\n",
    "    preds = np.zeros(n)\n",
    "    X = np.hstack([np.ones((n, 1)), factors])\n",
    "    for i in range(n):\n",
    "        dist = np.linalg.norm(coords - coords[i], axis=1)\n",
    "        W = np.diag(gaussian_kernel(dist, bw))\n",
    "        try:\n",
    "            beta = np.linalg.pinv(X.T @ W @ X) @ (X.T @ W @ y.reshape(-1, 1))\n",
    "            preds[i] = (np.array([1] + list(factors[i])) @ beta).item()\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Handle singular matrix by using a simpler model\n",
    "            preds[i] = y.mean()\n",
    "    return preds.reshape(-1, 1)\n",
    "\n",
    "GWR_train = fixed_gwr(coords_train, G_train, y_train, bw=0.5)\n",
    "\n",
    "# --- 2.3 Interpolate PMF factors for the test set ---\n",
    "def idw_interpolation(known_coords, known_values, query_coords, power=2):\n",
    "    \"\"\"Performs IDW to interpolate values from known points to query points.\"\"\"\n",
    "    tree = cKDTree(known_coords)\n",
    "    dists, idxs = tree.query(query_coords, k=4)\n",
    "    dists[dists == 0] = 1e-10  # Avoid division by zero\n",
    "    weights = 1 / (dists ** power)\n",
    "    weights /= weights.sum(axis=1)[:, None]\n",
    "    return np.sum(weights * known_values[idxs], axis=1)\n",
    "\n",
    "G_test = np.column_stack([idw_interpolation(coords_train, G_train[:, i], coords_test) for i in range(G_train.shape[1])])\n",
    "\n",
    "# --- 2.4 Apply GWR to the interpolated PMF factors for the test set ---\n",
    "GWR_test = fixed_gwr(coords_test, G_test, y_test, bw=0.5)\n",
    "\n",
    "# --- 2.5 Interaction Features ---\n",
    "def create_interactions(pmf, gwr):\n",
    "    \"\"\"Creates interaction features between PMF factors and GWR predictions.\"\"\"\n",
    "    interactions = pd.DataFrame()\n",
    "    for i in range(pmf.shape[1]):\n",
    "        interactions[f\"PMF{i}_GWR\"] = pmf[:, i] * gwr.flatten()\n",
    "    return interactions\n",
    "\n",
    "train_interact = create_interactions(G_train, GWR_train)\n",
    "test_interact = create_interactions(G_test, GWR_test)\n",
    "\n",
    "# ==================== 3. Prepare GNN & MLP Input ==================== #\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "mlp_data_train_raw = pd.DataFrame(\n",
    "    np.hstack([\n",
    "        train_combined[numeric_cols].values,\n",
    "        G_train,\n",
    "        GWR_train,\n",
    "        train_interact.values\n",
    "    ]),\n",
    "    columns=list(numeric_cols) + [f\"PMF_Factor{i}\" for i in range(G_train.shape[1])] + [\"GWR_Adjusted\"] + list(train_interact.columns)\n",
    ")\n",
    "\n",
    "mlp_data_test_raw = pd.DataFrame(\n",
    "    np.hstack([\n",
    "        test_orig[numeric_cols].values,\n",
    "        G_test,\n",
    "        GWR_test,\n",
    "        test_interact.values\n",
    "    ]),\n",
    "    columns=list(numeric_cols) + [f\"PMF_Factor{i}\" for i in range(G_test.shape[1])] + [\"GWR_Adjusted\"] + list(test_interact.columns)\n",
    ")\n",
    "\n",
    "# --- IMPUTATION FIX: Fill NaN in raw MLP data before scaling ---\n",
    "mlp_data_train_raw.fillna(0, inplace=True)\n",
    "mlp_data_test_raw.fillna(0, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(mlp_data_train_raw)\n",
    "mlp_test = scaler.transform(mlp_data_test_raw)\n",
    "\n",
    "# ==================== 4. Collect ALL Rasters for CNN ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"\\nUsing {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 5. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # --- NORMALIZATION FIX: Add a small epsilon to avoid division by zero ---\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if max_val != 0:\n",
    "                        arr /= max_val + 1e-8 # Add epsilon for stability\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 6. Define Custom Transformer Layer ==================== #\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.expand_dims(inputs, axis=1)\n",
    "        attn_output = self.att(x, x)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return tf.squeeze(out2, axis=1)\n",
    "\n",
    "# ==================== 7. Define the New Fusion Model ==================== #\n",
    "def build_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # CNN input\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    cnn_3x3 = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_3x3 = MaxPooling2D((2,2))(cnn_3x3)\n",
    "    cnn_3x3 = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_3x3)\n",
    "    cnn_3x3 = MaxPooling2D((2,2))(cnn_3x3)\n",
    "    cnn_3x3 = Flatten()(cnn_3x3)\n",
    "\n",
    "    cnn_5x5 = Conv2D(32, (5,5), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_5x5 = MaxPooling2D((2,2))(cnn_5x5)\n",
    "    cnn_5x5 = Conv2D(64, (5,5), activation=\"relu\", padding=\"same\")(cnn_5x5)\n",
    "    cnn_5x5 = MaxPooling2D((2,2))(cnn_5x5)\n",
    "    cnn_5x5 = Flatten()(cnn_5x5)\n",
    "\n",
    "    cnn_7x7 = Conv2D(32, (7,7), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_7x7 = MaxPooling2D((2,2))(cnn_7x7)\n",
    "    cnn_7x7 = Conv2D(64, (7,7), activation=\"relu\", padding=\"same\")(cnn_7x7)\n",
    "    cnn_7x7 = MaxPooling2D((2,2))(cnn_7x7)\n",
    "    cnn_7x7 = Flatten()(cnn_7x7)\n",
    "\n",
    "    cnn_combined = Concatenate(name=\"cnn_combined\")([cnn_3x3, cnn_5x5, cnn_7x7])\n",
    "    cnn_out = Dense(128, activation=\"relu\", name=\"cnn_out\")(cnn_combined)\n",
    "\n",
    "    # MLP branch (for numerical site features)\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    m = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_out = Dense(32, activation=\"relu\", name=\"mlp_out\")(m)\n",
    "\n",
    "    # GNN branch (for spatial connectivity)\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    g = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_out = Dense(32, activation=\"relu\", name=\"gnn_out\")(g)\n",
    "\n",
    "    # Meta-learner (Transformer Block)\n",
    "    pre_transformer_features = Concatenate()([cnn_out, mlp_out, gnn_out])\n",
    "    \n",
    "    # Calculate the new embedding dimension\n",
    "    embed_dim = pre_transformer_features.shape[1]\n",
    "    \n",
    "    transformer_out = TransformerBlock(\n",
    "        embed_dim=embed_dim,\n",
    "        num_heads=4,\n",
    "        ff_dim=256\n",
    "    )(pre_transformer_features)\n",
    "    \n",
    "    # Final Fusion Layer\n",
    "    f = Dense(128, activation=\"relu\")(transformer_out)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn), verbose=0).flatten())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        # --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "        y_pred[np.isnan(y_pred)] = 0 # Replace NaNs with 0\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "# ==================== 8. Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing with Enhanced CNN–GNN–MLP Model ({BUFFER_METERS}m)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# Create data generators\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = model.predict(train_generator, verbose=0).flatten()\n",
    "# --- NaN FIX: Ensure y_pred has no NaNs before calculating metrics ---\n",
    "y_pred_train[np.isnan(y_pred_train)] = 0\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n✅ Enhanced CNN–GNN–MLP Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "y_pred_baseline[np.isnan(y_pred_baseline)] = 0\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "print(f\"\\nBaseline Performance on Test Set: R² = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test), verbose=0).flatten()\n",
    "y_pred_cnn_ablated[np.isnan(y_pred_cnn_ablated)] = 0\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test), verbose=0).flatten()\n",
    "y_pred_mlp_ablated[np.isnan(y_pred_mlp_ablated)] = 0\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated), verbose=0).flatten()\n",
    "y_pred_gnn_ablated[np.isnan(y_pred_gnn_ablated)] = 0\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R² drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R² drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R² drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(mlp_data_train_raw.columns):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test), verbose=0).flatten()\n",
    "    y_pred_shuffled[np.isnan(y_pred_shuffled)] = 0\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# ==================== 10. Save Model and Data for Reproducibility ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Saving Model and Processed Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "models_dir = \"models\"\n",
    "data_exports_dir = \"data_exports\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(data_exports_dir, exist_ok=True)\n",
    "\n",
    "# Save the trained model in the Keras native format\n",
    "model_filename = f\"fusion_model_{BUFFER_METERS}m.keras\"\n",
    "model.save(os.path.join(models_dir, model_filename))\n",
    "print(f\"✅ Model saved to '{os.path.join(models_dir, model_filename)}'\")\n",
    "\n",
    "# Save processed NumPy arrays for later use\n",
    "np.savez_compressed(\n",
    "    os.path.join(data_exports_dir, \"processed_train_data.npz\"),\n",
    "    coords=coords_train,\n",
    "    mlp=mlp_train,\n",
    "    y=y_train\n",
    ")\n",
    "np.savez_compressed(\n",
    "    os.path.join(data_exports_dir, \"processed_test_data.npz\"),\n",
    "    coords=coords_test,\n",
    "    mlp=mlp_test,\n",
    "    y=y_test\n",
    ")\n",
    "np.savez_compressed(\n",
    "    os.path.join(data_exports_dir, \"gnn_data.npz\"),\n",
    "    gnn_train=gnn_train,\n",
    "    gnn_test=gnn_test\n",
    ")\n",
    "print(f\"✅ Processed data arrays saved to '{data_exports_dir}'\")\n",
    "\n",
    "# Save the raw dataframes to CSV for easy inspection\n",
    "train_combined.to_csv(os.path.join(data_exports_dir, \"train_combined.csv\"), index=False)\n",
    "test_orig.to_csv(os.path.join(data_exports_dir, \"test_orig.csv\"), index=False)\n",
    "print(f\"✅ Raw dataframes saved to '{data_exports_dir}'\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a6c37-f3f6-460b-928b-c96cf6a875fd",
   "metadata": {},
   "source": [
    "# CNN GNN MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f773f64d-634f-4d43-b5be-bee199f66e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_47    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_47… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_48    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_48… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,333,696</span> │ flatten_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_26      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ gnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concatenate_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_52 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m,    │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_47    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_53 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_47… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_48    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_48… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_131 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,024\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_132 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m4,333,696\u001b[0m │ flatten_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_132[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_26      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ cnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ gnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_133 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ concatenate_26[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_134 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,405,025</span> (16.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,405,025\u001b[0m (16.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,405,025</span> (16.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,405,025\u001b[0m (16.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - loss: 64932.6875 - val_loss: 21961.8418\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 22477.2480 - val_loss: 6374.6865\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 8924.4512 - val_loss: 6423.1353\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 6554.2734 - val_loss: 5683.7803\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 9617.4072 - val_loss: 5499.2466\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 4635.0176 - val_loss: 5995.5684\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 7153.4341 - val_loss: 4666.9512\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 5955.0645 - val_loss: 3723.6865\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 3753.4939 - val_loss: 3081.9600\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 4126.3911 - val_loss: 2409.8386\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 3231.7905 - val_loss: 2011.5493\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 3570.9805 - val_loss: 1593.4828\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 2535.7161 - val_loss: 1106.4746\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 1803.5408 - val_loss: 775.9102\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - loss: 1844.5269 - val_loss: 506.8592\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 1394.0970 - val_loss: 645.6378\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 1147.5288 - val_loss: 404.8920\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 1231.2070 - val_loss: 409.6231\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 1008.4201 - val_loss: 348.6466\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 1431.6699 - val_loss: 362.8777\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 855.5308 - val_loss: 333.2672\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 854.2971 - val_loss: 258.2816\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 933.3932 - val_loss: 796.6979\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 1201.0840 - val_loss: 949.4065\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 1170.2434 - val_loss: 327.3332\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 1017.6339 - val_loss: 1345.1189\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 1120.0413 - val_loss: 635.7762\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 918.7227 - val_loss: 354.2274\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 656.1550 - val_loss: 409.0626\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 762.6601 - val_loss: 131.4327\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 924.3413 - val_loss: 652.4243\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 634.4244 - val_loss: 598.6708\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 609.4695 - val_loss: 508.2222\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 634.4005 - val_loss: 101.8612\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 676.2088 - val_loss: 376.8649\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 714.4688 - val_loss: 396.3561\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 647.0056 - val_loss: 409.9897\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 747.9131 - val_loss: 354.4470\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 478.4935 - val_loss: 247.7935\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 646.1812 - val_loss: 257.9452\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 351.7791 - val_loss: 113.3756\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 513.7554 - val_loss: 587.5462\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 690.8871 - val_loss: 462.4906\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 475.2055 - val_loss: 676.6095\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      " Enhanced CNN–GNN–MLP Model Performance (All Rasters):\n",
      "R² Train: 0.9785 | RMSE Train: 24.4394\n",
      "R² Test: 0.9045 | RMSE Test: 24.4394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the buffer size in meters\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "river_100.drop(columns=\"Source\", inplace=True)\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, batch_size=4, shuffle=True, buffer_meters=BUFFER_METERS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        # The GNN input is now a (batch_size, num_train_samples) matrix\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "\n",
    "# ==================== 5. Define Enhanced CNN–GNN–MLP Model ==================== #\n",
    "def build_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # CNN branch (for raster data)\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    x = Conv2D(32, (3,3), activation=\"relu\")(cnn_input)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    cnn_out = Dense(128, activation=\"relu\", name=\"cnn_out\")(x)\n",
    "\n",
    "    # MLP branch (for numerical site features)\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    m = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_out = Dense(32, activation=\"relu\", name=\"mlp_out\")(m)\n",
    "\n",
    "    # GNN branch (for spatial connectivity)\n",
    "    # The GNN input dimension is now the number of training samples\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    g = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_out = Dense(32, activation=\"relu\", name=\"gnn_out\")(g)\n",
    "\n",
    "    # Fusion Layer\n",
    "    combined = Concatenate()([cnn_out, mlp_out, gnn_out])\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# We need to determine the final GNN input dimension for the model\n",
    "# It's the total number of training samples\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "cnn_patch_shape = (2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), len(raster_paths))\n",
    "model = build_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "# We create a separate generator for the validation data.\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    buffer_meters=BUFFER_METERS\n",
    ")\n",
    "\n",
    "# For evaluation, we will create a generator for the full test set.\n",
    "# The shuffle is set to False for consistent evaluation results.\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    # Pre-calculate patch size from the first raster for evaluation\n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        # Get the corresponding slice of the test GNN input matrix\n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        # Make predictions on the batch and append to list\n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator # Using the same generator for validation for this example\n",
    ")\n",
    "\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "# Re-create a data generator without shuffling for evaluation on the training set\n",
    "train_eval_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    buffer_meters=BUFFER_METERS\n",
    ")\n",
    "\n",
    "y_pred_train = model.predict(train_eval_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "\n",
    "print(f\"\\n Enhanced CNN–GNN–MLP Model Performance (All Rasters):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_test:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72832a97-70bd-4189-bf41-09c6b50ffd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "9. Feature Importance Analysis\n",
      "==================================================\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Baseline Performance on Test Set: R² = 0.9045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R² drop): 1.9020\n",
      "MLP Branch Importance (R² drop): 0.6377\n",
      "GNN Branch Importance (R² drop): -0.0039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "CuR                 : 0.0881938248\n",
      "FeR                 : 0.0774321096\n",
      "PbR                 : 0.0634686604\n",
      "SiltR               : 0.0292306012\n",
      "NiR                 : 0.0154820609\n",
      "CrR                 : 0.0113277295\n",
      "hydro_dist_brick    : -0.0000000654\n",
      "hydro_dist_ind      : -0.0000001546\n",
      "num_industry        : -0.0023789270\n",
      "AsR                 : -0.0076581517\n",
      "CdR                 : -0.0141643951\n",
      "num_brick_field     : -0.0184750708\n",
      "MR                  : -0.0189192987\n",
      "SandR               : -0.0218427579\n",
      "ClayR               : -0.0268473488\n"
     ]
    }
   ],
   "source": [
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"9. Feature Importance Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "# This method measures the importance of each model branch (CNN, MLP, GNN)\n",
    "# by temporarily 'ablating' it and measuring the drop in model performance (R²).\n",
    "\n",
    "# Calculate baseline performance on the test set\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nBaseline Performance on Test Set: R² = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0])\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test)).flatten()\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0])\n",
    "), mlp_test_ablated, gnn_test)).flatten()\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0])\n",
    "), mlp_test, gnn_test_ablated)).flatten()\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R² drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R² drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R² drop): {importance_gnn:.4f}\")\n",
    "\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "# This method measures the importance of each individual MLP feature\n",
    "# by shuffling its values and measuring the drop in model performance.\n",
    "\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(numeric_cols):\n",
    "    # Create a copy of the test data to avoid modifying the original\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    # Shuffle the values of the current feature (column i)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    # Make predictions with the shuffled feature\n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0]), 2*int(BUFFER_METERS/rasterio.open(raster_paths[0]).res[0])\n",
    "    ), mlp_test_shuffled, gnn_test)).flatten()\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    # Calculate the drop in performance\n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "# Sort and print the results\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2970f-f191-47f1-bb49-fdf99e0e3677",
   "metadata": {},
   "source": [
    "# CNN GAT MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b76e408-afd1-40a8-9291-4663d01e19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing for BUFFER_METERS = 500m\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_40\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_40\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_49    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_49… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_50    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_50… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,333,696</span> │ flatten_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_135[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_136[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_27      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ gnn_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concatenate_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_137[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_54 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m,    │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_49    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_55 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_49… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_50    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_50… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_135 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,024\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_136 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m4,333,696\u001b[0m │ flatten_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_135[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_136[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_27      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ cnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ gnn_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_137 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ concatenate_27[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_137[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_138 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,405,025</span> (16.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,405,025\u001b[0m (16.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,405,025</span> (16.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,405,025\u001b[0m (16.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - loss: 53052.2227 - val_loss: 23666.8750\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 20460.6328 - val_loss: 5928.3057\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 9825.4600 - val_loss: 5770.5464\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 6039.1973 - val_loss: 5678.9658\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 6581.0752 - val_loss: 5565.4912\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 6617.1831 - val_loss: 4843.4546\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 5915.6299 - val_loss: 4607.8208\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 4426.1465 - val_loss: 4438.5308\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 6320.9819 - val_loss: 4375.6782\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 5020.4043 - val_loss: 3876.7874\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 5432.9224 - val_loss: 3781.9329\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 3289.3982 - val_loss: 3307.4185\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 4699.4082 - val_loss: 3539.1584\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 3228.1033 - val_loss: 1972.5076\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 2774.7434 - val_loss: 1532.7125\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 2886.7163 - val_loss: 1141.0623\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 1627.8927 - val_loss: 1261.2358\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 1111.8953 - val_loss: 747.2529\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 1693.9209 - val_loss: 952.4917\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 1354.0032 - val_loss: 484.7690\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 1517.2554 - val_loss: 504.4310\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 1241.4431 - val_loss: 614.8011\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 1152.2303 - val_loss: 321.0196\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 1392.6001 - val_loss: 277.4326\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 909.0143 - val_loss: 279.2836\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 1123.6129 - val_loss: 356.5914\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 997.3942 - val_loss: 385.8030\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 730.3693 - val_loss: 174.5408\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 896.2302 - val_loss: 222.4818\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 924.8371 - val_loss: 169.6517\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 735.9274 - val_loss: 265.4681\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 566.5300 - val_loss: 350.4896\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 579.6212 - val_loss: 327.2378\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 654.0552 - val_loss: 876.9138\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 1107.6184 - val_loss: 475.4542\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 741.8509 - val_loss: 126.7784\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 538.1423 - val_loss: 425.3065\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 662.1038 - val_loss: 201.6745\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 818.0486 - val_loss: 278.8013\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 453.0302 - val_loss: 315.5532\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 651.7515 - val_loss: 343.3459\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 543.3316 - val_loss: 155.1478\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 788.6677 - val_loss: 423.7727\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 569.7294 - val_loss: 141.6806\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 528.9960 - val_loss: 70.4106\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 746.0079 - val_loss: 1844.0526\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 756.3773 - val_loss: 272.9092\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 411.2027 - val_loss: 636.5922\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 808.4558 - val_loss: 302.1597\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 417.5574 - val_loss: 415.3074\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 785.1228 - val_loss: 600.6878\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 540.3239 - val_loss: 309.5145\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 737.6537 - val_loss: 191.2233\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 386.9525 - val_loss: 564.3806\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 588.7040 - val_loss: 544.9938\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      " Enhanced CNN–GNN–MLP Model Performance (500m):\n",
      "R² Train: -1.1715 | RMSE Train: 21.5695\n",
      "R² Test: 0.9256 | RMSE Test: 21.5695\n",
      "\n",
      "--------------------------------------------------\n",
      "Feature Importance Analysis for 500m\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Baseline Performance on Test Set: R² = 0.9256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R² drop): 1.4670\n",
      "MLP Branch Importance (R² drop): 0.9285\n",
      "GNN Branch Importance (R² drop): -0.0188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "PbR                 : 0.2048\n",
      "CuR                 : 0.1631\n",
      "num_brick_field     : 0.0101\n",
      "ClayR               : 0.0095\n",
      "CdR                 : 0.0027\n",
      "MR                  : 0.0015\n",
      "hydro_dist_ind      : -0.0000\n",
      "hydro_dist_brick    : -0.0000\n",
      "SandR               : -0.0025\n",
      "FeR                 : -0.0032\n",
      "CrR                 : -0.0037\n",
      "AsR                 : -0.0049\n",
      "NiR                 : -0.0051\n",
      "SiltR               : -0.0057\n",
      "num_industry        : -0.0271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31276"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "\n",
    "# ==================== 5. Define Enhanced CNN–GNN–MLP Model ==================== #\n",
    "def build_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # CNN branch (for raster data)\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    x = Conv2D(32, (3,3), activation=\"relu\")(cnn_input)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64, (3,3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    cnn_out = Dense(128, activation=\"relu\", name=\"cnn_out\")(x)\n",
    "\n",
    "    # MLP branch (for numerical site features)\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    m = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_out = Dense(32, activation=\"relu\", name=\"mlp_out\")(m)\n",
    "\n",
    "    # GNN branch (for spatial connectivity)\n",
    "    # The GNN input dimension is now the number of training samples\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    g = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_out = Dense(32, activation=\"relu\", name=\"gnn_out\")(g)\n",
    "\n",
    "    # Fusion Layer\n",
    "    combined = Concatenate()([cnn_out, mlp_out, gnn_out])\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing for BUFFER_METERS = {BUFFER_METERS}m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# We need to determine the final GNN input dimension for the model\n",
    "# It's the total number of training samples\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n Enhanced CNN–GNN–MLP Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_test:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nBaseline Performance on Test Set: R² = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test)).flatten()\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test)).flatten()\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated)).flatten()\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R² drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R² drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R² drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(numeric_cols):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test)).flatten()\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e643b0d-5fcb-46ab-9263-7a1dd1ab577f",
   "metadata": {},
   "source": [
    "# Mixture of Experts (MoE) Ensemble\n",
    "\n",
    "```\n",
    "[Expert 1: CNN] ┐\n",
    "[Expert 2: GNN] ├── Gating Network (softmax weights) → Weighted Sum → Output\n",
    "[Expert 3: MLP] ┘\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "762581f4-13da-4d7a-8fc6-0970fc691a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "   - bui.tif\n",
      "   - ndsi.tif\n",
      "   - savi.tif\n",
      "   - ndbsi.tif\n",
      "   - ui.tif\n",
      "   - ndwi.tif\n",
      "   - ndbi.tif\n",
      "   - awei.tif\n",
      "   - evi.tif\n",
      "   - mndwi.tif\n",
      "   - ndvi.tif\n",
      "   - LULC2020.tif\n",
      "   - LULC2021.tif\n",
      "   - LULC2022.tif\n",
      "   - LULC2019.tif\n",
      "   - LULC2018.tif\n",
      "   - LULC2017.tif\n",
      "   - Pb_R.tif\n",
      "   - ClayR.tif\n",
      "   - SandR.tif\n",
      "   - CdR.tif\n",
      "   - CrR.tif\n",
      "   - AsR.tif\n",
      "   - SiltR.tif\n",
      "   - CuR.tif\n",
      "   - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing for BUFFER_METERS = 500m\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_41\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_41\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_51    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_51… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_52    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_52… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,128</span> │ flatten_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_140[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_142[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_28      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_139[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_141[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_143[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ concatenate_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_expert_out      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_139[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_expert_out      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_141[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_expert_out      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_143[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ experts_stack       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_expert_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_expert_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ gnn_expert_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gate_weights        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │ dense_145[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ experts_stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ gate_weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_56 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_51    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_57 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_51… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_52    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_52… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_140 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,024\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_142 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_139 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m5,120,128\u001b[0m │ flatten_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_141 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_140[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_143 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_142[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_28      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_139[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_141[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_143[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_144 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m12,352\u001b[0m │ concatenate_28[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_expert_out      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dense_139[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_expert_out      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_141[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_expert_out      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_143[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_145 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ experts_stack       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ cnn_expert_out[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_expert_out[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ gnn_expert_out[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gate_weights        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m99\u001b[0m │ dense_145[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ experts_stack[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │ gate_weights[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,173,158</span> (19.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,173,158\u001b[0m (19.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,173,158</span> (19.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,173,158\u001b[0m (19.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - loss: 196014.8438 - val_loss: 62951.0430\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 26831.1055 - val_loss: 17206.7090\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 11594.4219 - val_loss: 7692.9883\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 6581.2964 - val_loss: 5468.3784\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 6043.9692 - val_loss: 6683.2158\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 4637.2651 - val_loss: 4192.2793\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 3533.2510 - val_loss: 3857.0295\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 3378.0117 - val_loss: 3803.9812\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 3389.1392 - val_loss: 3202.0969\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 3552.9177 - val_loss: 2826.9912\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 2565.2429 - val_loss: 2489.7942\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 2446.3835 - val_loss: 2279.0474\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 2769.9775 - val_loss: 3642.7261\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 3353.9990 - val_loss: 1879.4130\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 1851.7153 - val_loss: 1556.2416\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 2037.7878 - val_loss: 1865.8857\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 1644.8619 - val_loss: 1333.8865\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 1090.9203 - val_loss: 1134.8550\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 752.7758 - val_loss: 885.8856\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 847.7044 - val_loss: 717.1031\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 779.5332 - val_loss: 659.6403\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 617.1283 - val_loss: 802.0629\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 414.9007 - val_loss: 538.2323\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 486.9508 - val_loss: 549.4819\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 624.1207 - val_loss: 503.2342\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 408.1071 - val_loss: 481.3681\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 469.2986 - val_loss: 459.0568\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 390.7466 - val_loss: 393.7585\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 501.6220 - val_loss: 401.3585\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 603.6008 - val_loss: 364.3602\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 482.3578 - val_loss: 352.7281\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 460.7653 - val_loss: 398.3272\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 389.6035 - val_loss: 405.1485\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 421.0868 - val_loss: 256.5887\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 218.5337 - val_loss: 241.2967\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 340.5518 - val_loss: 257.5004\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 506.6884 - val_loss: 250.7888\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 242.2419 - val_loss: 381.8375\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 278.8005 - val_loss: 263.3503\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 296.4254 - val_loss: 212.5125\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 160.3664 - val_loss: 346.4576\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 191.2833 - val_loss: 199.3248\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 278.2948 - val_loss: 218.8339\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 296.6640 - val_loss: 259.7656\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 271.0311 - val_loss: 325.3275\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 289.5559 - val_loss: 315.4543\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 407.4030 - val_loss: 242.6383\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 167.4176 - val_loss: 161.2202\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 112.6394 - val_loss: 141.2823\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 112.7061 - val_loss: 127.5851\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 196.8888 - val_loss: 126.0385\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 92.6443 - val_loss: 106.0692\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 151.1542 - val_loss: 101.3637\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 135.7029 - val_loss: 149.8142\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 104.7547 - val_loss: 142.9937\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 188.5639 - val_loss: 101.6167\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 115.6405 - val_loss: 118.7578\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 118.6730 - val_loss: 84.0472\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 106.1876 - val_loss: 99.6186\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 113.3496 - val_loss: 165.1895\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 148.1358 - val_loss: 198.3445\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 146.7386 - val_loss: 67.1343\n",
      "Epoch 63/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 97.6385 - val_loss: 86.7411\n",
      "Epoch 64/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 75.5881 - val_loss: 93.8500\n",
      "Epoch 65/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 82.7697 - val_loss: 54.2780\n",
      "Epoch 66/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - loss: 57.7117 - val_loss: 72.7582\n",
      "Epoch 67/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 69.9111 - val_loss: 100.9025\n",
      "Epoch 68/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 92.2058 - val_loss: 125.6542\n",
      "Epoch 69/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 96.4107 - val_loss: 94.9575\n",
      "Epoch 70/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 68.6244 - val_loss: 85.7476\n",
      "Epoch 71/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 235.6199 - val_loss: 234.1230\n",
      "Epoch 72/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 182.7719 - val_loss: 77.2223\n",
      "Epoch 73/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 113.8334 - val_loss: 168.9492\n",
      "Epoch 74/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 189.0806 - val_loss: 140.0078\n",
      "Epoch 75/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 73.3304 - val_loss: 69.8607\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\n",
      " Mixture of Experts Model Performance (500m):\n",
      "R² Train: -1.0047 | RMSE Train: 96.6778\n",
      "R² Test: 0.8612 | RMSE Test: 29.4608\n",
      "\n",
      "--------------------------------------------------\n",
      "Feature Importance Analysis for 500m\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Baseline Performance on Test Set: R² = 0.8612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R² drop): 4.8359\n",
      "MLP Branch Importance (R² drop): 0.0000\n",
      "GNN Branch Importance (R² drop): 0.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "hydro_dist_brick    : 0.0000\n",
      "num_brick_field     : 0.0000\n",
      "hydro_dist_ind      : 0.0000\n",
      "num_industry        : 0.0000\n",
      "CrR                 : 0.0000\n",
      "NiR                 : 0.0000\n",
      "CuR                 : 0.0000\n",
      "AsR                 : 0.0000\n",
      "CdR                 : 0.0000\n",
      "PbR                 : 0.0000\n",
      "MR                  : 0.0000\n",
      "SandR               : 0.0000\n",
      "SiltR               : 0.0000\n",
      "ClayR               : 0.0000\n",
      "FeR                 : 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13225"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    LayerNormalization,\n",
    "    Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: The data loading logic remains the same as it provides the inputs\n",
    "# required for the new model architecture.\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "\n",
    "# Define the columns to drop and the numeric columns to use for MLP\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "\n",
    "# Ensure there are no NaNs in the numeric columns before proceeding\n",
    "# This code was moved up to before the `numeric_cols` variable was used.\n",
    "orig[numeric_cols] = orig[numeric_cols].fillna(0)\n",
    "river_100[numeric_cols] = river_100[numeric_cols].fillna(0)\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"   -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \n",
    "    This version includes robust NaN handling to prevent model training errors.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    \n",
    "                    # Corrected logic: Convert any NaNs to a numerical value, e.g., 0,\n",
    "                    # to prevent them from propagating through the model.\n",
    "                    arr = np.nan_to_num(arr, nan=0.0)\n",
    "                    \n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # Get the maximum value, but check if it's a valid number and > 0.\n",
    "                    # This prevents division by zero if the patch is all zeros.\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if np.isfinite(max_val) and max_val > 0:\n",
    "                        arr /= max_val\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define the Mixture of Experts Model ==================== #\n",
    "def build_moe_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- Expert 1: CNN Branch ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch_flattened = Flatten()(cnn_branch)\n",
    "    cnn_branch_dense = Dense(128, activation=\"relu\")(cnn_branch_flattened)\n",
    "    # The CNN expert's final prediction\n",
    "    cnn_expert_out = Dense(1, activation=\"linear\", name=\"cnn_expert_out\")(cnn_branch_dense)\n",
    "\n",
    "    # --- Expert 2: MLP Branch ---\n",
    "    mlp_branch = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_branch = Dense(32, activation=\"relu\")(mlp_branch)\n",
    "    # The MLP expert's final prediction\n",
    "    mlp_expert_out = Dense(1, activation=\"linear\", name=\"mlp_expert_out\")(mlp_branch)\n",
    "\n",
    "    # --- Expert 3: GNN Branch ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_branch = Dense(32, activation=\"relu\")(gnn_branch)\n",
    "    # The GNN expert's final prediction\n",
    "    gnn_expert_out = Dense(1, activation=\"linear\", name=\"gnn_expert_out\")(gnn_branch)\n",
    "\n",
    "    # --- Gating Network ---\n",
    "    # The gating network needs features from all inputs to make its decision.\n",
    "    # We use the outputs of the dense layers before the final predictions as features.\n",
    "    gate_input = Concatenate()([cnn_branch_dense, mlp_branch, gnn_branch])\n",
    "    gate_network = Dense(64, activation=\"relu\")(gate_input)\n",
    "    gate_network = Dense(32, activation=\"relu\")(gate_network)\n",
    "    # The output is a set of weights for each expert (summing to 1 via softmax)\n",
    "    gate_weights = Dense(3, activation=\"softmax\", name=\"gate_weights\")(gate_network)\n",
    "\n",
    "    # --- Combine Experts and Gating Network ---\n",
    "    # Stack the predictions from each expert.\n",
    "    # The shape will be (batch_size, 3)\n",
    "    experts_stack = Concatenate(axis=1, name=\"experts_stack\")([cnn_expert_out, mlp_expert_out, gnn_expert_out])\n",
    "    \n",
    "    # Perform the weighted sum.\n",
    "    # This is done using a Lambda layer which takes the experts' outputs and\n",
    "    # the gating network's weights, and computes the dot product for each sample.\n",
    "    final_output = Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"final_output\")([experts_stack, gate_weights])\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing for BUFFER_METERS = {BUFFER_METERS}m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_moe_model(cnn_patch_shape, gnn_input_dim, mlp_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n Mixture of Experts Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nBaseline Performance on Test Set: R² = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test)).flatten()\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test)).flatten()\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated)).flatten()\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R² drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R² drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R² drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(numeric_cols):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test)).flatten()\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "422d6287-816a-4789-b832-9655bebbdccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "   - bui.tif\n",
      "   - ndsi.tif\n",
      "   - savi.tif\n",
      "   - ndbsi.tif\n",
      "   - ui.tif\n",
      "   - ndwi.tif\n",
      "   - ndbi.tif\n",
      "   - awei.tif\n",
      "   - evi.tif\n",
      "   - mndwi.tif\n",
      "   - ndvi.tif\n",
      "   - LULC2020.tif\n",
      "   - LULC2021.tif\n",
      "   - LULC2022.tif\n",
      "   - LULC2019.tif\n",
      "   - LULC2018.tif\n",
      "   - LULC2017.tif\n",
      "   - Pb_R.tif\n",
      "   - ClayR.tif\n",
      "   - SandR.tif\n",
      "   - CdR.tif\n",
      "   - CrR.tif\n",
      "   - AsR.tif\n",
      "   - SiltR.tif\n",
      "   - CuR.tif\n",
      "   - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing for BUFFER_METERS = 500m\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_42\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_42\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_53    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_53… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_54    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_54… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,696</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,128</span> │ flatten_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_147[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_29      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ concatenate_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_expert_out      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_146[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_expert_out      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_expert_out      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ experts_stack       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_expert_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_expert_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ gnn_expert_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gate_weights        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │ dense_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ experts_stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ gate_weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_58 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_53    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_59 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_53… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_54    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_54… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_147 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,024\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_149 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m5,696\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_146 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m5,120,128\u001b[0m │ flatten_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_148 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_147[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_150 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_29      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_151 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m12,352\u001b[0m │ concatenate_29[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_expert_out      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dense_146[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_expert_out      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_expert_out      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_152 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ experts_stack       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ cnn_expert_out[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_expert_out[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ gnn_expert_out[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gate_weights        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m99\u001b[0m │ dense_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ experts_stack[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │ gate_weights[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,171,750</span> (19.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,171,750\u001b[0m (19.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,171,750</span> (19.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,171,750\u001b[0m (19.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 103719.0078 - val_loss: 35935.1055\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 34567.2773 - val_loss: 35656.7266\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 32869.5391 - val_loss: 35312.9062\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 34663.8906 - val_loss: 34876.9062\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 38162.6445 - val_loss: 34316.2461\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 29751.8086 - val_loss: 33634.1211\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 28911.1523 - val_loss: 32762.1914\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 26308.6719 - val_loss: 31647.1973\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 25009.7246 - val_loss: 30274.2402\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 24946.5879 - val_loss: 28570.7148\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 25479.9141 - val_loss: 26497.7402\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 22476.4121 - val_loss: 24242.3477\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 22504.7949 - val_loss: 21646.6875\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 20956.0918 - val_loss: 18884.3281\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 15562.4473 - val_loss: 16161.9062\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 14541.4775 - val_loss: 13223.5811\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - loss: 12372.3994 - val_loss: 10534.9170\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 8680.6123 - val_loss: 8200.4629\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 6550.5991 - val_loss: 6131.3921\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 5194.0005 - val_loss: 4505.6416\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 5007.3755 - val_loss: 3254.7395\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 3372.7666 - val_loss: 2328.3354\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 2261.0254 - val_loss: 1739.5215\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 1928.0045 - val_loss: 1304.7000\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 1598.6710 - val_loss: 1021.5039\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1170.2122 - val_loss: 837.4042\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 1106.0696 - val_loss: 695.1953\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 994.6021 - val_loss: 620.8180\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 854.5134 - val_loss: 562.8983\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 837.8467 - val_loss: 525.1320\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1047.3712 - val_loss: 505.5934\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 805.4791 - val_loss: 489.3492\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 630.8423 - val_loss: 477.0076\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 501.0007 - val_loss: 465.0607\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 561.9440 - val_loss: 458.2867\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 531.3242 - val_loss: 446.4966\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 467.0329 - val_loss: 441.5172\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 563.6385 - val_loss: 433.6584\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 511.9748 - val_loss: 430.2105\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 540.1918 - val_loss: 420.5523\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 434.0540 - val_loss: 416.5890\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 460.1780 - val_loss: 411.7497\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 490.9846 - val_loss: 408.8709\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 371.9273 - val_loss: 402.9920\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 394.6091 - val_loss: 396.1545\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 445.0752 - val_loss: 393.3582\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 525.8738 - val_loss: 385.9028\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 370.3756 - val_loss: 381.9870\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 506.1852 - val_loss: 376.7472\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 359.2689 - val_loss: 373.5876\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 430.4126 - val_loss: 369.5496\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 342.3810 - val_loss: 367.1488\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 327.5629 - val_loss: 363.6860\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 403.3679 - val_loss: 359.5250\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 352.4254 - val_loss: 353.6143\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 290.7974 - val_loss: 351.9640\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 348.7676 - val_loss: 348.4724\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 367.4523 - val_loss: 344.4893\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 393.2390 - val_loss: 341.5622\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 280.1199 - val_loss: 339.8198\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 308.4358 - val_loss: 335.7488\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 274.6513 - val_loss: 333.9254\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 288.0586 - val_loss: 326.2083\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 213.4806 - val_loss: 326.7011\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 390.4263 - val_loss: 323.8407\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 333.8650 - val_loss: 322.0570\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 269.5991 - val_loss: 317.2129\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 279.1643 - val_loss: 315.6695\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 304.0831 - val_loss: 313.8770\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 258.8071 - val_loss: 308.6017\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 275.6784 - val_loss: 306.7992\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 363.8527 - val_loss: 304.2606\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 287.2298 - val_loss: 302.4089\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 305.4293 - val_loss: 296.5477\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 253.3042 - val_loss: 297.7105\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 229.7407 - val_loss: 296.9879\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 230.8269 - val_loss: 294.6458\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 260.2643 - val_loss: 289.3632\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 242.1922 - val_loss: 286.4475\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 250.3315 - val_loss: 287.2688\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 235.9999 - val_loss: 283.6906\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 255.6578 - val_loss: 279.3901\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 323.5229 - val_loss: 277.3436\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 298.3803 - val_loss: 276.0616\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 190.5111 - val_loss: 277.1676\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 202.9954 - val_loss: 272.5655\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 193.3265 - val_loss: 271.5650\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 224.5139 - val_loss: 268.0100\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 245.6535 - val_loss: 266.6799\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 286.2077 - val_loss: 262.7088\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 201.5271 - val_loss: 263.9753\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 206.1970 - val_loss: 261.1151\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 200.8618 - val_loss: 258.0312\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 283.8147 - val_loss: 255.2774\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 160.5282 - val_loss: 255.9835\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 237.9633 - val_loss: 251.9866\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 229.5044 - val_loss: 251.3113\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 146.7078 - val_loss: 249.0835\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 167.1124 - val_loss: 248.0610\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 161.8971 - val_loss: 245.2845\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      " Mixture of Experts Model Performance (500m):\n",
      "R² Train: -0.9102 | RMSE Train: 94.0110\n",
      "R² Test: 0.9243 | RMSE Test: 21.7532\n",
      "\n",
      "--------------------------------------------------\n",
      "Feature Importance Analysis for 500m\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "Baseline Performance on Test Set: R² = 0.9243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R² drop): 0.0000\n",
      "MLP Branch Importance (R² drop): 2.2593\n",
      "GNN Branch Importance (R² drop): 0.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "CuR                 : 0.1434\n",
      "AsR                 : 0.0695\n",
      "PbR                 : 0.0627\n",
      "num_brick_field     : 0.0489\n",
      "MR                  : 0.0425\n",
      "num_industry        : 0.0178\n",
      "SandR               : 0.0175\n",
      "NiR                 : 0.0107\n",
      "hydro_dist_brick    : -0.0000\n",
      "hydro_dist_ind      : -0.0000\n",
      "CrR                 : -0.0062\n",
      "SiltR               : -0.0084\n",
      "FeR                 : -0.0139\n",
      "CdR                 : -0.0146\n",
      "ClayR               : -0.0326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11322"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    LayerNormalization,\n",
    "    Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: The data loading logic remains the same as it provides the inputs\n",
    "# required for the new model architecture.\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "# Define the columns to drop and the numeric columns to use for MLP\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Ensure there are no NaNs in the numeric columns before proceeding\n",
    "orig[numeric_cols] = orig[numeric_cols].fillna(0)\n",
    "river_100[numeric_cols] = river_100[numeric_cols].fillna(0)\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"   -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \n",
    "    This version includes robust NaN handling to prevent model training errors.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    \n",
    "                    # Corrected logic: Convert any NaNs to a numerical value, e.g., 0,\n",
    "                    # to prevent them from propagating through the model.\n",
    "                    arr = np.nan_to_num(arr, nan=0.0)\n",
    "                    \n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    # Get the maximum value, but check if it's a valid number and > 0.\n",
    "                    # This prevents division by zero if the patch is all zeros.\n",
    "                    max_val = np.nanmax(arr)\n",
    "                    if np.isfinite(max_val) and max_val > 0:\n",
    "                        arr /= max_val\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "\n",
    "# We now split the training data into a training and validation set\n",
    "train_split, val_split = train_test_split(train_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "coords_train_split = train_split[['Long','Lat']].values\n",
    "coords_val_split = val_split[['Long','Lat']].values\n",
    "\n",
    "dist_mat_train_split = distance_matrix(coords_train_split, coords_train_split)\n",
    "gnn_train_split = np.exp(-dist_mat_train_split/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train_split)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "dist_mat_val_train = distance_matrix(coords_val_split, coords_train_split)\n",
    "gnn_val_split = np.exp(-dist_mat_val_train/10)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train_split = scaler.fit_transform(train_split[numeric_cols])\n",
    "mlp_val_split = scaler.transform(val_split[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train_split = train_split['RI'].values\n",
    "y_val_split = val_split['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define the Mixture of Experts Model ==================== #\n",
    "def build_moe_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- Expert 1: CNN Branch ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch_flattened = Flatten()(cnn_branch)\n",
    "    cnn_branch_dense = Dense(128, activation=\"relu\")(cnn_branch_flattened)\n",
    "    # The CNN expert's final prediction\n",
    "    cnn_expert_out = Dense(1, activation=\"linear\", name=\"cnn_expert_out\")(cnn_branch_dense)\n",
    "\n",
    "    # --- Expert 2: MLP Branch ---\n",
    "    mlp_branch = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_branch = Dense(32, activation=\"relu\")(mlp_branch)\n",
    "    # The MLP expert's final prediction\n",
    "    mlp_expert_out = Dense(1, activation=\"linear\", name=\"mlp_expert_out\")(mlp_branch)\n",
    "\n",
    "    # --- Expert 3: GNN Branch ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_branch = Dense(32, activation=\"relu\")(gnn_branch)\n",
    "    # The GNN expert's final prediction\n",
    "    gnn_expert_out = Dense(1, activation=\"linear\", name=\"gnn_expert_out\")(gnn_branch)\n",
    "\n",
    "    # --- Gating Network ---\n",
    "    # The gating network needs features from all inputs to make its decision.\n",
    "    # We use the outputs of the dense layers before the final predictions as features.\n",
    "    gate_input = Concatenate()([cnn_branch_dense, mlp_branch, gnn_branch])\n",
    "    gate_network = Dense(64, activation=\"relu\")(gate_input)\n",
    "    gate_network = Dense(32, activation=\"relu\")(gate_network)\n",
    "    # The output is a set of weights for each expert (summing to 1 via softmax)\n",
    "    gate_weights = Dense(3, activation=\"softmax\", name=\"gate_weights\")(gate_network)\n",
    "\n",
    "    # --- Combine Experts and Gating Network ---\n",
    "    # Stack the predictions from each expert.\n",
    "    # The shape will be (batch_size, 3)\n",
    "    experts_stack = Concatenate(axis=1, name=\"experts_stack\")([cnn_expert_out, mlp_expert_out, gnn_expert_out])\n",
    "    \n",
    "    # Perform the weighted sum.\n",
    "    # This is done using a Lambda layer which takes the experts' outputs and\n",
    "    # the gating network's weights, and computes the dot product for each sample.\n",
    "    final_output = Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"final_output\")([experts_stack, gate_weights])\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing for BUFFER_METERS = {BUFFER_METERS}m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(train_split)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_moe_model(cnn_patch_shape, gnn_input_dim, mlp_train_split.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train_split,\n",
    "    mlp_data=mlp_train_split,\n",
    "    gnn_data=gnn_train_split,\n",
    "    y=y_train_split,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = DataGenerator(\n",
    "    coords=coords_val_split,\n",
    "    mlp_data=mlp_val_split,\n",
    "    gnn_data=gnn_val_split,\n",
    "    y=y_val_split,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False # No need to shuffle validation data\n",
    ")\n",
    "\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train_split[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_split[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n Mixture of Experts Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 9. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 9.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nBaseline Performance on Test Set: R² = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test)).flatten()\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test)).flatten()\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated)).flatten()\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R² drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R² drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R² drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 9.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(numeric_cols):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test)).flatten()\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator, validation_generator\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d3d2a-3b3e-4da5-ad4d-f1e4230786dd",
   "metadata": {},
   "source": [
    "# Dual Attention Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7958c587-867c-4d28-9697-5f55ae584734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing for BUFFER_METERS = 500m\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_43\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_43\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_55    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_55… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_56    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_attention_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ max_pooling2d_56… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialAttention</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span> │ spatial_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FeatureAttention</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ feature_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span> │ dense_156[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FeatureAttention</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,128</span> │ flatten_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_155[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ feature_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ gnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ combined_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_159[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_60 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_55    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_61 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_55… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_56    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_attention_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │         \u001b[38;5;34m65\u001b[0m │ max_pooling2d_56… │\n",
       "│ (\u001b[38;5;33mSpatialAttention\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m580\u001b[0m │ spatial_attentio… │\n",
       "│ (\u001b[38;5;33mFeatureAttention\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_156 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ feature_attentio… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_155 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,024\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_attention_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m580\u001b[0m │ dense_156[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mFeatureAttention\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m5,120,128\u001b[0m │ flatten_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_155[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ feature_attentio… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ cnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ gnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_159 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ combined_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_159[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_160 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,192,682</span> (19.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,192,682\u001b[0m (19.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,192,682</span> (19.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,192,682\u001b[0m (19.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 38509.0195 - val_loss: 10339.6250\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 11427.6318 - val_loss: 5737.3286\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 6921.1147 - val_loss: 5162.6240\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 7134.8667 - val_loss: 5388.1177\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 8378.8984 - val_loss: 6094.2749\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 7324.8931 - val_loss: 6341.5684\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 5987.6206 - val_loss: 4219.8662\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 5350.9990 - val_loss: 3969.6746\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 5192.5103 - val_loss: 3503.4751\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 3658.0215 - val_loss: 3432.9375\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 3334.0254 - val_loss: 3147.3901\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 3585.9368 - val_loss: 2551.2087\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 2636.3652 - val_loss: 1667.0466\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2844.8091 - val_loss: 1183.1818\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 1583.7133 - val_loss: 670.6736\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 1737.0222 - val_loss: 1240.3456\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 1483.8446 - val_loss: 641.4672\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 1241.8663 - val_loss: 379.0318\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 956.0259 - val_loss: 441.1362\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 992.6067 - val_loss: 654.2586\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 876.6573 - val_loss: 564.9452\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 958.9203 - val_loss: 444.1705\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 1028.7582 - val_loss: 266.1903\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 1037.0563 - val_loss: 246.9263\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 824.3050 - val_loss: 398.4117\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 780.4807 - val_loss: 283.3599\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 664.0100 - val_loss: 295.2289\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 719.8334 - val_loss: 226.6016\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 854.3489 - val_loss: 455.3517\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 656.6158 - val_loss: 188.4628\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 610.2795 - val_loss: 365.5605\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 780.4538 - val_loss: 748.1320\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 890.1691 - val_loss: 224.2583\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 527.6053 - val_loss: 203.0710\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 455.7232 - val_loss: 583.3862\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 702.4205 - val_loss: 209.5977\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 618.2269 - val_loss: 299.7644\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 663.5809 - val_loss: 250.1052\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 996.8817 - val_loss: 304.2189\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 338.2081 - val_loss: 90.1941\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 548.3879 - val_loss: 108.9285\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 634.1647 - val_loss: 139.6806\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 624.2316 - val_loss: 539.0131\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 619.9326 - val_loss: 244.1707\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 591.3117 - val_loss: 552.2926\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 335.3126 - val_loss: 152.9544\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 629.7659 - val_loss: 159.3669\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 477.2498 - val_loss: 550.9937\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 619.5190 - val_loss: 546.4235\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 629.9553 - val_loss: 111.3753\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      " Dual Attention Model Performance (500m):\n",
      "R² Train: -1.0315 | RMSE Train: 97.3211\n",
      "R² Test: 0.9277 | RMSE Test: 21.2671\n",
      "\n",
      "--------------------------------------------------\n",
      "Feature Importance Analysis for 500m\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Baseline Performance on Test Set: R² = 0.9277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "--- Combined Feature Importance (by Model Branch) ---\n",
      "CNN Branch Importance (R² drop): 2.3989\n",
      "MLP Branch Importance (R² drop): 0.7616\n",
      "GNN Branch Importance (R² drop): -0.0008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "--- MLP Feature Importance (Permutation-based) ---\n",
      "PbR                 : 0.0965\n",
      "CuR                 : 0.0792\n",
      "FeR                 : 0.0756\n",
      "AsR                 : 0.0085\n",
      "hydro_dist_brick    : 0.0000\n",
      "hydro_dist_ind      : -0.0000\n",
      "CrR                 : -0.0000\n",
      "MR                  : -0.0014\n",
      "SandR               : -0.0015\n",
      "SiltR               : -0.0016\n",
      "num_industry        : -0.0065\n",
      "NiR                 : -0.0070\n",
      "CdR                 : -0.0074\n",
      "ClayR               : -0.0122\n",
      "num_brick_field     : -0.0278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11623"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Dropout,\n",
    "    Layer,\n",
    "    Lambda,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    "    Multiply\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: The data loading logic remains the same.\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        \n",
    "        # Slice the GNN adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        # Return a tuple of inputs and the target, which Keras expects\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define Custom Attention Layers ==================== #\n",
    "\n",
    "class SpatialAttention(Layer):\n",
    "    \"\"\"\n",
    "    A custom layer to apply spatial attention to a feature map.\n",
    "    It generates a spatial attention map and multiplies it with the input.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpatialAttention, self).__init__(**kwargs)\n",
    "        self.conv1 = Conv2D(1, (1, 1), activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Squeeze the channels and generate a 2D attention map\n",
    "        attention_map = self.conv1(inputs)\n",
    "        # Multiply the input feature map by the attention map\n",
    "        return Multiply()([inputs, attention_map])\n",
    "\n",
    "class FeatureAttention(Layer):\n",
    "    \"\"\"\n",
    "    A custom layer to apply feature-wise attention.\n",
    "    It learns a weight for each feature channel and multiplies it with the input.\n",
    "    Inspired by Squeeze-and-Excitation networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction_ratio=16, **kwargs):\n",
    "        super(FeatureAttention, self).__init__(**kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) == 4: # CNN output\n",
    "            self.avg_pool = GlobalAveragePooling2D()\n",
    "            self.dense1 = Dense(units=input_shape[-1] // self.reduction_ratio, activation='relu')\n",
    "            self.dense2 = Dense(units=input_shape[-1], activation='sigmoid')\n",
    "            self.reshape_output = Reshape((1, 1, input_shape[-1]))\n",
    "        else: # MLP or GNN output\n",
    "            self.dense1 = Dense(units=input_shape[-1] // self.reduction_ratio, activation='relu')\n",
    "            self.dense2 = Dense(units=input_shape[-1], activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if len(inputs.shape) == 4: # CNN branch\n",
    "            x = self.avg_pool(inputs)\n",
    "            x = self.dense1(x)\n",
    "            x = self.dense2(x)\n",
    "            x = self.reshape_output(x)\n",
    "        else: # MLP or GNN branch\n",
    "            x = self.dense1(inputs)\n",
    "            x = self.dense2(x)\n",
    "        \n",
    "        return Multiply()([inputs, x])\n",
    "\n",
    "# ==================== 6. Define the Dual Attention Model ==================== #\n",
    "def build_dual_attention_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- CNN Branch with Spatial and Feature Attention ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    \n",
    "    # Spatial Attention\n",
    "    cnn_spatial_attn = SpatialAttention()(cnn_branch)\n",
    "    \n",
    "    # Feature Attention\n",
    "    cnn_feature_attn = FeatureAttention()(cnn_spatial_attn)\n",
    "    \n",
    "    # Flatten and get embedding\n",
    "    cnn_embedding = Flatten()(cnn_feature_attn)\n",
    "    cnn_embedding = Dense(128, activation=\"relu\", name=\"cnn_embedding\")(cnn_embedding)\n",
    "\n",
    "    # --- MLP Branch with Embedding ---\n",
    "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(32, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch with Feature Attention and Embedding ---\n",
    "    gnn_branch = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    \n",
    "    # Feature Attention\n",
    "    gnn_feature_attn = FeatureAttention()(gnn_branch)\n",
    "    gnn_embedding = Dense(32, activation=\"relu\", name=\"gnn_embedding\")(gnn_feature_attn)\n",
    "\n",
    "    # --- Attention Fusion ---\n",
    "    # Concatenate all embeddings\n",
    "    combined_embedding = Concatenate(name=\"combined_embedding\")([cnn_embedding, mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined_embedding)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        \n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        batch_y = y_test[i:i+batch_size]\n",
    "\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            raster_paths,\n",
    "            buffer_pixels_x,\n",
    "            buffer_pixels_y,\n",
    "            patch_width,\n",
    "            patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing for BUFFER_METERS = {BUFFER_METERS}m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "model = build_dual_attention_model(cnn_patch_shape, gnn_input_dim, mlp_train.shape[1])\n",
    "model.summary()\n",
    "\n",
    "# ==================== 7. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train,\n",
    "    mlp_data=mlp_train,\n",
    "    gnn_data=gnn_train,\n",
    "    y=y_train,\n",
    "    raster_paths=raster_paths,\n",
    "    buffer_meters=BUFFER_METERS,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 8. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 9. Evaluate ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n Dual Attention Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# ==================== 10. Feature Importance Analysis ==================== #\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"Feature Importance Analysis for {BUFFER_METERS}m\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# --- 10.1 Combined Feature Importance (by Model Branch) ---\n",
    "y_pred_baseline = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, return_preds=True)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nBaseline Performance on Test Set: R² = {baseline_r2:.4f}\")\n",
    "\n",
    "# Ablate CNN branch\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    buffer_pixels_y = int(BUFFER_METERS / res_y)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "cnn_test_ablated = np.zeros_like(extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "))\n",
    "y_pred_cnn_ablated = model.predict((cnn_test_ablated, mlp_test, gnn_test)).flatten()\n",
    "r2_cnn_ablated = r2_score(y_test, y_pred_cnn_ablated)\n",
    "importance_cnn = baseline_r2 - r2_cnn_ablated\n",
    "\n",
    "# Ablate MLP branch\n",
    "mlp_test_ablated = np.zeros_like(mlp_test)\n",
    "y_pred_mlp_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test_ablated, gnn_test)).flatten()\n",
    "r2_mlp_ablated = r2_score(y_test, y_pred_mlp_ablated)\n",
    "importance_mlp = baseline_r2 - r2_mlp_ablated\n",
    "\n",
    "# Ablate GNN branch\n",
    "gnn_test_ablated = np.zeros_like(gnn_test)\n",
    "y_pred_gnn_ablated = model.predict((extract_patch_for_generator(\n",
    "    coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "), mlp_test, gnn_test_ablated)).flatten()\n",
    "r2_gnn_ablated = r2_score(y_test, y_pred_gnn_ablated)\n",
    "importance_gnn = baseline_r2 - r2_gnn_ablated\n",
    "\n",
    "print(\"\\n--- Combined Feature Importance (by Model Branch) ---\")\n",
    "print(f\"CNN Branch Importance (R² drop): {importance_cnn:.4f}\")\n",
    "print(f\"MLP Branch Importance (R² drop): {importance_mlp:.4f}\")\n",
    "print(f\"GNN Branch Importance (R² drop): {importance_gnn:.4f}\")\n",
    "\n",
    "# --- 10.2 MLP Feature Importance (Permutation-based) ---\n",
    "mlp_feature_importance = {}\n",
    "for i, feature_name in enumerate(numeric_cols):\n",
    "    mlp_test_shuffled = np.copy(mlp_test)\n",
    "    np.random.shuffle(mlp_test_shuffled[:, i])\n",
    "    \n",
    "    y_pred_shuffled = model.predict((extract_patch_for_generator(\n",
    "        coords_test, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "    ), mlp_test_shuffled, gnn_test)).flatten()\n",
    "    r2_shuffled = r2_score(y_test, y_pred_shuffled)\n",
    "    \n",
    "    importance = baseline_r2 - r2_shuffled\n",
    "    mlp_feature_importance[feature_name] = importance\n",
    "\n",
    "print(\"\\n--- MLP Feature Importance (Permutation-based) ---\")\n",
    "sorted_importance = sorted(mlp_feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:<20}: {importance:.4f}\")\n",
    "    \n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5291cf5-d34f-40a8-b496-18b8ba415bea",
   "metadata": {},
   "source": [
    "# Stacked Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a8ef4bd-be79-4a10-a6bf-ba26d1b7484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing Stacked Deep Ensemble for BUFFER_METERS = 500m\n",
      "================================================================================\n",
      "\n",
      "--- Training CNN-MLP Base Model ---\n",
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 189ms/step - loss: 385478.0625 - val_loss: 43572.1250\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 33179.5117 - val_loss: 23165.2891\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 13353.2676 - val_loss: 9021.6162\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 8968.4580 - val_loss: 6605.4121\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 7135.8447 - val_loss: 6284.5776\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 7969.8403 - val_loss: 4805.4580\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 4267.9761 - val_loss: 3967.9670\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 4123.1226 - val_loss: 3129.3223\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - loss: 2743.0476 - val_loss: 2137.2759\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 2006.5985 - val_loss: 1917.2687\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 1562.6423 - val_loss: 896.8272\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 859.4891 - val_loss: 551.7071\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 599.2740 - val_loss: 422.3724\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 358.0335 - val_loss: 327.0349\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 281.9104 - val_loss: 264.0676\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 225.5314 - val_loss: 204.0444\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 217.4034 - val_loss: 219.6745\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - loss: 386.1687 - val_loss: 399.6148\n",
      "\n",
      "--- Training GNN-MLP Base Model ---\n",
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 35677.8594 - val_loss: 33350.7539\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 35192.5586 - val_loss: 28165.7402\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 28146.4336 - val_loss: 19900.7422\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 17401.0332 - val_loss: 8214.2939\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 8922.8125 - val_loss: 3615.0645\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 3291.7607 - val_loss: 3363.6479\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 3319.9849 - val_loss: 2695.9824\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 2241.4324 - val_loss: 2079.6331\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 2032.0607 - val_loss: 1420.8986\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 1171.4437 - val_loss: 910.4397\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 846.7778 - val_loss: 609.6826\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 627.3659 - val_loss: 507.0802\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 523.8396 - val_loss: 431.1787\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 468.8333 - val_loss: 361.1899\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 342.6514 - val_loss: 315.8818\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 370.9554 - val_loss: 279.4593\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 218.4081 - val_loss: 245.3237\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 205.2081 - val_loss: 223.7995\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 291.6069 - val_loss: 203.5947\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 173.8046 - val_loss: 188.6414\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 174.8675 - val_loss: 172.3148\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 154.8670 - val_loss: 162.4818\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 154.0370 - val_loss: 149.9754\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 140.6077 - val_loss: 139.8483\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 128.4896 - val_loss: 137.2924\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 146.4603 - val_loss: 127.6015\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 182.5809 - val_loss: 120.6629\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 141.5329 - val_loss: 114.8203\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 102.5403 - val_loss: 108.5558\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 100.3856 - val_loss: 99.5917\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 102.4683 - val_loss: 94.6684\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 120.6079 - val_loss: 90.7053\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 82.7026 - val_loss: 86.0927\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 73.3349 - val_loss: 86.0820\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 95.1335 - val_loss: 80.3012\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 85.1333 - val_loss: 75.8551\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 67.9305 - val_loss: 73.8395\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 59.9335 - val_loss: 68.1653\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 55.2959 - val_loss: 68.4304\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 71.4744 - val_loss: 61.8015\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 70.8857 - val_loss: 60.3905\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 50.1440 - val_loss: 56.5917\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 67.0840 - val_loss: 53.2347\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 38.2988 - val_loss: 53.8287\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 53.2844 - val_loss: 49.6434\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 76.9635 - val_loss: 46.2617\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 50.8454 - val_loss: 40.7783\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 52.2038 - val_loss: 44.7765\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 47.1498 - val_loss: 42.4333\n",
      "\n",
      "--- Training CNN-GNN Base Model ---\n",
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - loss: 171834.0469 - val_loss: 161972.7188\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 104696.6250 - val_loss: 10773.5889\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 8230.3154 - val_loss: 5350.1567\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - loss: 6365.6704 - val_loss: 4977.1284\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 5951.9619 - val_loss: 5078.5591\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 5162.4282 - val_loss: 4513.2695\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 4262.3608 - val_loss: 4613.9653\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 4244.2100 - val_loss: 5610.8037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\n",
      "--- Training Meta-Learner Model ---\n",
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 25998.0371 - val_loss: 29323.8691\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25019.1602 - val_loss: 26602.0312\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 21915.8223 - val_loss: 24042.5293\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19004.6406 - val_loss: 21623.0469\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17268.9082 - val_loss: 19350.1152\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 15427.0908 - val_loss: 17227.4629\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13975.5957 - val_loss: 15262.2227\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12433.8125 - val_loss: 13541.9316\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10495.2490 - val_loss: 12046.3555\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9737.8711 - val_loss: 10748.8760\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8200.4170 - val_loss: 9612.5312\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7292.5244 - val_loss: 8596.3184\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6514.0127 - val_loss: 7682.7515\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5533.9429 - val_loss: 6854.9341\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5260.4790 - val_loss: 6093.8628\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4702.4932 - val_loss: 5414.7041\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3528.3013 - val_loss: 4810.0332\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3822.1953 - val_loss: 4251.6401\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3104.0503 - val_loss: 3756.8328\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2472.0239 - val_loss: 3318.2600\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2486.3713 - val_loss: 2923.4607\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2045.2104 - val_loss: 2577.1965\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1770.7002 - val_loss: 2272.2075\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1413.8081 - val_loss: 2005.4761\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1257.6609 - val_loss: 1774.0435\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1250.5839 - val_loss: 1572.3273\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1139.6338 - val_loss: 1400.0237\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 995.5982 - val_loss: 1254.2251\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 764.7699 - val_loss: 1135.9161\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 870.3690 - val_loss: 1033.0430\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 797.5583 - val_loss: 948.5494\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 799.1663 - val_loss: 878.0422\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 670.4215 - val_loss: 820.5078\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 501.1232 - val_loss: 773.2067\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 559.7450 - val_loss: 731.5307\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 585.7924 - val_loss: 696.5089\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 683.2374 - val_loss: 666.3762\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 620.3223 - val_loss: 640.7137\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 524.5829 - val_loss: 618.8387\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 509.1326 - val_loss: 598.0715\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 498.2715 - val_loss: 578.6888\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 517.9200 - val_loss: 559.7297\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 556.4464 - val_loss: 542.1717\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 523.0094 - val_loss: 525.5881\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 459.4549 - val_loss: 510.3560\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 497.9366 - val_loss: 494.8093\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 401.5215 - val_loss: 480.7307\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 437.8486 - val_loss: 466.3697\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 434.4550 - val_loss: 453.1605\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 492.0583 - val_loss: 439.3970\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 403.8737 - val_loss: 426.8832\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 395.8798 - val_loss: 414.1010\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 396.8122 - val_loss: 401.8715\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 391.2744 - val_loss: 389.8042\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 372.6424 - val_loss: 378.5568\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 385.8018 - val_loss: 367.8189\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 334.2327 - val_loss: 357.5032\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 350.1871 - val_loss: 346.9853\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 347.0768 - val_loss: 336.8098\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 373.1214 - val_loss: 326.8034\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 351.3515 - val_loss: 317.1860\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 323.4598 - val_loss: 308.0872\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 319.3352 - val_loss: 299.2583\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 318.5780 - val_loss: 290.9259\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 260.5377 - val_loss: 283.1584\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 258.6242 - val_loss: 274.8951\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 293.9904 - val_loss: 266.6338\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 293.9478 - val_loss: 258.7388\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 241.1863 - val_loss: 251.0246\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 266.2894 - val_loss: 243.4724\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 283.9401 - val_loss: 236.0356\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 289.9870 - val_loss: 228.9785\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 213.9598 - val_loss: 222.7224\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 224.5930 - val_loss: 216.4197\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 207.4645 - val_loss: 210.3663\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 215.1022 - val_loss: 204.5657\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 219.5022 - val_loss: 199.0752\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 255.9175 - val_loss: 193.7970\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 232.3127 - val_loss: 189.0925\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 219.1687 - val_loss: 184.5997\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 197.2522 - val_loss: 180.4287\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 198.1803 - val_loss: 176.5124\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 213.8746 - val_loss: 172.7487\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 174.5646 - val_loss: 169.1745\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 150.8299 - val_loss: 165.6742\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 201.9121 - val_loss: 162.2343\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 170.2997 - val_loss: 159.0291\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 174.9458 - val_loss: 155.8768\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 184.7583 - val_loss: 152.8817\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 168.4946 - val_loss: 150.0693\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 154.8430 - val_loss: 147.2949\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 165.2935 - val_loss: 144.8069\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 200.0657 - val_loss: 142.4424\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 158.4956 - val_loss: 140.2429\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 132.3445 - val_loss: 138.0546\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 145.1998 - val_loss: 136.0067\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 147.2386 - val_loss: 134.1878\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 139.4731 - val_loss: 132.1900\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 144.3045 - val_loss: 130.3736\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 142.9408 - val_loss: 128.8372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      " Stacked Deep Ensemble Model Performance (500m):\n",
      "R² Test: 0.8261 | RMSE Test: 32.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33670"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "# NOTE: The data loading logic remains the same.\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "\n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define Base Models ==================== #\n",
    "def build_cnn_mlp_model(patch_shape, mlp_dim):\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "\n",
    "    # CNN branch\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_embedding = Flatten()(cnn_branch)\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(32, activation=\"relu\")(mlp_embedding)\n",
    "\n",
    "    # Combine\n",
    "    combined = Concatenate()([cnn_embedding, mlp_embedding])\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    output = Dense(1, activation=\"linear\", name=\"cnn_mlp_output\")(f)\n",
    "    \n",
    "    model = Model(inputs=[cnn_input, mlp_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_gnn_mlp_model(gnn_dim, mlp_dim):\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "\n",
    "    # GNN branch\n",
    "    gnn_embedding = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(32, activation=\"relu\")(gnn_embedding)\n",
    "\n",
    "    # MLP branch\n",
    "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(32, activation=\"relu\")(mlp_embedding)\n",
    "\n",
    "    # Combine\n",
    "    combined = Concatenate()([gnn_embedding, mlp_embedding])\n",
    "    f = Dense(64, activation=\"relu\")(combined)\n",
    "    output = Dense(1, activation=\"linear\", name=\"gnn_mlp_output\")(f)\n",
    "    \n",
    "    model = Model(inputs=[gnn_input, mlp_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_cnn_gnn_model(patch_shape, gnn_dim):\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "\n",
    "    # CNN branch\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_embedding = Flatten()(cnn_branch)\n",
    "    \n",
    "    # GNN branch\n",
    "    gnn_embedding = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(32, activation=\"relu\")(gnn_embedding)\n",
    "\n",
    "    # Combine\n",
    "    combined = Concatenate()([cnn_embedding, gnn_embedding])\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    output = Dense(1, activation=\"linear\", name=\"cnn_gnn_output\")(f)\n",
    "    \n",
    "    model = Model(inputs=[cnn_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_meta_learner_model():\n",
    "    # Takes predictions from the 3 base models as input\n",
    "    pred1_input = Input(shape=(1,), name=\"pred1_input\")\n",
    "    pred2_input = Input(shape=(1,), name=\"pred2_input\")\n",
    "    pred3_input = Input(shape=(1,), name=\"pred3_input\")\n",
    "\n",
    "    # Concatenate the predictions\n",
    "    combined = Concatenate()([pred1_input, pred2_input, pred3_input])\n",
    "    \n",
    "    # Simple MLP as the meta-learner\n",
    "    f = Dense(32, activation=\"relu\")(combined)\n",
    "    f = Dense(16, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "    \n",
    "    model = Model(inputs=[pred1_input, pred2_input, pred3_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# ==================== 6. Create Data Generators for Base Models ==================== #\n",
    "# NOTE: We create generators that provide only the necessary inputs for each base model.\n",
    "class CNNDropoutGenerator(DataGenerator):\n",
    "    def __getitem__(self, index):\n",
    "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
    "        return (batch_cnn, batch_mlp), batch_y\n",
    "\n",
    "class GNNDropoutGenerator(DataGenerator):\n",
    "    def __getitem__(self, index):\n",
    "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
    "        return (batch_gnn, batch_mlp), batch_y\n",
    "\n",
    "class MLPDropoutGenerator(DataGenerator):\n",
    "    def __getitem__(self, index):\n",
    "        (batch_cnn, batch_mlp, batch_gnn), batch_y = super().__getitem__(index)\n",
    "        return (batch_cnn, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 7. Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing Stacked Deep Ensemble for BUFFER_METERS = {BUFFER_METERS}m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "# --- Train Base Models ---\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training CNN-MLP Base Model ---\")\n",
    "cnn_mlp_model = build_cnn_mlp_model(cnn_patch_shape, mlp_input_dim)\n",
    "cnn_mlp_train_gen = CNNDropoutGenerator(\n",
    "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "cnn_mlp_model.fit(cnn_mlp_train_gen, epochs=100, verbose=1, callbacks=[early_stopping], validation_data=cnn_mlp_train_gen)\n",
    "\n",
    "print(\"\\n--- Training GNN-MLP Base Model ---\")\n",
    "gnn_mlp_model = build_gnn_mlp_model(gnn_input_dim, mlp_input_dim)\n",
    "gnn_mlp_train_gen = GNNDropoutGenerator(\n",
    "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "gnn_mlp_model.fit(gnn_mlp_train_gen, epochs=100, verbose=1, callbacks=[early_stopping], validation_data=gnn_mlp_train_gen)\n",
    "\n",
    "print(\"\\n--- Training CNN-GNN Base Model ---\")\n",
    "cnn_gnn_model = build_cnn_gnn_model(cnn_patch_shape, gnn_input_dim)\n",
    "cnn_gnn_train_gen = MLPDropoutGenerator(\n",
    "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "cnn_gnn_model.fit(cnn_gnn_train_gen, epochs=100, verbose=1, callbacks=[early_stopping], validation_data=cnn_gnn_train_gen)\n",
    "\n",
    "# --- Generate predictions for meta-learner ---\n",
    "def get_base_model_predictions(model, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size):\n",
    "    num_samples = len(y)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords[i:i+batch_size]\n",
    "        batch_mlp = mlp_data[i:i+batch_size]\n",
    "        batch_gnn = gnn_data[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "        )\n",
    "        \n",
    "        # Check which inputs the model expects and provide them\n",
    "        input_names = [inp.name for inp in model.inputs]\n",
    "        input_dict = {}\n",
    "        if 'cnn_input' in input_names:\n",
    "            input_dict['cnn_input'] = batch_cnn\n",
    "        if 'mlp_input' in input_names:\n",
    "            input_dict['mlp_input'] = batch_mlp\n",
    "        if 'gnn_input' in input_names:\n",
    "            input_dict['gnn_input'] = batch_gnn\n",
    "            \n",
    "        y_pred_list.append(model.predict(input_dict).flatten())\n",
    "        \n",
    "    return np.concatenate(y_pred_list)\n",
    "\n",
    "# Get predictions from base models on training data\n",
    "preds1_train = get_base_model_predictions(cnn_mlp_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
    "preds2_train = get_base_model_predictions(gnn_mlp_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
    "preds3_train = get_base_model_predictions(cnn_gnn_model, coords_train, mlp_train, gnn_train, y_train, raster_paths, BUFFER_METERS, batch_size)\n",
    "\n",
    "meta_train_inputs = (preds1_train.reshape(-1, 1), preds2_train.reshape(-1, 1), preds3_train.reshape(-1, 1))\n",
    "\n",
    "# --- Train Meta-Learner ---\n",
    "print(\"\\n--- Training Meta-Learner Model ---\")\n",
    "meta_model = build_meta_learner_model()\n",
    "meta_model.fit(meta_train_inputs, y_train, epochs=100, verbose=1, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "# --- Get predictions from base models on test data ---\n",
    "preds1_test = get_base_model_predictions(cnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
    "preds2_test = get_base_model_predictions(gnn_mlp_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
    "preds3_test = get_base_model_predictions(cnn_gnn_model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size)\n",
    "\n",
    "meta_test_inputs = (preds1_test.reshape(-1, 1), preds2_test.reshape(-1, 1), preds3_test.reshape(-1, 1))\n",
    "\n",
    "# --- Evaluate with Meta-Learner ---\n",
    "y_pred = meta_model.predict(meta_test_inputs).flatten()\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"\\n Stacked Deep Ensemble Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del cnn_mlp_model, gnn_mlp_model, cnn_gnn_model, meta_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c98e1-a046-4312-a85a-4192a7b47f9f",
   "metadata": {},
   "source": [
    "# CNN + LSTM (Spatio-Temporal)\n",
    "\n",
    "- **Idea:** If LULC rasters are time-series (2017–2022), stack them and process with **ConvLSTM2D**.\n",
    "- **Architecture:**\n",
    "\n",
    "```\n",
    "Time-Series Rasters → ConvLSTM2D → Flatten → Dense → Fusion → Output\n",
    "\n",
    "```\n",
    "\n",
    "- **Fusion:** Combine ConvLSTM output with MLP (hydrology) and GNN (spatial network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd1d9c62-deb9-4efd-a61c-8086beed2d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing CNN + LSTM Model with 5 mock time steps\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_53\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_53\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_lstm2d_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">207,616</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640000</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv_lstm2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_178 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_179 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">81,920,128</span> │ flatten_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_178[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_179[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ mlp_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ gnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_180 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ combined_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_180[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_181 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_181[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m100\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m26\u001b[0m)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv_lstm2d_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │    \u001b[38;5;34m207,616\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConvLSTM2D\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640000\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv_lstm2d_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_178 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,024\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_179 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m7,104\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │ \u001b[38;5;34m81,920,128\u001b[0m │ flatten_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_178[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_179[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ combined_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ cnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ mlp_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ gnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_180 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ combined_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_180[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_181 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_181[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,173,057</span> (313.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,173,057\u001b[0m (313.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,173,057</span> (313.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,173,057\u001b[0m (313.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - loss: 270388.5000 - val_loss: 864318.2500\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - loss: 503771.0312 - val_loss: 338200.4375\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - loss: 545703.2500 - val_loss: 40266.3672\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - loss: 41380.5859 - val_loss: 47581.9805\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 99993.2031 - val_loss: 44445.0586\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - loss: 29817.1309 - val_loss: 24908.7129\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 50399.3672 - val_loss: 27223.2402\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - loss: 26029.4141 - val_loss: 11001.4004\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - loss: 22219.3164 - val_loss: 9658.1738\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - loss: 10058.6670 - val_loss: 5910.6021\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - loss: 6507.4517 - val_loss: 7011.7476\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - loss: 9867.9990 - val_loss: 6054.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 10148.6396 - val_loss: 6041.8438\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - loss: 29110.5176 - val_loss: 12546.2539\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 7930.3276 - val_loss: 3868.0916\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 12532.9033 - val_loss: 8404.3623\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 28112.0332 - val_loss: 2797.8315\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - loss: 8272.7080 - val_loss: 2820.8003\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - loss: 5274.8105 - val_loss: 3565.7722\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - loss: 13591.0664 - val_loss: 3799.7390\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 4093.7622 - val_loss: 2444.5417\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 10752.8369 - val_loss: 2117.5354\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 6161.8726 - val_loss: 1971.7087\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 6779.0190 - val_loss: 4919.5127\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 15597.6992 - val_loss: 2690.5923\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 6683.6021 - val_loss: 3452.6506\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 8141.0640 - val_loss: 1610.2970\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 5913.8389 - val_loss: 2795.7583\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - loss: 4592.1582 - val_loss: 1627.4031\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 2080.6943 - val_loss: 1278.3953\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - loss: 2779.7014 - val_loss: 1215.0984\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 3870.8762 - val_loss: 1783.4116\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 1695.8136 - val_loss: 1908.0702\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 1397.3577 - val_loss: 1687.0159\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 2882.0310 - val_loss: 1633.7979\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 2579.2644 - val_loss: 1259.8352\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 3774.7651 - val_loss: 1641.3099\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - loss: 2317.3979 - val_loss: 1978.2812\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 2014.8057 - val_loss: 1353.5492\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - loss: 2020.2874 - val_loss: 1125.4271\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 1727.6062 - val_loss: 723.1423\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - loss: 1626.5746 - val_loss: 1114.5848\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - loss: 4835.9199 - val_loss: 1238.5635\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 3220.9380 - val_loss: 1300.6239\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 1922.9539 - val_loss: 971.2589\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - loss: 3266.1370 - val_loss: 991.4234\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 2048.9766 - val_loss: 1042.0908\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - loss: 1498.2211 - val_loss: 817.1422\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 1991.6050 - val_loss: 579.6458\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - loss: 2074.5659 - val_loss: 820.9394\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - loss: 1796.3544 - val_loss: 927.1395\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - loss: 1448.6951 - val_loss: 902.5234\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - loss: 1237.8435 - val_loss: 991.4905\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - loss: 1549.7958 - val_loss: 1130.7216\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - loss: 1337.7670 - val_loss: 1016.2669\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - loss: 1350.1002 - val_loss: 1297.2440\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - loss: 1675.9722 - val_loss: 1267.2596\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - loss: 1774.9829 - val_loss: 892.9772\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - loss: 1283.1796 - val_loss: 1221.3921\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 351ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "\n",
      " Spatio-Temporal Model Performance (500m):\n",
      "R² Train: -1.1527 | RMSE Train: 100.1830\n",
      "R² Test: 0.4486 | RMSE Test: 58.7165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6276"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, ConvLSTM2D, Flatten, Dense, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "# Define number of time steps for mock data\n",
    "TIME_STEPS = 5\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# NOTE: This code assumes the rasters are not time-series.\n",
    "# The `generate_mock_time_series` function below will create a time-series\n",
    "# for demonstration purposes.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "def generate_mock_time_series(patches, time_steps):\n",
    "    \"\"\"\n",
    "    Generates mock time-series data by stacking the same patch for 'time_steps'\n",
    "    time steps. In a real-world scenario, you would have different rasters\n",
    "    for each time step.\n",
    "    \n",
    "    Input shape: (batch_size, height, width, channels)\n",
    "    Output shape: (batch_size, time_steps, height, width, channels)\n",
    "    \"\"\"\n",
    "    return np.stack([patches] * time_steps, axis=1)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, time_steps=TIME_STEPS, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "        \n",
    "        # Generate mock time-series data\n",
    "        batch_cnn_time_series = generate_mock_time_series(batch_cnn, self.time_steps)\n",
    "\n",
    "        return (batch_cnn_time_series, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define Spatio-Temporal Model ==================== #\n",
    "def build_spatio_temporal_model(time_series_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=time_series_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- ConvLSTM2D Branch for Spatio-Temporal Data ---\n",
    "    # `return_sequences=False` means we get the final output of the sequence\n",
    "    conv_lstm_branch = ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        return_sequences=False,\n",
    "        activation='relu'\n",
    "    )(cnn_input)\n",
    "    \n",
    "    # Flatten and get embedding\n",
    "    cnn_embedding = Flatten()(conv_lstm_branch)\n",
    "    cnn_embedding = Dense(128, activation=\"relu\", name=\"cnn_embedding\")(cnn_embedding)\n",
    "\n",
    "    # --- MLP Branch with Embedding ---\n",
    "    mlp_embedding = Dense(64, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(32, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch with Embedding ---\n",
    "    gnn_embedding = Dense(64, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(32, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Fusion ---\n",
    "    combined_embedding = Concatenate(name=\"combined_embedding\")([cnn_embedding, mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined_embedding)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, time_steps, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "        )\n",
    "        batch_cnn_time_series = generate_mock_time_series(batch_cnn, time_steps)\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn_time_series, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing CNN + LSTM Model with {TIME_STEPS} mock time steps\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    time_series_shape = (TIME_STEPS, patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_spatio_temporal_model(time_series_shape, gnn_input_dim, mlp_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, TIME_STEPS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n Spatio-Temporal Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4488e9e5-3019-4173-aed7-0ad3d2936bfa",
   "metadata": {},
   "source": [
    " ##  **4. Transformer-based Fusion (CNN + GNN + MLP)**\n",
    "\n",
    "- **Idea:** Use a **Transformer Encoder** to fuse embeddings from CNN, GNN, and MLP branches.\n",
    "- **Architecture:**\n",
    "\n",
    "```\n",
    "CNN Embedding ┐\n",
    "GNN Embedding ├── Transformer Encoder → Dense → Output\n",
    "MLP Embedding ┘\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f975b6d-9ba9-41f0-aca2-7bdd8da49f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 26 raster layers for CNN input.\n",
      "  - bui.tif\n",
      "  - ndsi.tif\n",
      "  - savi.tif\n",
      "  - ndbsi.tif\n",
      "  - ui.tif\n",
      "  - ndwi.tif\n",
      "  - ndbi.tif\n",
      "  - awei.tif\n",
      "  - evi.tif\n",
      "  - mndwi.tif\n",
      "  - ndvi.tif\n",
      "  - LULC2020.tif\n",
      "  - LULC2021.tif\n",
      "  - LULC2022.tif\n",
      "  - LULC2019.tif\n",
      "  - LULC2018.tif\n",
      "  - LULC2017.tif\n",
      "  - Pb_R.tif\n",
      "  - ClayR.tif\n",
      "  - SandR.tif\n",
      "  - CdR.tif\n",
      "  - CrR.tif\n",
      "  - AsR.tif\n",
      "  - SiltR.tif\n",
      "  - CuR.tif\n",
      "  - NiR.tif\n",
      "\n",
      "================================================================================\n",
      "Analyzing Transformer-based Fusion Model for BUFFER_METERS = 500m\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_54\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_54\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,520</span> │ cnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_63    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_63… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_64    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_182 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_183 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding_flat… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40000</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_64… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_182[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_183[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_184 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,064</span> │ cnn_embedding_fl… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_185 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ mlp_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_186 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ gnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_184[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_185[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_186[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_35      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ concatenate_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ concatenate_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ flatten_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_187[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_188[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m26\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_77 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m7,520\u001b[0m │ cnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_63    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_78 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_63… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_64    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_182 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_183 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m14,208\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cnn_embedding_flat… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40000\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_64… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_182[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_183[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_184 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m2,560,064\u001b[0m │ cnn_embedding_fl… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_185 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ mlp_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_186 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ gnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_184[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_185[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_186[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_35      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m66,368\u001b[0m │ concatenate_35[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ concatenate_35[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ concatenate_35[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_187 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ flatten_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_187[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_188 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_188[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,726,689</span> (10.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,726,689\u001b[0m (10.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,726,689</span> (10.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,726,689\u001b[0m (10.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - loss: 28427.5312 - val_loss: 24340.9336\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 24209.4434 - val_loss: 10438.9443\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 9043.3613 - val_loss: 4714.5601\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 4750.4780 - val_loss: 2545.2229\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 2077.0437 - val_loss: 1151.7869\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 1692.1530 - val_loss: 751.4403\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 1303.8755 - val_loss: 753.8965\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 1109.9171 - val_loss: 404.4688\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 709.5677 - val_loss: 525.3448\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 793.0837 - val_loss: 427.1672\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 576.0964 - val_loss: 352.9005\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 468.2078 - val_loss: 264.2246\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 462.8748 - val_loss: 258.0963\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 794.5283 - val_loss: 377.2024\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 604.2375 - val_loss: 851.9296\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 1020.4084 - val_loss: 442.3767\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 704.3821 - val_loss: 483.8203\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 548.9521 - val_loss: 316.6216\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 650.1121 - val_loss: 263.2299\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 428.3466 - val_loss: 210.8243\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 399.8189 - val_loss: 235.4388\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - loss: 428.2495 - val_loss: 396.7731\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 695.2979 - val_loss: 417.7687\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 946.8825 - val_loss: 235.9228\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 843.9436 - val_loss: 283.3873\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 641.9739 - val_loss: 194.4557\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 409.5766 - val_loss: 117.8689\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 300.5616 - val_loss: 245.2036\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - loss: 728.2209 - val_loss: 176.1859\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - loss: 462.0981 - val_loss: 151.5230\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - loss: 529.2185 - val_loss: 168.8728\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 545.3233 - val_loss: 175.6976\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 378.1737 - val_loss: 145.8558\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 392.4657 - val_loss: 85.1169\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 439.7675 - val_loss: 234.1782\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 443.6476 - val_loss: 323.2926\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 819.9382 - val_loss: 138.5796\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 503.3640 - val_loss: 244.4883\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - loss: 419.4965 - val_loss: 135.8063\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 665.1664 - val_loss: 182.7678\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 451.9009 - val_loss: 119.9392\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - loss: 663.5877 - val_loss: 145.0735\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - loss: 416.0308 - val_loss: 190.2447\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - loss: 387.8833 - val_loss: 144.5058\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\n",
      " Transformer-based Fusion Model Performance (500m):\n",
      "R² Train: -0.7780 | RMSE Train: 91.0478\n",
      "R² Test: 0.9417 | RMSE Test: 19.0872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14256"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(f\"Using {len(raster_paths)} raster layers for CNN input.\")\n",
    "for r in raster_paths:\n",
    "    print(\"  -\", os.path.basename(r))\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "def extract_patch_for_generator(coords, raster_files, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height):\n",
    "    \"\"\"\n",
    "    Extracts a batch of patches from rasters for a given set of coordinates.\n",
    "    This function is optimized to be called by the data generator for each batch.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    # Loop through each coordinate pair in the batch\n",
    "    for lon, lat in coords:\n",
    "        channels = []\n",
    "        # Loop through each raster file to get a single patch for each raster\n",
    "        for rfile in raster_files:\n",
    "            with rasterio.open(rfile) as src:\n",
    "                try:\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    win = Window(col - buffer_pixels_x, row - buffer_pixels_y, patch_width, patch_height)\n",
    "                    arr = src.read(1, window=win, boundless=True, fill_value=0)\n",
    "                    arr = arr.astype(np.float32)\n",
    "\n",
    "                    if np.nanmax(arr) != 0:\n",
    "                        arr /= np.nanmax(arr)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {rfile} for coordinates ({lon}, {lat}): {e}\")\n",
    "                    arr = np.zeros((patch_width, patch_height), dtype=np.float32)\n",
    "            channels.append(arr)\n",
    "        patches.append(np.stack(channels, axis=-1))\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, coords, mlp_data, gnn_data, y, raster_paths, buffer_meters, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.coords = coords\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.raster_paths = raster_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.buffer_meters = buffer_meters\n",
    "\n",
    "        # Pre-calculate patch size from the first raster\n",
    "        with rasterio.open(raster_paths[0]) as src:\n",
    "            res_x, res_y = src.res\n",
    "            self.buffer_pixels_x = int(self.buffer_meters / res_x)\n",
    "            self.buffer_pixels_y = int(self.buffer_meters / res_y)\n",
    "            self.patch_width = 2 * self.buffer_pixels_x\n",
    "            self.patch_height = 2 * self.buffer_pixels_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_coords = self.coords[batch_indices]\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "\n",
    "        # Extract CNN patches for the current batch\n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords,\n",
    "            self.raster_paths,\n",
    "            self.buffer_pixels_x,\n",
    "            self.buffer_pixels_y,\n",
    "            self.patch_width,\n",
    "            self.patch_height\n",
    "        )\n",
    "        \n",
    "        return (batch_cnn, batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define Transformer-based Fusion Model ==================== #\n",
    "def build_transformer_fusion_model(patch_shape, gnn_dim, mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    cnn_input = Input(shape=patch_shape, name=\"cnn_input\")\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- CNN Branch ---\n",
    "    cnn_branch = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(cnn_input)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_branch = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(cnn_branch)\n",
    "    cnn_branch = MaxPooling2D((2,2))(cnn_branch)\n",
    "    cnn_embedding = Flatten(name=\"cnn_embedding_flatten\")(cnn_branch)\n",
    "    \n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Transformer Fusion ---\n",
    "    # To feed into the transformer, we need to make all embeddings have the same dimension.\n",
    "    # Let's use a dense layer to project them to a common size.\n",
    "    projection_dim = 64\n",
    "    cnn_proj = Dense(projection_dim)(cnn_embedding)\n",
    "    mlp_proj = Dense(projection_dim)(mlp_embedding)\n",
    "    gnn_proj = Dense(projection_dim)(gnn_embedding)\n",
    "\n",
    "    # Stack the embeddings to create a sequence for the transformer\n",
    "    # Shape becomes (None, 3, projection_dim)\n",
    "    # Corrected code to use Keras-compatible operations\n",
    "    cnn_expanded = Reshape((1, projection_dim))(cnn_proj)\n",
    "    mlp_expanded = Reshape((1, projection_dim))(mlp_proj)\n",
    "    gnn_expanded = Reshape((1, projection_dim))(gnn_proj)\n",
    "    embeddings = Concatenate(axis=1)([cnn_expanded, mlp_expanded, gnn_expanded])\n",
    "\n",
    "    # Transformer Encoder block\n",
    "    transformer_output = MultiHeadAttention(\n",
    "        num_heads=4,\n",
    "        key_dim=projection_dim\n",
    "    )(embeddings, embeddings)\n",
    "    transformer_output = Dropout(0.2)(transformer_output)\n",
    "    transformer_output = LayerNormalization(epsilon=1e-6)(embeddings + transformer_output)\n",
    "    \n",
    "    # The output from the transformer is a sequence of 3 vectors.\n",
    "    # We flatten this for the final prediction layer.\n",
    "    transformer_output_flattened = Flatten()(transformer_output)\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(transformer_output_flattened)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[cnn_input, mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, coords_test, mlp_test, gnn_test_matrix, y_test, raster_paths, buffer_meters, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with rasterio.open(raster_paths[0]) as src:\n",
    "        res_x, res_y = src.res\n",
    "        buffer_pixels_x = int(buffer_meters / res_x)\n",
    "        buffer_pixels_y = int(buffer_meters / res_y)\n",
    "        patch_width = 2 * buffer_pixels_x\n",
    "        patch_height = 2 * buffer_pixels_y\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_coords = coords_test[i:i+batch_size]\n",
    "        batch_mlp = mlp_test[i:i+batch_size]\n",
    "        batch_gnn = gnn_test_matrix[i:i+batch_size, :]\n",
    "        \n",
    "        batch_cnn = extract_patch_for_generator(\n",
    "            batch_coords, raster_paths, buffer_pixels_x, buffer_pixels_y, patch_width, patch_height\n",
    "        )\n",
    "        \n",
    "        y_pred_list.append(model.predict((batch_cnn, batch_mlp, batch_gnn)).flatten())\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing Transformer-based Fusion Model for BUFFER_METERS = {BUFFER_METERS}m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "\n",
    "# Calculate CNN patch shape based on the current buffer size\n",
    "with rasterio.open(raster_paths[0]) as src:\n",
    "    res_x, res_y = src.res\n",
    "    buffer_pixels_x = int(BUFFER_METERS / res_x)\n",
    "    patch_width = 2 * buffer_pixels_x\n",
    "    cnn_patch_shape = (patch_width, patch_width, len(raster_paths))\n",
    "\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_transformer_fusion_model(cnn_patch_shape, gnn_input_dim, mlp_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    coords=coords_train, mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    raster_paths=raster_paths, buffer_meters=BUFFER_METERS, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "r2_test, rmse_test = evaluate_model(model, coords_test, mlp_test, gnn_test, y_test, raster_paths, BUFFER_METERS, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n Transformer-based Fusion Model Performance ({BUFFER_METERS}m):\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625ba2c-9730-4c23-a33a-972f97b36a88",
   "metadata": {},
   "source": [
    "# GNN-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f617f76c-a9b9-4a83-b0d9-1777e51a3fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data is not used in this GNN-MLP model.\n",
      "\n",
      "================================================================================\n",
      "Analyzing GNN-MLP Fusion Model\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_56\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_56\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_192[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_193[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_37      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mlp_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ gnn_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ concatenate_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_194[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_195[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m14,208\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_192[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_193[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_37      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ mlp_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ gnn_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ concatenate_37[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_194[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_195[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,601</span> (225.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,601\u001b[0m (225.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,601</span> (225.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,601\u001b[0m (225.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 31092.3438 - val_loss: 32478.9863\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33183.5508 - val_loss: 19262.1777\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15648.8164 - val_loss: 4919.0029\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4859.6807 - val_loss: 3437.0469\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2810.4050 - val_loss: 2330.9536\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2761.4712 - val_loss: 1211.1638\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1409.3055 - val_loss: 600.3790\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 935.3477 - val_loss: 506.2572\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 915.4335 - val_loss: 367.5989\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 989.3988 - val_loss: 351.1776\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1080.3745 - val_loss: 256.5721\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 576.5131 - val_loss: 261.8635\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 537.4811 - val_loss: 199.3639\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 607.7291 - val_loss: 225.1796\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509.8159 - val_loss: 197.7247\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 564.7440 - val_loss: 166.3562\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 587.2372 - val_loss: 200.7388\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 686.8140 - val_loss: 145.5357\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 731.9449 - val_loss: 147.9014\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 537.8177 - val_loss: 146.2375\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.5620 - val_loss: 335.2686\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 501.0148 - val_loss: 146.0694\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 629.0425 - val_loss: 113.3704\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 531.4013 - val_loss: 129.8964\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.4830 - val_loss: 94.2139\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.1635 - val_loss: 366.1886\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 869.9307 - val_loss: 77.6451\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 465.9055 - val_loss: 75.6852\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 524.7322 - val_loss: 108.8038\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451.1481 - val_loss: 71.1794\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 575.3780 - val_loss: 116.9121\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 472.8313 - val_loss: 98.7079\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 319.7409 - val_loss: 63.1025\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 572.1066 - val_loss: 221.8624\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.8102 - val_loss: 189.7501\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 400.9489 - val_loss: 61.9360\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 862.9008 - val_loss: 52.0565\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477.7635 - val_loss: 41.0223\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329.6482 - val_loss: 53.1243\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.4396 - val_loss: 160.7128\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.7082 - val_loss: 45.3681\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492.7826 - val_loss: 39.6041\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.4985 - val_loss: 50.3994\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 454.6013 - val_loss: 145.1194\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.0800 - val_loss: 42.6512\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 479.1423 - val_loss: 106.5929\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 525.2673 - val_loss: 53.7210\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 466.9332 - val_loss: 29.2352\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.5788 - val_loss: 43.0625\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 308.4816 - val_loss: 118.1940\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.3519 - val_loss: 268.4100\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 612.3614 - val_loss: 123.5255\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.1991 - val_loss: 193.6628\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 702.6047 - val_loss: 424.4724\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.2003 - val_loss: 80.3670\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 579.2847 - val_loss: 139.4139\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.5514 - val_loss: 60.0251\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349.0838 - val_loss: 46.0325\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      " GNN-MLP Fusion Model Performance:\n",
      "R² Train: -0.9721 | RMSE Train: 95.8867\n",
      "R² Test: 0.9451 | RMSE Test: 18.5212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6021"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# We are not using rasters in this GNN-MLP model, but the paths are still\n",
    "# defined for consistency with previous versions.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(\"Note: Raster data is not used in this GNN-MLP model.\")\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define GNN-MLP Fusion Model ==================== #\n",
    "def build_gnn_mlp_model(mlp_dim, gnn_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- MLP Branch ---\n",
    "    mlp_embedding = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_embedding = Dense(64, activation=\"relu\", name=\"mlp_embedding\")(mlp_embedding)\n",
    "\n",
    "    # --- GNN Branch ---\n",
    "    gnn_embedding = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_embedding = Dense(64, activation=\"relu\", name=\"gnn_embedding\")(gnn_embedding)\n",
    "\n",
    "    # --- Concatenate Embeddings ---\n",
    "    combined = Concatenate()([mlp_embedding, gnn_embedding])\n",
    "    \n",
    "    # Final dense layers for prediction\n",
    "    f = Dense(128, activation=\"relu\")(combined)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, mlp_test, gnn_test_matrix, y_test, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    y_pred_list = []\n",
    "    \n",
    "    # Predict directly on the test data\n",
    "    y_pred = model.predict((mlp_test, gnn_test_matrix)).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP Fusion Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_gnn_mlp_model(mlp_input_dim, gnn_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "# Predict on the training data using the generator\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "# Evaluate on the test data using the updated function\n",
    "r2_test, rmse_test = evaluate_model(model, mlp_test, gnn_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n GNN-MLP Fusion Model Performance:\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273ed05-6660-4dbe-a0f1-dc8d8c719cb4",
   "metadata": {},
   "source": [
    "# GNN-MLP Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1463f2dc-b4ad-45c8-a72e-b6c169b100d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data is not used in this GNN-MLP model.\n",
      "\n",
      "================================================================================\n",
      "Analyzing GNN-MLP Autoencoder Model\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_57\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_57\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_197 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,208</span> │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_encoder_output  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_196[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_encoder_output  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_197[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent_space        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mlp_encoder_outp… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ gnn_encoder_outp… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_198 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ latent_space[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_198[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_199 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_199[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_197 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m14,208\u001b[0m │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_encoder_output  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_196[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_encoder_output  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_197[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent_space        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ mlp_encoder_outp… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ gnn_encoder_outp… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_198 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ latent_space[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_198[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_199 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_199[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,601</span> (225.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,601\u001b[0m (225.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,601</span> (225.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,601\u001b[0m (225.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 35839.9336 - val_loss: 30378.0918\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25957.2422 - val_loss: 10230.2324\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6813.6450 - val_loss: 4153.4395\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5244.6865 - val_loss: 3688.3115\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3193.0347 - val_loss: 2422.5203\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2537.5188 - val_loss: 1168.1431\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1325.7271 - val_loss: 641.5915\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1463.0836 - val_loss: 453.4164\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233.9707 - val_loss: 426.3362\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1036.8502 - val_loss: 308.2445\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 651.1323 - val_loss: 327.7905\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 770.3735 - val_loss: 235.3382\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 754.9042 - val_loss: 206.5920\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 692.3938 - val_loss: 183.8412\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 806.9321 - val_loss: 229.1984\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 567.6862 - val_loss: 159.3821\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 545.6325 - val_loss: 290.6540\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 669.3440 - val_loss: 139.6432\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.8165 - val_loss: 120.7755\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 690.9319 - val_loss: 153.5096\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 776.9012 - val_loss: 148.1108\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 505.0665 - val_loss: 111.6192\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 507.4846 - val_loss: 165.6836\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 753.0668 - val_loss: 99.5849\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 543.1944 - val_loss: 79.6935\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.2231 - val_loss: 100.4364\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464.9182 - val_loss: 114.1289\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.2972 - val_loss: 84.9391\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 563.3688 - val_loss: 87.2114\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.1502 - val_loss: 155.9691\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.5376 - val_loss: 184.2037\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 605.6246 - val_loss: 151.8177\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.0662 - val_loss: 275.4211\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 637.2993 - val_loss: 56.1024\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354.7257 - val_loss: 398.1106\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.1471 - val_loss: 54.8489\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415.0811 - val_loss: 50.2852\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 669.1246 - val_loss: 46.1834\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360.1890 - val_loss: 134.7073\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.2538 - val_loss: 73.2989\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 424.1789 - val_loss: 77.9668\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.3918 - val_loss: 236.9643\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 472.8114 - val_loss: 149.8798\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.1820 - val_loss: 42.7560\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.6708 - val_loss: 39.8137\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.1884 - val_loss: 184.6411\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 566.4951 - val_loss: 47.5358\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 424.6799 - val_loss: 30.2968\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.8005 - val_loss: 294.9919\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 568.9718 - val_loss: 28.9519\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 547.3184 - val_loss: 108.5274\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.3224 - val_loss: 102.2525\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.8826 - val_loss: 197.1092\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 318.5662 - val_loss: 73.2213\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508.2144 - val_loss: 51.6432\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.5917 - val_loss: 34.7795\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.0512 - val_loss: 139.9401\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384.3672 - val_loss: 154.1338\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.5217 - val_loss: 139.1686\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.2842 - val_loss: 313.1173\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      " GNN-MLP Autoencoder Model Performance:\n",
      "R² Train: -1.1549 | RMSE Train: 100.2326\n",
      "R² Test: 0.9230 | RMSE Test: 21.9355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6614"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout, Layer, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# We are not using rasters in this GNN-MLP model, but the paths are still\n",
    "# defined for consistency with previous versions.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(\"Note: Raster data is not used in this GNN-MLP model.\")\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        batch_gnn = self.gnn_data[batch_indices, :]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_test_train = distance_matrix(coords_test, coords_train)\n",
    "gnn_test = np.exp(-dist_mat_test_train/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train = scaler.fit_transform(train_combined[numeric_cols])\n",
    "mlp_test = scaler.transform(test_orig[numeric_cols])\n",
    "y_train = train_combined['RI'].values\n",
    "y_test = test_orig['RI'].values\n",
    "\n",
    "# ==================== 5. Define GNN-MLP Fusion Autoencoder Model ==================== #\n",
    "def build_gnn_mlp_autoencoder_model(mlp_dim, gnn_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(gnn_dim,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- Encoder Branch (MLP) ---\n",
    "    mlp_encoded = Dense(128, activation=\"relu\")(mlp_input)\n",
    "    mlp_encoded = Dense(64, activation=\"relu\", name=\"mlp_encoder_output\")(mlp_encoded)\n",
    "\n",
    "    # --- Encoder Branch (GNN) ---\n",
    "    gnn_encoded = Dense(128, activation=\"relu\")(gnn_input)\n",
    "    gnn_encoded = Dense(64, activation=\"relu\", name=\"gnn_encoder_output\")(gnn_encoded)\n",
    "\n",
    "    # --- Bottleneck/Latent Space ---\n",
    "    # Concatenate the encoded representations\n",
    "    latent_space = Concatenate(name=\"latent_space\")([mlp_encoded, gnn_encoded])\n",
    "    \n",
    "    # --- Decoder Branch for Prediction ---\n",
    "    # The decoder takes the latent space and performs the final prediction\n",
    "    f = Dense(128, activation=\"relu\")(latent_space)\n",
    "    f = Dropout(0.4)(f)\n",
    "    f = Dense(64, activation=\"relu\")(f)\n",
    "    output = Dense(1, activation=\"linear\", name=\"final_output\")(f)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, mlp_test, gnn_test_matrix, y_test, batch_size=4, return_preds=False):\n",
    "    num_samples = len(y_test)\n",
    "    \n",
    "    # Predict directly on the test data\n",
    "    y_pred = model.predict((mlp_test, gnn_test_matrix)).flatten()\n",
    "    \n",
    "    if return_preds:\n",
    "        return y_pred\n",
    "    else:\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return r2, rmse\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GNN-MLP Autoencoder Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train.shape[1]\n",
    "\n",
    "model = build_gnn_mlp_autoencoder_model(mlp_input_dim, gnn_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train, gnn_data=gnn_train, y=y_train,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=train_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "# Predict on the training data using the generator\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "# Evaluate on the test data using the updated function\n",
    "r2_test, rmse_test = evaluate_model(model, mlp_test, gnn_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\n GNN-MLP Autoencoder Model Performance:\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff9bd1-9951-47ba-9d92-a8c8f5370346",
   "metadata": {},
   "source": [
    "# GCN GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "306c9a95-4c00-49d4-9355-41ab36bf7c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data is not used in this GCN-GIN ensemble model.\n",
      "\n",
      "================================================================================\n",
      "Analyzing GCN-GAT Ensemble Model\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_1         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GATLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_35          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gat_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_2         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GATLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gat_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ensemble_output     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)           │                   │            │ gat_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m1,920\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mGCNLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_1         │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │      \u001b[38;5;34m3,968\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mGATLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ gcn_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_35          │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ gat_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,192\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mGCNLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_2         │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │     \u001b[38;5;34m32,832\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mGATLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ gcn_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ gat_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │      \u001b[38;5;34m2,064\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │         \u001b[38;5;34m17\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ensemble_output     │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ gcn_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mAverage\u001b[0m)           │                   │            │ gat_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,106</span> (199.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,106\u001b[0m (199.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,106</span> (199.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,106\u001b[0m (199.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 34745.5000 - val_loss: 31642.9473\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33201.1602 - val_loss: 30923.5898\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38171.8867 - val_loss: 29860.6133\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31031.3730 - val_loss: 28010.2695\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31742.3555 - val_loss: 25020.2617\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28393.9863 - val_loss: 20557.5312\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27021.1953 - val_loss: 14634.0098\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16359.5586 - val_loss: 8415.7100\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10227.2246 - val_loss: 3890.0991\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3686.4951 - val_loss: 2052.0144\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2159.6282 - val_loss: 1477.1333\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2417.9260 - val_loss: 1156.5627\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1723.8594 - val_loss: 1043.5173\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2372.0986 - val_loss: 923.8807\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1626.0824 - val_loss: 898.5035\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1326.9821 - val_loss: 806.8242\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1143.1128 - val_loss: 738.2762\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 914.4131 - val_loss: 743.8059\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 689.5412 - val_loss: 814.9081\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1145.1283 - val_loss: 652.0975\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 915.0186 - val_loss: 644.9512\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1083.2939 - val_loss: 670.5235\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 881.8303 - val_loss: 617.6995\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 664.8179 - val_loss: 753.3590\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1799.2791 - val_loss: 637.5851\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1000.5533 - val_loss: 723.5356\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 718.5071 - val_loss: 726.0968\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 693.8792 - val_loss: 757.4707\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 901.5467 - val_loss: 765.7817\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 602.8009 - val_loss: 678.2288\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 715.0624 - val_loss: 653.5411\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 792.7352 - val_loss: 718.8387\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1073.1442 - val_loss: 574.0685\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 940.9027 - val_loss: 590.7612\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 769.5322 - val_loss: 605.0712\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 817.3806 - val_loss: 611.8973\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 515.5056 - val_loss: 597.7037\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 580.6238 - val_loss: 572.1617\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 524.1306 - val_loss: 541.7415\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 928.2368 - val_loss: 572.4652\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 909.3498 - val_loss: 561.2717\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 681.2672 - val_loss: 523.2468\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.5695 - val_loss: 536.9645\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 596.7697 - val_loss: 521.3470\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 611.4929 - val_loss: 535.7665\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 866.4587 - val_loss: 536.9045\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 829.9316 - val_loss: 524.7480\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 555.2155 - val_loss: 541.0563\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.7085 - val_loss: 584.4045\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 591.0753 - val_loss: 591.3063\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.3036 - val_loss: 570.5306\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 630.7383 - val_loss: 602.8254\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 481.4399 - val_loss: 563.4631\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.9883 - val_loss: 571.9870\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.4828 - val_loss: 528.2722\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.2493 - val_loss: 508.9411\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.0481 - val_loss: 530.9499\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393.6953 - val_loss: 560.1661\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.2295 - val_loss: 585.7205\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 505.9825 - val_loss: 538.3307\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 561.0665 - val_loss: 557.8444\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 637.9175 - val_loss: 595.9120\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 513.5768 - val_loss: 569.2689\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.4549 - val_loss: 534.2831\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 601.2282 - val_loss: 504.0621\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 473.7538 - val_loss: 466.2362\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 561.4240 - val_loss: 480.1204\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.4571 - val_loss: 493.5016\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274.3045 - val_loss: 485.4018\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 562.6365 - val_loss: 480.4897\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.5081 - val_loss: 513.5569\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 554.0379 - val_loss: 451.7626\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 558.0446 - val_loss: 464.6432\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.5059 - val_loss: 462.9340\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523.6785 - val_loss: 471.7405\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.6316 - val_loss: 494.9522\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 302.6974 - val_loss: 513.0493\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.9972 - val_loss: 509.8140\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.6463 - val_loss: 555.6512\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 322.8279 - val_loss: 491.1340\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355.8916 - val_loss: 493.2729\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.7811 - val_loss: 479.7809\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 423.7948 - val_loss: 467.4637\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.7727 - val_loss: 506.6996\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.3756 - val_loss: 511.5803\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.8999 - val_loss: 513.3118\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.0273 - val_loss: 611.7780\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 548.5911 - val_loss: 504.8147\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.2533 - val_loss: 499.0509\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.4323 - val_loss: 538.1991\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.5459 - val_loss: 533.9579\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.8982 - val_loss: 536.9435\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\n",
      " GCN-GAT Ensemble Model Performance:\n",
      "R² Train: -0.8933 | RMSE Train: 91.5427\n",
      "R² Test: 0.9096 | RMSE Test: 21.2547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout, Layer, Average\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# We are not using rasters in this GCN-GIN model, but the paths are still\n",
    "# defined for consistency with previous versions.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(\"Note: Raster data is not used in this GCN-GIN ensemble model.\")\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # We need to make sure we return an integer number of batches.\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        # FIX: Correctly create a sub-graph adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[np.ix_(batch_indices, batch_indices)]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train_val = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "\n",
    "# FIX: Split the training combined data into a training and a validation set\n",
    "mlp_train_val, mlp_test = train_test_split(train_combined, test_size=len(test_orig), random_state=42)\n",
    "y_train_val, y_test = train_test_split(train_combined['RI'], test_size=len(test_orig), random_state=42)\n",
    "mlp_train, mlp_val, y_train, y_val = train_test_split(mlp_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, re-do the distance matrices and scaling with the new splits\n",
    "coords_train = mlp_train[['Long', 'Lat']].values\n",
    "coords_val = mlp_val[['Long', 'Lat']].values\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_val = distance_matrix(coords_val, coords_val)\n",
    "gnn_val = np.exp(-dist_mat_val/10)\n",
    "dist_mat_test = distance_matrix(coords_test, coords_test)\n",
    "gnn_test_data = np.exp(-dist_mat_test/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train_scaled = scaler.fit_transform(mlp_train[numeric_cols])\n",
    "mlp_val_scaled = scaler.transform(mlp_val[numeric_cols])\n",
    "mlp_test_scaled = scaler.transform(test_orig[numeric_cols])\n",
    "y_train_arr = y_train.values\n",
    "y_val_arr = y_val.values\n",
    "y_test_arr = y_test.values\n",
    "\n",
    "# ==================== 5. Define GCN-GAT Ensemble Model ==================== #\n",
    "\n",
    "class GCNLayer(Layer):\n",
    "    \"\"\"\n",
    "    Custom GCN Layer. Given the pre-computed similarity matrix, this layer\n",
    "    aggregates information from neighboring nodes and transforms it.\n",
    "    \"\"\"\n",
    "    def __init__(self, units, activation=\"relu\", **kwargs):\n",
    "        super(GCNLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        mlp_shape, gnn_shape = input_shape\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(mlp_shape[-1], self.units),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        super(GCNLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mlp_input, gnn_input = inputs\n",
    "        # The gnn_input is treated as the normalized adjacency matrix,\n",
    "        # which performs the aggregation.\n",
    "        aggregated_features = tf.matmul(gnn_input, mlp_input)\n",
    "        # Apply the linear transformation\n",
    "        output = tf.matmul(aggregated_features, self.kernel)\n",
    "        # Apply activation\n",
    "        return self.activation(output)\n",
    "\n",
    "class GATLayer(Layer):\n",
    "    \"\"\"\n",
    "    Custom GAT Layer. This layer computes attention scores for neighboring\n",
    "    nodes and aggregates features based on these scores.\n",
    "    \"\"\"\n",
    "    def __init__(self, units, num_heads=4, activation=\"relu\", **kwargs):\n",
    "        super(GATLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.num_heads = num_heads\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        mlp_shape, gnn_shape = input_shape\n",
    "        self.kernel_f = self.add_weight(\n",
    "            shape=(mlp_shape[-1], self.units * self.num_heads),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.kernel_a_1 = self.add_weight(\n",
    "            shape=(self.units, 1),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.kernel_a_2 = self.add_weight(\n",
    "            shape=(self.units, 1),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        super(GATLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        mlp_input, gnn_input = inputs\n",
    "        \n",
    "        # Linear transformation\n",
    "        features = tf.matmul(mlp_input, self.kernel_f)\n",
    "        \n",
    "        # Split features into attention heads\n",
    "        features_heads = tf.reshape(features, (-1, self.num_heads, self.units))\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        # We need to broadcast the weights for each head\n",
    "        a_1_heads = tf.tile(tf.expand_dims(self.kernel_a_1, axis=0), [self.num_heads, 1, 1])\n",
    "        a_2_heads = tf.tile(tf.expand_dims(self.kernel_a_2, axis=0), [self.num_heads, 1, 1])\n",
    "\n",
    "        # Calculate attention scores for each head\n",
    "        e_input_1 = tf.matmul(features_heads, a_1_heads)\n",
    "        e_input_2 = tf.transpose(tf.matmul(features_heads, a_2_heads), perm=[1, 2, 0])\n",
    "        \n",
    "        e = e_input_1 + e_input_2\n",
    "        e = tf.nn.leaky_relu(e, alpha=0.2)\n",
    "\n",
    "        # Mask attention scores for non-existent edges\n",
    "        mask = -10e9 * (1.0 - gnn_input)\n",
    "        attention_scores = e + mask\n",
    "        \n",
    "        # Softmax normalization\n",
    "        attention = tf.nn.softmax(attention_scores, axis=-1)\n",
    "        \n",
    "        # Aggregate features\n",
    "        aggregated_features = tf.matmul(attention, features_heads)\n",
    "        \n",
    "        # Concatenate heads and apply final activation\n",
    "        output = tf.reshape(aggregated_features, (-1, self.units * self.num_heads))\n",
    "        return self.activation(output)\n",
    "\n",
    "def build_gcn_gat_ensemble_model(mlp_dim):\n",
    "    # Inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    # FIX: Change the gnn_input shape to accept a 2D tensor of dynamic size\n",
    "    gnn_input = Input(shape=(None,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- GCN Branch (FIX: Added more layers and dropout for better performance and regularization) ---\n",
    "    gcn_branch = GCNLayer(128, name=\"gcn_layer_1\")([mlp_input, gnn_input])\n",
    "    gcn_branch = Dropout(0.2)(gcn_branch)\n",
    "    gcn_branch = GCNLayer(64, name=\"gcn_layer_2\")([gcn_branch, gnn_input])\n",
    "    gcn_branch = Dropout(0.2)(gcn_branch)\n",
    "    gcn_branch = Dense(32, activation=\"relu\")(gcn_branch)\n",
    "    gcn_output = Dense(1, activation=\"linear\", name=\"gcn_output\")(gcn_branch)\n",
    "\n",
    "    # --- GAT Branch (New) ---\n",
    "    gat_branch = GATLayer(64, num_heads=4, name=\"gat_layer_1\")([mlp_input, gnn_input])\n",
    "    gat_branch = Dropout(0.2)(gat_branch)\n",
    "    gat_branch = GATLayer(32, num_heads=4, name=\"gat_layer_2\")([gat_branch, gnn_input])\n",
    "    gat_branch = Dropout(0.2)(gat_branch)\n",
    "    gat_branch = Dense(16, activation=\"relu\")(gat_branch)\n",
    "    gat_output = Dense(1, activation=\"linear\", name=\"gat_output\")(gat_branch)\n",
    "\n",
    "    # --- Ensemble Layer ---\n",
    "    # Average the predictions from both models\n",
    "    ensemble_output = Average(name=\"ensemble_output\")([gcn_output, gat_output])\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=ensemble_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing GCN-GAT Ensemble Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train_scaled.shape[1]\n",
    "\n",
    "model = build_gcn_gat_ensemble_model(mlp_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train_scaled, gnn_data=gnn_train, y=y_train_arr,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    mlp_data=mlp_val_scaled, gnn_data=gnn_val, y=y_val_arr,\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = DataGenerator(\n",
    "    mlp_data=mlp_test_scaled, gnn_data=gnn_test_data, y=y_test_arr,\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "# Predict on the training data using the generator\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train_arr[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_arr[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "# Evaluate on the validation data\n",
    "y_pred_val = model.predict(val_generator).flatten()\n",
    "r2_test = r2_score(y_val_arr[:len(y_pred_val)], y_pred_val)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_val_arr[:len(y_pred_val)], y_pred_val))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n GCN-GAT Ensemble Model Performance:\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_test:.4f} | RMSE Test: {rmse_test:.4f}\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator, test_generator, val_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4ce44-cb44-4615-80a3-7ef7e3c46a71",
   "metadata": {},
   "source": [
    "# Graphsage GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0116baf-9fd0-4038-a246-188f9af2b30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Raster data is not used in this Stacking GNN ensemble model.\n",
      "\n",
      "================================================================================\n",
      "Analyzing Stacking GNN Ensemble Model\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_1         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │ mlp_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GATLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gat_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GCNLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_2         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GATLayer</span>)          │                   │            │ gnn_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gat_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_features        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_features        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_learner_input  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gcn_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ gat_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_dense_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │ meta_learner_inp… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_dense_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ meta_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ meta_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ mlp_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gnn_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m1,920\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mGCNLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_1         │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │      \u001b[38;5;34m3,968\u001b[0m │ mlp_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mGATLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ gcn_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ gat_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_layer_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,192\u001b[0m │ dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mGCNLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_layer_2         │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │     \u001b[38;5;34m32,832\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mGATLayer\u001b[0m)          │                   │            │ gnn_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ gcn_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ gat_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gcn_features        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gat_features        │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │      \u001b[38;5;34m2,064\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_learner_input  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ gcn_features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ gat_features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_dense_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m784\u001b[0m │ meta_learner_inp… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ meta_dense_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m136\u001b[0m │ meta_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ meta_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,985</span> (203.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,985\u001b[0m (203.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,985</span> (203.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,985\u001b[0m (203.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 37451.3164 - val_loss: 32351.1445\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35613.4648 - val_loss: 32182.5625\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34045.2305 - val_loss: 32100.3164\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37251.9141 - val_loss: 32067.7910\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35072.5664 - val_loss: 32044.7617\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34756.4414 - val_loss: 32025.8223\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40539.7695 - val_loss: 31999.2305\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37791.7148 - val_loss: 31958.6289\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33811.1680 - val_loss: 31887.1504\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32966.8242 - val_loss: 31718.6211\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39754.7891 - val_loss: 31208.0840\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31935.9395 - val_loss: 29574.0156\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31927.0371 - val_loss: 24506.2246\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22590.0586 - val_loss: 13331.1328\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9639.9736 - val_loss: 2618.8635\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2300.5972 - val_loss: 1700.0183\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1363.5823 - val_loss: 1651.1560\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1256.0724 - val_loss: 1273.3486\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1552.3641 - val_loss: 1090.5844\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 688.2656 - val_loss: 1013.0731\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1258.0691 - val_loss: 924.8409\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 759.3255 - val_loss: 862.1341\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 897.4069 - val_loss: 813.7433\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 630.5258 - val_loss: 830.3174\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 987.9496 - val_loss: 797.6124\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1024.2311 - val_loss: 762.2809\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1000.2793 - val_loss: 736.8940\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 919.6902 - val_loss: 809.3448\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 885.2856 - val_loss: 724.9144\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 619.8863 - val_loss: 663.9186\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 758.6118 - val_loss: 667.6656\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462.7803 - val_loss: 852.5671\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 490.3970 - val_loss: 699.4816\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 856.9533 - val_loss: 632.4954\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 491.1457 - val_loss: 643.4447\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 611.9401 - val_loss: 645.4163\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 724.6054 - val_loss: 629.5999\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 579.7256 - val_loss: 628.4503\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 552.5108 - val_loss: 609.9504\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451.3033 - val_loss: 607.4376\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 588.3239 - val_loss: 636.0375\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 561.1804 - val_loss: 593.0483\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 678.9345 - val_loss: 597.8047\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523.1230 - val_loss: 572.4051\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 659.3716 - val_loss: 590.3360\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387.3438 - val_loss: 577.8466\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 629.1175 - val_loss: 636.5719\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 470.3232 - val_loss: 578.1927\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 559.4420 - val_loss: 630.4141\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.1331 - val_loss: 551.2321\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 668.6531 - val_loss: 533.8799\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.5631 - val_loss: 547.2846\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 511.5526 - val_loss: 548.5072\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 536.7267 - val_loss: 646.5870\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 645.0033 - val_loss: 563.8627\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.2630 - val_loss: 567.2930\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 465.7643 - val_loss: 574.9644\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.6637 - val_loss: 609.3080\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325.9684 - val_loss: 608.6810\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.8841 - val_loss: 605.4515\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.1245 - val_loss: 536.6745\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\n",
      " Stacking GNN Ensemble Model Performance:\n",
      "R² Train: -1.2917 | RMSE Train: 100.7152\n",
      "R² Test: 0.8931 | RMSE Test: 23.1058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8331"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import gc # Import garbage collector\n",
    "\n",
    "# Define the single buffer size to use\n",
    "BUFFER_METERS = 500\n",
    "\n",
    "# ==================== 1. Load Data ==================== #\n",
    "orig = pd.read_csv(\"../../data/RainySeason.csv\")\n",
    "river_100 = pd.read_csv(\"../data/Samples_100.csv\")\n",
    "\n",
    "drop_cols = ['Stations','River','Lat','Long','geometry']\n",
    "numeric_cols = orig.drop(columns=drop_cols).columns.drop('RI')\n",
    "\n",
    "# Train-test split\n",
    "train_orig = orig.sample(10, random_state=42)\n",
    "test_orig = orig.drop(train_orig.index)\n",
    "train_combined = pd.concat([river_100, train_orig], ignore_index=True)\n",
    "\n",
    "# ==================== 2. Collect ALL Rasters ==================== #\n",
    "# We are not using rasters in this GCN-GIN model, but the paths are still\n",
    "# defined for consistency with previous versions.\n",
    "raster_paths = []\n",
    "raster_paths += glob.glob(\"../CalIndices/*.tif\")\n",
    "raster_paths += glob.glob(\"../LULCMerged/*.tif\")\n",
    "raster_paths += glob.glob(\"../IDW/*.tif\")\n",
    "\n",
    "print(\"Note: Raster data is not used in this Stacking GNN ensemble model.\")\n",
    "\n",
    "# ==================== 3. Create a Custom Data Generator ==================== #\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, mlp_data, gnn_data, y, batch_size=4, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp_data = mlp_data\n",
    "        self.gnn_data = gnn_data\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.y))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # We need to make sure we return an integer number of batches.\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Get batch data\n",
    "        batch_mlp = self.mlp_data[batch_indices]\n",
    "        # FIX: Correctly create a sub-graph adjacency matrix for the current batch\n",
    "        batch_gnn = self.gnn_data[np.ix_(batch_indices, batch_indices)]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        return (batch_mlp, batch_gnn), batch_y\n",
    "\n",
    "# ==================== 4. Prepare GNN & MLP Input (only once) ==================== #\n",
    "coords_train_val = train_combined[['Long','Lat']].values\n",
    "coords_test = test_orig[['Long','Lat']].values\n",
    "\n",
    "# FIX: Split the training combined data into a training and a validation set\n",
    "mlp_train_val, mlp_test = train_test_split(train_combined, test_size=len(test_orig), random_state=42)\n",
    "y_train_val, y_test = train_test_split(train_combined['RI'], test_size=len(test_orig), random_state=42)\n",
    "mlp_train, mlp_val, y_train, y_val = train_test_split(mlp_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, re-do the distance matrices and scaling with the new splits\n",
    "coords_train = mlp_train[['Long', 'Lat']].values\n",
    "coords_val = mlp_val[['Long', 'Lat']].values\n",
    "coords_test = test_orig[['Long', 'Lat']].values\n",
    "\n",
    "dist_mat_train = distance_matrix(coords_train, coords_train)\n",
    "gnn_train = np.exp(-dist_mat_train/10)\n",
    "dist_mat_val = distance_matrix(coords_val, coords_val)\n",
    "gnn_val = np.exp(-dist_mat_val/10)\n",
    "dist_mat_test = distance_matrix(coords_test, coords_test)\n",
    "gnn_test_data = np.exp(-dist_mat_test/10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mlp_train_scaled = scaler.fit_transform(mlp_train[numeric_cols])\n",
    "mlp_val_scaled = scaler.transform(mlp_val[numeric_cols])\n",
    "mlp_test_scaled = scaler.transform(test_orig[numeric_cols])\n",
    "y_train_arr = y_train.values\n",
    "y_val_arr = y_val.values\n",
    "y_test_arr = y_test.values\n",
    "\n",
    "# ==================== 5. Define Stacking GNN Ensemble Model ==================== #\n",
    "\n",
    "class GCNLayer(Layer):\n",
    "    \"\"\"\n",
    "    Custom GCN Layer. Given the pre-computed similarity matrix, this layer\n",
    "    aggregates information from neighboring nodes and transforms it.\n",
    "    \"\"\"\n",
    "    def __init__(self, units, activation=\"relu\", **kwargs):\n",
    "        super(GCNLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        mlp_shape, gnn_shape = input_shape\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(mlp_shape[-1], self.units),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        super(GCNLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mlp_input, gnn_input = inputs\n",
    "        # The gnn_input is treated as the normalized adjacency matrix,\n",
    "        # which performs the aggregation.\n",
    "        aggregated_features = tf.matmul(gnn_input, mlp_input)\n",
    "        # Apply the linear transformation\n",
    "        output = tf.matmul(aggregated_features, self.kernel)\n",
    "        # Apply activation\n",
    "        return self.activation(output)\n",
    "\n",
    "class GATLayer(Layer):\n",
    "    \"\"\"\n",
    "    Custom GAT Layer. This layer computes attention scores for neighboring\n",
    "    nodes and aggregates features based on these scores.\n",
    "    \"\"\"\n",
    "    def __init__(self, units, num_heads=4, activation=\"relu\", **kwargs):\n",
    "        super(GATLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.num_heads = num_heads\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        mlp_shape, gnn_shape = input_shape\n",
    "        self.kernel_f = self.add_weight(\n",
    "            shape=(mlp_shape[-1], self.units * self.num_heads),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.kernel_a_1 = self.add_weight(\n",
    "            shape=(self.units, 1),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self.kernel_a_2 = self.add_weight(\n",
    "            shape=(self.units, 1),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True\n",
    "        )\n",
    "        super(GATLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        mlp_input, gnn_input = inputs\n",
    "        \n",
    "        # Linear transformation\n",
    "        features = tf.matmul(mlp_input, self.kernel_f)\n",
    "        \n",
    "        # Split features into attention heads\n",
    "        features_heads = tf.reshape(features, (-1, self.num_heads, self.units))\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        # We need to broadcast the weights for each head\n",
    "        a_1_heads = tf.tile(tf.expand_dims(self.kernel_a_1, axis=0), [self.num_heads, 1, 1])\n",
    "        a_2_heads = tf.tile(tf.expand_dims(self.kernel_a_2, axis=0), [self.num_heads, 1, 1])\n",
    "\n",
    "        # Calculate attention scores for each head\n",
    "        e_input_1 = tf.matmul(features_heads, a_1_heads)\n",
    "        e_input_2 = tf.transpose(tf.matmul(features_heads, a_2_heads), perm=[1, 2, 0])\n",
    "        \n",
    "        e = e_input_1 + e_input_2\n",
    "        e = tf.nn.leaky_relu(e, alpha=0.2)\n",
    "\n",
    "        # Mask attention scores for non-existent edges\n",
    "        mask = -10e9 * (1.0 - gnn_input)\n",
    "        attention_scores = e + mask\n",
    "        \n",
    "        # Softmax normalization\n",
    "        attention = tf.nn.softmax(attention_scores, axis=-1)\n",
    "        \n",
    "        # Aggregate features\n",
    "        aggregated_features = tf.matmul(attention, features_heads)\n",
    "        \n",
    "        # Concatenate heads and apply final activation\n",
    "        output = tf.reshape(aggregated_features, (-1, self.units * self.num_heads))\n",
    "        return self.activation(output)\n",
    "\n",
    "def build_stacking_ensemble_model(mlp_dim):\n",
    "    \"\"\"\n",
    "    Builds a stacking ensemble model with GCN and GAT base learners\n",
    "    and an MLP meta-learner.\n",
    "    \"\"\"\n",
    "    # Define inputs for all branches\n",
    "    mlp_input = Input(shape=(mlp_dim,), name=\"mlp_input\")\n",
    "    gnn_input = Input(shape=(None,), name=\"gnn_input\")\n",
    "    \n",
    "    # --- GCN Base Learner Branch ---\n",
    "    gcn_branch = GCNLayer(128, name=\"gcn_layer_1\")([mlp_input, gnn_input])\n",
    "    gcn_branch = Dropout(0.2)(gcn_branch)\n",
    "    gcn_branch = GCNLayer(64, name=\"gcn_layer_2\")([gcn_branch, gnn_input])\n",
    "    gcn_branch = Dropout(0.2)(gcn_branch)\n",
    "    # The output of this branch will be a feature vector for the meta-learner\n",
    "    gcn_output_features = Dense(32, activation=\"relu\", name=\"gcn_features\")(gcn_branch)\n",
    "\n",
    "    # --- GAT Base Learner Branch ---\n",
    "    gat_branch = GATLayer(64, num_heads=4, name=\"gat_layer_1\")([mlp_input, gnn_input])\n",
    "    gat_branch = Dropout(0.2)(gat_branch)\n",
    "    gat_branch = GATLayer(32, num_heads=4, name=\"gat_layer_2\")([gat_branch, gnn_input])\n",
    "    gat_branch = Dropout(0.2)(gat_branch)\n",
    "    # The output of this branch will be a feature vector for the meta-learner\n",
    "    gat_output_features = Dense(16, activation=\"relu\", name=\"gat_features\")(gat_branch)\n",
    "    \n",
    "    # --- MLP Meta-Learner ---\n",
    "    # Concatenate the feature outputs of the base learners\n",
    "    meta_learner_input = Concatenate(name=\"meta_learner_input\")([gcn_output_features, gat_output_features])\n",
    "    \n",
    "    # Define the meta-learner's layers\n",
    "    meta_learner_output = Dense(16, activation=\"relu\", name=\"meta_dense_1\")(meta_learner_input)\n",
    "    meta_learner_output = Dense(8, activation=\"relu\", name=\"meta_dense_2\")(meta_learner_output)\n",
    "    \n",
    "    # Final prediction layer\n",
    "    final_output = Dense(1, activation=\"linear\", name=\"final_output\")(meta_learner_output)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[mlp_input, gnn_input], outputs=final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==================== Run the Analysis ==================== #\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Analyzing Stacking GNN Ensemble Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "batch_size = 4\n",
    "gnn_input_dim = len(coords_train)\n",
    "mlp_input_dim = mlp_train_scaled.shape[1]\n",
    "\n",
    "# Build the stacking ensemble model\n",
    "model = build_stacking_ensemble_model(mlp_input_dim)\n",
    "model.summary()\n",
    "\n",
    "# ==================== 6. Create Data Generators ==================== #\n",
    "train_generator = DataGenerator(\n",
    "    mlp_data=mlp_train_scaled, gnn_data=gnn_train, y=y_train_arr,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    mlp_data=mlp_val_scaled, gnn_data=gnn_val, y=y_val_arr,\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = DataGenerator(\n",
    "    mlp_data=mlp_test_scaled, gnn_data=gnn_test_data, y=y_test_arr,\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# ==================== 7. Train Model ==================== #\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# ==================== 8. Evaluate ==================== #\n",
    "# Predict on the training data using the generator\n",
    "y_pred_train = model.predict(train_generator).flatten()\n",
    "r2_train = r2_score(y_train_arr[:len(y_pred_train)], y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_arr[:len(y_pred_train)], y_pred_train))\n",
    "\n",
    "# Evaluate on the validation data\n",
    "y_pred_val = model.predict(val_generator).flatten()\n",
    "r2_val = r2_score(y_val_arr[:len(y_pred_val)], y_pred_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val_arr[:len(y_pred_val)], y_pred_val))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n Stacking GNN Ensemble Model Performance:\")\n",
    "print(f\"R² Train: {r2_train:.4f} | RMSE Train: {rmse_train:.4f}\")\n",
    "print(f\"R² Test: {r2_val:.4f} | RMSE Test: {rmse_val:.4f}\")\n",
    "\n",
    "# Garbage collect to free up memory\n",
    "del model, history, train_generator, test_generator, val_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53bb2c-d460-4abf-a0b0-889cf11b2c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
